import streamlit as st
import requests
import re
import json
import warnings
from langgraph.graph import StateGraph
from dotenv import load_dotenv
import os
from groq import Groq

# --- 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ (Streamlit UI ë¡œì§ë³´ë‹¤ ë¨¼ì € ì‹¤í–‰) ---
warnings.filterwarnings("ignore", category=FutureWarning)
load_dotenv()

# --- 2. Streamlit í˜ì´ì§€ ì„¤ì • ë° UI ì´ˆê¸°í™” (ë°˜ë“œì‹œ ëª¨ë“  st. ëª…ë ¹ë³´ë‹¤ ìƒë‹¨ì— ìœ„ì¹˜) ---
st.set_page_config(page_title="AI ë†ì—… ì „ë¬¸ê°€", layout="centered")
st.title("AI ë†ì—… ì±—ë´‡ ğŸ§‘â€ğŸŒ¾")
st.markdown("ì‘ë¬¼ ì¬ë°°, ì¬í•´ ëŒ€ì‘, íŒë§¤ì²˜ ë“± ë†ì—… ê´€ë ¨ ê¶ê¸ˆì¦ì„ í•´ê²°í•´ ë“œë¦½ë‹ˆë‹¤.")

# --- 3. ì—ì´ì „íŠ¸ ëª¨ë“ˆ ë¡œë“œ ë° ìƒíƒœ ë©”ì‹œì§€ í‘œì‹œ ---
agent_modules_loaded = False
try:
    from ì‘ë¬¼ì¶”ì²œ.crop65pdfllm import run as crop_recommend_run
    from ì¬ë°°ë°©ë²•.crop_overall import run as crop_cultivation_run
    from ì¬í•´ëŒ€ì‘.verification_search import run as disaster_run
    from sales.SalesAgent import run as market_run
    agent_modules_loaded = True
    st.info("âœ… ì—ì´ì „íŠ¸ ëª¨ë“ˆì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
except ImportError:
    st.warning("ğŸš¨ ì—ì´ì „íŠ¸ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ëª¨ìš© ë”ë¯¸ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    def crop_recommend_run(state): return {"pred_answer": "ì‘ë¬¼ì¶”ì²œ ì—ì´ì „íŠ¸ (ë”ë¯¸)ê°€ ì¶”ì²œ ì •ë³´ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤."}
    def crop_cultivation_run(state): return {"pred_answer": "ì‘ë¬¼ì¬ë°° ì—ì´ì „íŠ¸ (ë”ë¯¸)ê°€ ì¬ë°° ë°©ë²•ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."}
    def disaster_run(state): return {"pred_answer": "ì¬í•´ëŒ€ì‘ ì—ì´ì „íŠ¸ (ë”ë¯¸)ê°€ ì¬í•´ ëŒ€ì‘ ë°©ë²•ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤."}
    def market_run(state): return {"pred_answer": "íŒë§¤ì²˜ ì—ì´ì „íŠ¸ (ë”ë¯¸)ê°€ íŒë§¤ ì •ë³´ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤."}
    agent_modules_loaded = False

# --- 4. ê¸°ì¡´ í”„ë¡œì íŠ¸ì˜ í•µì‹¬ í•¨ìˆ˜ ë° í´ë˜ìŠ¤ ì •ì˜ ---

agent_descriptions = {
    "ì‘ë¬¼ì¶”ì²œ_agent": (
        "ì‚¬ìš©ìì˜ ì¬ë°° í™˜ê²½(ê³„ì ˆ, í† ì–‘, ê¸°í›„ ë“±), ëª©ì , íŠ¹ì • ì¡°ê±´(ìˆ˜í™• ì‹œê¸°, ë§›, ì €ì¥ì„± ë“±)ì— ë§ëŠ” ìƒˆë¡œìš´ ì‘ë¬¼ì´ë‚˜ í’ˆì¢…ì„ ì¶”ì²œí•©ë‹ˆë‹¤."
    ),
    "ì‘ë¬¼ì¬ë°°_agent": (
        "ì”¨ì•—, ëª¨ì¢… ì‹¬ê¸°ë¶€í„° ì‘ë¬¼ì˜ ì¬ë°° ë°©ë²•, ì‹¬ëŠ” ë°©ë²•, ì´ë‘ì„ ë§Œë“œëŠ” ë°©ë²•, ì†ìŒ, ì˜ì–‘ ê´€ë¦¬(ì‹œë¹„, ë¹„ë£Œ, ê±°ë¦„), ë³‘í•´ì¶© ë°©ì œ, ìˆ˜í™•ì— ì´ë¥´ê¸°ê¹Œì§€ íŠ¹ì • ì‘ë¬¼ì„ í‚¤ìš°ëŠ” ë° í•„ìš”í•œ ì¼ìƒì ì¸ ì¬ë°° ê´€ë¦¬ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤."
    ),
    "ì¬í•´_agent": (
        "í­ì—¼, í•œíŒŒ, ê°€ë­„, ì§‘ì¤‘í˜¸ìš°, í™ìˆ˜ ë“± ìì—°ì¬í•´ ë° ì´ìƒê¸°í›„ë¡œ ì¸í•œ í”¼í•´ë¥¼ ì˜ˆë°©í•˜ê³  ëŒ€ì‘í•˜ëŠ” ë°©ë²•ì„ ì•ˆë‚´í•©ë‹ˆë‹¤. ì¬í•´ ë°œìƒ ì „ ëŒ€ë¹„, ì¬í•´ ë°œìƒ ì¤‘ì˜ ì¡°ì¹˜, ì¬í•´ í›„ ì‘ë¬¼ ë³µêµ¬ ë° í”¼í•´ ìµœì†Œí™” ë°©ì•ˆì„ ë‹¤ë£¹ë‹ˆë‹¤."
    ),
    "íŒë§¤ì²˜_agent": (
        "ì‚¬ìš©ìê°€ ì¬ë°°í•˜ê±°ë‚˜ ìˆ˜í™•í•œ ë†ì‚°ë¬¼ì„ ì–´ë””ì— íŒ” ìˆ˜ ìˆëŠ”ì§€, íŒë§¤ì²˜ ìœ„ì¹˜ ì •ë³´ì™€ í•´ë‹¹ ì‘ë¬¼ì˜ ì‹¤ì‹œê°„ ì‹œì„¸, ìµœê·¼ ê°€ê²© ë³€ë™ì„ ì•ˆë‚´í•©ë‹ˆë‹¤."
    ),
    "ê¸°íƒ€": "ë†ì—…ê³¼ ì „í˜€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì¼ ê²½ìš° ì„ íƒí•©ë‹ˆë‹¤."
}

class GroqLLM:
    def __init__(self, model="llama3-8b-8192", api_key=None):
        if api_key:
            self.client = Groq(api_key=api_key)
        else:
            self.client = Groq()
        self.model = model

    def invoke(self, prompt: str):
        completion = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8,
            max_completion_tokens=2048,
            top_p=0.8,
            stream=False,
            stop=None
        )
        return completion.choices[0].message.content.strip()

llm = GroqLLM(api_key=os.getenv("OPENAI_KEY1"))

def simple_agent_selector(user_question, llm):
    selection_prompt = f"""
    ë‹¹ì‹ ì€ ì‚¬ìš©ì ì§ˆë¬¸ì— ê°€ì¥ ì í•©í•œ ë†ì—… ì „ë¬¸ ì—ì´ì „íŠ¸ë¥¼ ì„ íƒí•˜ëŠ” ë¼ìš°í„°ì…ë‹ˆë‹¤.
    ë‹¤ìŒ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ í•„ìš”í•œ ì—ì´ì „íŠ¸ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì„ íƒí•´ì£¼ì„¸ìš”.

    [ì—ì´ì „íŠ¸ ì—­í•  ë° ì„¤ëª…]
    1) ì‘ë¬¼ì¶”ì²œ_agent: {agent_descriptions["ì‘ë¬¼ì¶”ì²œ_agent"]}
    2) ì‘ë¬¼ì¬ë°°_agent: {agent_descriptions["ì‘ë¬¼ì¬ë°°_agent"]}
    3) ì¬í•´_agent: {agent_descriptions["ì¬í•´_agent"]}
    4) íŒë§¤ì²˜_agent: {agent_descriptions["íŒë§¤ì²˜_agent"]}
    5) ê¸°íƒ€: ë†ì—…ê³¼ ì „í˜€ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ì¼ ê²½ìš°.

    [ì‘ë‹µ ê·œì¹™]
    - ì§ˆë¬¸ì´ ë†ì—…ê³¼ ê´€ë ¨ ìˆë‹¤ë©´ ì ˆëŒ€ 'ê¸°íƒ€'ë¥¼ ì„ íƒí•˜ì§€ ë§ˆì„¸ìš”.
    - ê°€ì¥ ì í•©í•œ ì—ì´ì „íŠ¸ëª…ì„ ì„ íƒí•©ë‹ˆë‹¤.
    - ë‹µë³€ì€ ë°˜ë“œì‹œ ì•„ë˜ì˜ JSON í˜•ì‹ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
    
    [1ê°œ ì—ì´ì „íŠ¸ì¸ ê²½ìš°]
    {{
        "selected_agents": ["ì—ì´ì „íŠ¸ëª…"],
        "execution_order": ["ì—ì´ì „íŠ¸ëª…"]
    }}
    
    [2ê°œ ì´ìƒ ì—ì´ì „íŠ¸ì¸ ê²½ìš°]
    {{
        "selected_agents": ["ì—ì´ì „íŠ¸ëª…1", "ì—ì´ì „íŠ¸ëª…2"],
        "question_parts": {{
            "ì—ì´ì „íŠ¸ëª…1": "ë‹´ë‹¹í•  ì§ˆë¬¸ ë¶€ë¶„",
            "ì—ì´ì „íŠ¸ëª…2": "ë‹´ë‹¹í•  ì§ˆë¬¸ ë¶€ë¶„"
        }},
        "execution_order": ["ì—ì´ì „íŠ¸ëª…1", "ì—ì´ì „íŠ¸ëª…2"]
    }}
    
    ì§ˆë¬¸: "{user_question}"
    """
    
    try:
        result = llm.invoke(selection_prompt)
        json_match = re.search(r'\{.*\}', result, re.DOTALL)
        if json_match:
            parsed_result = json.loads(json_match.group())
            selected_agents = parsed_result.get("selected_agents", [])
            
            if "ê¸°íƒ€" in selected_agents and any(keyword in user_question for keyword in ["í‚¤ìš°ê¸°", "ì¬ë°°", "ì¶”ì²œ", "ì‹¬ì„", "ì¢‹ì€"]):
                return {"selected_agents": ["ì‘ë¬¼ì¶”ì²œ_agent"], "question_parts": None, "execution_order": ["ì‘ë¬¼ì¶”ì²œ_agent"]}

            if not selected_agents:
                return {"selected_agents": ["ê¸°íƒ€"], "question_parts": None, "execution_order": ["ê¸°íƒ€"]}
            
            if len(selected_agents) == 1:
                return {
                    "selected_agents": selected_agents,
                    "question_parts": None,
                    "execution_order": parsed_result.get("execution_order", [])
                }
            elif len(selected_agents) >= 2:
                if "question_parts" in parsed_result:
                    return parsed_result
                else:
                    question_parts = {agent: user_question for agent in selected_agents}
                    return {
                        "selected_agents": selected_agents,
                        "question_parts": question_parts,
                        "execution_order": parsed_result.get("execution_order", [])
                    }
        else:
            if any(keyword in user_question for keyword in ["í‚¤ìš°ê¸°", "ì¬ë°°", "ì¶”ì²œ", "ì‹¬ì„", "ì¢‹ì€"]):
                return {"selected_agents": ["ì‘ë¬¼ì¶”ì²œ_agent"], "question_parts": None, "execution_order": ["ì‘ë¬¼ì¶”ì²œ_agent"]}
            else:
                return {"selected_agents": ["ê¸°íƒ€"], "question_parts": None, "execution_order": ["ê¸°íƒ€"]}
    except Exception as e:
        return {"selected_agents": ["ê¸°íƒ€"], "question_parts": None, "execution_order": ["ê¸°íƒ€"]}

def execute_agent_with_boundaries(agent_name, question_part, llm):
    agent_functions = {
        "ì‘ë¬¼ì¶”ì²œ_agent": crop_recommend_run, "ì‘ë¬¼ì¬ë°°_agent": crop_cultivation_run,
        "ì¬í•´_agent": disaster_run, "íŒë§¤ì²˜_agent": market_run, "ê¸°íƒ€": etc_agent_run
    }
    agent_func = agent_functions.get(agent_name)
    if not agent_func:
        return f"{agent_name} ì‹¤í–‰ í•¨ìˆ˜ê°€ ì—°ê²°ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
    
    try:
        agent_state = {"query": question_part}
        agent_result = agent_func(agent_state)
        return agent_result.get("pred_answer", "ë‹µë³€ ìƒì„± ì‹¤íŒ¨")
    except Exception as e:
        return f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}"

def web_search_with_tavily(query: str, api_key: str = None):
    try:
        from tavily import TavilyClient
        
        if not api_key:
            api_key = os.getenv("TAVILY_API_KEY")
        
        if not api_key:
            return "Tavily API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        client = TavilyClient(api_key=api_key)
        
        search_result = client.search(
            query=query,
            search_depth="basic",
            max_results=5
        )
        
        if search_result and 'results' in search_result:
            return search_result['results']
        else:
            return []
                        
    except ImportError:
        return "Tavily ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install tavily-python'ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
    except Exception as e:
        return f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

def etc_agent_run(state: dict) -> dict:
    query = state.get("query", "")
    st.info("ì›¹ ê²€ìƒ‰ì„ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤... ğŸŒ")
    search_results = web_search_with_tavily(query)
    
    if not search_results:
        final_answer = "ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    else:
        # ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        search_results_str = "\n\n".join([
            f"ì œëª©: {res.get('title', 'ì—†ìŒ')}\nURL: {res.get('url', 'ì—†ìŒ')}\në‚´ìš©: {res.get('content', 'ì—†ìŒ')}" 
            for res in search_results
        ])
        
        # LLMì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ ìƒì„± í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        summary_prompt = f"""
        ë‹¹ì‹ ì€ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì•„ë˜ ê²€ìƒ‰ ê²°ê³¼ë“¤ì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°€ì¥ ì •í™•í•˜ê³  ì™„ì „í•œ ë‹µë³€ì„ ì œê³µí•´ ì£¼ì„¸ìš”.

        ë‹µë³€ ê·œì¹™
        1. **ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ**: ì¹œê·¼í•˜ê³  ëª…í™•í•œ ë¬¸ì²´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        2. **ì •ë³´ì˜ ì¶œì²˜ ëª…ì‹œ**: ê²€ìƒ‰ ê²°ê³¼ì— ì œì‹œëœ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì„¸ìš”. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ê²€ìƒ‰ ê²°ê³¼ì— ì—†ë‹¤ë©´, 'ê²€ìƒ‰ ê²°ê³¼ì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ëª…í™•í•˜ê²Œ ë§í•´ì•¼ í•©ë‹ˆë‹¤.
        3. **í•µì‹¬ ìš”ì•½ ë° ì •ë¦¬**: ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¤‘ë³µë˜ëŠ” í•µì‹¬ ë‚´ìš©ë“¤ì„ ì¢…í•©í•˜ì—¬ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
        4. **êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ**: ë‹µë³€ì€ ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ì •ë³´(ì˜ˆ: ë‚ ì§œ, ìˆ«ì, ê¸°ê´€ëª… ë“±)ë¥¼ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ ì£¼ì„¸ìš”.
        5. **í•œê¸€ë¡œë§Œ ë‹µë³€**: ëª¨ë“  ë‹µë³€ì€ í•œê¸€ë¡œë§Œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
        6. **ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ í›„ ì¶œì²˜ ëª…ì‹œ**: ë‹µë³€ ë§ˆì§€ë§‰ì— 'â€» ìœ„ ì •ë³´ëŠ” ì›¹ ê²€ìƒ‰ì„ í†µí•´ ì œê³µë˜ì—ˆìŠµë‹ˆë‹¤.' ë¬¸êµ¬ë¥¼ ì¶”ê°€í•´ ì£¼ì„¸ìš”.

        ì§ˆë¬¸: {query}
        ê²€ìƒ‰ ê²°ê³¼:
        {search_results_str[:4000]}
        
        ë‹µë³€:
        """
        
        try:
            final_answer = llm.invoke(summary_prompt)
        except Exception as e:
            final_answer = f"ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ëŠ” ë„ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
            
    return {"pred_answer": final_answer, "source": "web_search"}

def select_single_crop_from_recommendations(crop_recommendations, llm):
    selection_prompt = f"""
    ë‹¤ìŒì€ ì‘ë¬¼ì¶”ì²œ ì—ì´ì „íŠ¸ê°€ ì¶”ì²œí•œ ì‘ë¬¼ë“¤ì…ë‹ˆë‹¤. 
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ìƒí™©ì„ ê³ ë ¤í•˜ì—¬ ìƒì„¸ ë¶„ì„í•  ì‘ë¬¼ í•˜ë‚˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.
    
    [ì¶”ì²œ ì‘ë¬¼ ëª©ë¡]
    {crop_recommendations}
    
    [ìš”êµ¬ì‚¬í•­]
    - ì‘ë¬¼ëª…ë§Œ ì‘ì„± (ì˜ˆ: ë¬´, í† ë§ˆí† , ê³ ì¶”, ì˜¤ì´)
    - ì„¤ëª…ì´ë‚˜ ë¬¸ì¥ì€ ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ ê²ƒ
    - í•œ ë‹¨ì–´ë¡œ ëœ ì‘ë¬¼ëª…ë§Œ
    - ì‘ë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìœ¼ë©´ "ì—†ìŒ"ì´ë¼ê³ ë§Œ ë‹µë³€
    
    ìƒì„¸ ë¶„ì„í•  ì‘ë¬¼: """
    
    try:
        selected_crop = llm.invoke(selection_prompt).strip()
        
        if selected_crop in ["ì—†ìŒ", "", "None", "null"]:
            return ""
        
        cleaned_crop = selected_crop.split('\n')[0].split('.')[0].split(',')[0].strip()
        
        return cleaned_crop
        
    except Exception as e:
        return ""

# --- 5. LangGraph ë…¸ë“œ ë° ê·¸ë˜í”„ êµ¬ì¡° ---

class RouterState(dict):
    query: str = ""
    selected_agents: list = []
    question_parts: dict = {}
    execution_order: list = []
    crop_info: str = ""
    selected_crop: str = ""
    agent_answers: dict = {}
    output: str = ""

def node_agent_select(state: RouterState) -> RouterState:
    result = simple_agent_selector(state["query"], llm)
    state["selected_agents"] = result["selected_agents"]
    state["question_parts"] = result.get("question_parts", {})
    state["execution_order"] = result["execution_order"]
    state["agent_answers"] = {}
    return state

def node_crop_recommend(state: RouterState) -> RouterState:
    if "ì‘ë¬¼ì¶”ì²œ_agent" not in state.get("selected_agents", []):
        return state
    
    question_parts = state.get("question_parts")
    question_part = question_parts.get("ì‘ë¬¼ì¶”ì²œ_agent", state["query"]) if question_parts else state["query"]
    answer = execute_agent_with_boundaries("ì‘ë¬¼ì¶”ì²œ_agent", question_part, llm)
    selected_crop = select_single_crop_from_recommendations(answer, llm)
    
    state["crop_info"] = answer
    state["selected_crop"] = selected_crop
    state["agent_answers"]["ì‘ë¬¼ì¶”ì²œ_agent"] = answer
    return state

def node_parallel_agents(state: RouterState) -> RouterState:
    existing_answers = state.get("agent_answers", {})
    answers = {}
    selected_agents = state.get("execution_order", [])
    selected_crop = state.get("selected_crop", "")
    question_parts = state.get("question_parts")

    for agent in selected_agents:
        if agent == "ì‘ë¬¼ì¶”ì²œ_agent":
            continue
        
        if question_parts:
            question_part = question_parts.get(agent, state["query"])
        else:
            question_part = state["query"]

        if selected_crop and selected_crop not in ["I don't know", "None", ""] and selected_crop not in question_part:
            question_part = f"{selected_crop} {question_part}"
        
        answer = execute_agent_with_boundaries(agent, question_part, llm)
        answers[agent] = answer
    
    state["agent_answers"] = {**existing_answers, **answers}
    return state

def node_merge_output(state: RouterState) -> RouterState:
    selected_agents = state.get("selected_agents", [])
    output = ""
    
    if len(selected_agents) == 1:
        agent = selected_agents[0]
        output = state["agent_answers"].get(agent, f"{agent} ì‹¤í–‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        if "ì‘ë¬¼ì¶”ì²œ_agent" in state.get("agent_answers", {}) and state.get("crop_info"):
            output += f"**[ì‘ë¬¼ì¶”ì²œ ê²°ê³¼]**\n{state['crop_info']}\n"
            if state.get("selected_crop"): output += f"\n**[ìƒì„¸ ë¶„ì„ ì‘ë¬¼]**\n{state['selected_crop']}\n"
        
        for agent in state.get("execution_order", []):
            if agent != "ì‘ë¬¼ì¶”ì²œ_agent":
                answer = state["agent_answers"].get(agent, f"{agent} ì‹¤í–‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                output += f"\n**[{agent}]**\n{answer}\n"
        
        if state.get("crop_info") and state.get("selected_crop"):
            output += f"\n---\n\në‹¤ë¥¸ ì¶”ì²œ ì‘ë¬¼ì— ëŒ€í•œ ì •ë³´ê°€ ê¶ê¸ˆí•˜ì‹œë©´, '{state['selected_crop']} ëŒ€ì‹  [ë‹¤ë¥¸ ì‘ë¬¼ëª…]ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”'ì™€ ê°™ì´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”."

    merged_output = output.strip()
    
    if len(selected_agents) > 1 and "ê¸°íƒ€" not in selected_agents:
        summary_prompt = f"ì•„ë˜ëŠ” ì—¬ëŸ¬ ë†ì—… ì—ì´ì „íŠ¸ì˜ ë‹µë³€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì—ê²Œ ëª…í™•í•˜ê³  ìì„¸í•˜ê²Œ ì •ë¦¬í•´ì„œ í•œêµ­ì–´ë¡œë§Œ ì•Œë ¤ì£¼ì„¸ìš”.\n\n{merged_output}\n\n"
        try:
            summary = llm.invoke(summary_prompt)
        except Exception as e:
            summary = f"ìš”ì•½ ì¤‘ ì˜¤ë¥˜: {e}"
        state["output"] = summary.strip()
    else:
        state["output"] = merged_output
    return state

def judge_branch(state: RouterState) -> str:
    if "ì‘ë¬¼ì¶”ì²œ_agent" in state.get("selected_agents", []):
        return "crop_recommend"
    else:
        return "parallel_agents"

# ê·¸ë˜í”„ êµ¬ì¡° ì •ì˜
graph = StateGraph(RouterState)
graph.add_node("agent_select", node_agent_select)
graph.add_node("crop_recommend", node_crop_recommend)
graph.add_node("parallel_agents", node_parallel_agents)
graph.add_node("merge_output", node_merge_output)
graph.add_conditional_edges("agent_select", judge_branch, {"crop_recommend": "crop_recommend", "parallel_agents": "parallel_agents"})
graph.add_edge("crop_recommend", "parallel_agents")
graph.add_edge("parallel_agents", "merge_output")
graph.set_entry_point("agent_select")
app = graph.compile()

# --- 6. Streamlit ì±—ë´‡ UI ë¡œì§ ---

if "messages" not in st.session_state:
    st.session_state.messages = []

# ëŒ€í™” ê¸°ë¡ í‘œì‹œ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
if user_query := st.chat_input("ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
    st.session_state.messages.append({"role": "user", "content": user_query})
    with st.chat_message("user"):
        st.write(user_query)

    with st.chat_message("assistant"):
        with st.spinner("ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤... ğŸŒ±"):
            graph_state = RouterState(query=user_query)
            final_state = app.invoke(graph_state)
            final_answer = final_state.get('output', 'ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.')
            
            st.write(final_answer)
            st.session_state.messages.append({"role": "assistant", "content": final_answer})