
# - ì‹¤í–‰ ì‹œ ë©”ë‰´ì—ì„œ 1) ì±„íŒ…  2) í‰ê°€ ì„ íƒ
# - ë‘ ëª¨ë“œ ëª¨ë‘ LLM ì°¸ê³  ì»¨í…ìŠ¤íŠ¸(ì›ë¬¸ RAW)ë¥¼ ì½˜ì†” ì¶œë ¥ ë° used_context_log.txtì— ì €ì¥
# - LLMì´ ì°¸ê³ í•œ ë¬¸ì„œ ì¶œì²˜ë¥¼ ë²ˆí˜¸/íŒŒì¼ëª… DataFrameìœ¼ë¡œ ë³´ì—¬ì¤Œ
import os, json, re
from typing import TypedDict, Optional, Any, Dict, List, Tuple
from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv())
from datetime import datetime
from pathlib import Path 
# =========================

# ===== ì‚¬ìš©ì ìš”ì²­: ê²½ë¡œ/ì¸ì ë°”ê¾¸ì§€ ì•ŠìŒ =====
GOLDENSET_CSV = r"C:\Rookies_project\ET_Agent\farmer\ì‘ë¬¼ì¶”ì²œ\Goldenset_test\Goldenset_test1.csv"

# === ì„¤ì • ===
# ì‹¤í–‰ íŒŒì¼ ìœ„ì¹˜: Goldenset_test
# ë²¡í„°ìŠ¤í† ì–´ ìœ„ì¹˜: ../Crop Recommedations DB/faiss_pdf_db
VECTOR_DB_PATH = Path("../faiss_pdf_db")

EMBED_MODEL_NAME = os.getenv("EMBED_MODEL_NAME", "jhgan/ko-sroberta-multitask")

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_MODEL   = os.getenv("GROQ_MODEL", "meta-llama/llama-4-scout-17b-16e-instruct")
TEMPERATURE  = float(os.getenv("TEMPERATURE", "0.2"))
SIM_THRESHOLD = float(os.getenv("SIM_THRESHOLD", "0.75"))

if not GROQ_API_KEY:
    raise ValueError("GROQ_API_KEYê°€ .envì— ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")

# === ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œ ì²˜ë¦¬ ===
BASE_DIR = Path(__file__).resolve().parent        # Goldenset_test
vector_db_dir = (BASE_DIR / VECTOR_DB_PATH).resolve()

print("[VectorDB] ë¡œë“œ ê²½ë¡œ =", vector_db_dir)
if not vector_db_dir.exists():
    raise FileNotFoundError(f"ë²¡í„°ìŠ¤í† ì–´ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vector_db_dir}")

print("ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜(BASE_DIR):", BASE_DIR)
print("ë²¡í„°DB ê²½ë¡œ(VECTOR_DB_PATH):", VECTOR_DB_PATH.resolve())
print("index.faiss ì¡´ì¬:", (VECTOR_DB_PATH / "index.faiss").exists())
print("index.pkl ì¡´ì¬:", (VECTOR_DB_PATH / "index.pkl").exists())

# =========================
# [ë¡œê·¸ ê´€ë¦¬ ìœ í‹¸ ì¶”ê°€ - ìë™ ë¡¤ë§ í¬í•¨]
# - ì±„íŒ…(1): ì„ íƒ/ìœ ì§€ë˜ëŠ” í™œì„± ë¡œê·¸ íŒŒì¼ì— ëˆ„ì  (+ í¬ê¸° ì´ˆê³¼ ì‹œ ìë™ ë¡¤ì˜¤ë²„)
# - í‰ê°€(2): ì‹¤í–‰ë§ˆë‹¤ ì‹ ê·œ íŒŒì¼ë¡œ êµì²´ (+ í¬ê¸° ì´ˆê³¼ ì‹œ ìë™ ë¡¤ì˜¤ë²„)
#   í™˜ê²½ë³€ìˆ˜:
#     LOG_MAX_MB   (ê¸°ë³¸ 10MB)  â€” íŒŒì¼ ìµœëŒ€ í¬ê¸°
#     LOG_KEEP     (ê¸°ë³¸ 50ê°œ)  â€” ë³´ê´€í•  ë¡œê·¸ íŒŒì¼ ê°œìˆ˜(ì´ˆê³¼ë¶„ì€ ì˜¤ë˜ëœ ê²ƒ ì‚­ì œ)
# =========================
LOG_DIR = "logs"
os.makedirs(LOG_DIR, exist_ok=True)

# í™˜ê²½ ë³€ìˆ˜
try:
    _LOG_MAX_MB = max(1, int(os.getenv("LOG_MAX_MB", "10")))
except Exception:
    _LOG_MAX_MB = 10

try:
    _LOG_KEEP = max(1, int(os.getenv("LOG_KEEP", "50")))
except Exception:
    _LOG_KEEP = 50

# ë‚´ë¶€ ìƒíƒœ: í™œì„± ë¡œê·¸ íŒŒì¼ëª…(ë””ë ‰í„°ë¦¬ ì œì™¸)
_active_log_file: Optional[str] = None

def _unique_log_name() -> str:
    """ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ íƒ€ì„ìŠ¤íƒ¬í”„ + ì¹´ìš´í„°ë¡œ ê³ ìœ  íŒŒì¼ëª… ìƒì„±"""
    base = datetime.now().strftime("used_context_log_%Y%m%d_%H%M%S")
    name = f"{base}.txt"
    if not os.path.exists(os.path.join(LOG_DIR, name)):
        return name
    counter = 1
    while True:
        name = f"{base}_{counter:02d}.txt"
        if not os.path.exists(os.path.join(LOG_DIR, name)):
            return name
        counter += 1

def _default_new_log_name() -> str:
    return _unique_log_name()

def _list_all_logs_sorted_newfirst() -> List[str]:
    files = [f for f in os.listdir(LOG_DIR) if f.startswith("used_context_log_") and f.endswith(".txt")]
    files.sort(reverse=True)  # ìµœì‹  ìš°ì„ 
    return files

def _prune_old_logs(keep: int = _LOG_KEEP) -> None:
    """ìµœì‹  keepê°œë§Œ ë‚¨ê¸°ê³  ì˜¤ë˜ëœ ë¡œê·¸ ì‚­ì œ"""
    files = _list_all_logs_sorted_newfirst()
    for f in files[keep:]:
        try:
            os.remove(os.path.join(LOG_DIR, f))
        except Exception:
            pass

def _get_active_log_path() -> str:
    """í™œì„± ë¡œê·¸ íŒŒì¼ ê²½ë¡œ(ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±)"""
    global _active_log_file
    if _active_log_file is None:
        _active_log_file = _default_new_log_name()
        _prune_old_logs()
    return os.path.join(LOG_DIR, _active_log_file)

def _force_new_log_file() -> str:
    """í•­ìƒ ìƒˆ ë¡œê·¸ íŒŒì¼ë¡œ í™œì„± íŒŒì¼ êµì²´ (í‰ê°€ ëª¨ë“œ/ë¡¤ì˜¤ë²„ì— ì‚¬ìš©)"""
    global _active_log_file
    _active_log_file = _default_new_log_name()
    path = os.path.join(LOG_DIR, _active_log_file)
    _prune_old_logs()
    return path

def _maybe_roll_log() -> None:
    """
    í™œì„± ë¡œê·¸ íŒŒì¼ì´ LOG_MAX_MBë¥¼ ì´ˆê³¼í•˜ë©´ ìë™ìœ¼ë¡œ ìƒˆ íŒŒì¼ë¡œ ë¡¤ì˜¤ë²„.
    - í™œì„± íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±ë§Œ í•¨.
    """
    path = _get_active_log_path()
    try:
        size_bytes = os.path.getsize(path) if os.path.exists(path) else 0
    except Exception:
        size_bytes = 0
    if size_bytes >= (_LOG_MAX_MB * 1024 * 1024):
        new_path = _force_new_log_file()
        print(f"[ë¡œê·¸ ë¡¤ì˜¤ë²„] ìµœëŒ€ í¬ê¸° {_LOG_MAX_MB}MB ì´ˆê³¼ â†’ ìƒˆ íŒŒì¼ë¡œ êµì²´: {os.path.basename(new_path)}")

def list_log_files() -> List[str]:
    """ë¡œê·¸ íŒŒì¼ ëª©ë¡(ìµœì‹ ìˆœ)"""
    return _list_all_logs_sorted_newfirst()

def choose_log_file(index_or_name: Any) -> str:
    """ì¸ë±ìŠ¤(ìµœì‹ =0) ë˜ëŠ” íŒŒì¼ëª…(.txt)ìœ¼ë¡œ í™œì„± íŒŒì¼ ì„ íƒ"""
    global _active_log_file
    files = list_log_files()
    if isinstance(index_or_name, int):
        if not files:
            raise FileNotFoundError("logs í´ë”ì— ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        if index_or_name < 0 or index_or_name >= len(files):
            raise IndexError(f"ì¸ë±ìŠ¤ ë²”ìœ„ ì˜¤ë¥˜: 0~{len(files)-1}")
        _active_log_file = files[index_or_name]
    else:
        name = str(index_or_name)
        if not name.endswith(".txt"):
            raise ValueError("íŒŒì¼ëª…ì€ .txtë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤.")
        path = os.path.join(LOG_DIR, name)
        if not os.path.exists(path):
            raise FileNotFoundError(f"í•´ë‹¹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {name}")
        _active_log_file = name
    return _active_log_file

def read_log_file(filename: Optional[str] = None) -> str:
    target = filename if filename else _active_log_file
    if target is None:
        raise FileNotFoundError("í™œì„± ë¡œê·¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì„ íƒí•˜ê±°ë‚˜ ê¸°ë¡ì„ ë‚¨ê¸°ì„¸ìš”.")
    path = os.path.join(LOG_DIR, target)
    if not os.path.exists(path):
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {target}")
    with open(path, "r", encoding="utf-8") as f:
        return f.read()

def get_active_log_file() -> Optional[str]:
    return _active_log_file

# === LangChain / LangGraph ===
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_groq import ChatGroq
from langgraph.graph import StateGraph, END

# í‰ê°€ìš©
import numpy as np
import pandas as pd

# --- í”„ë¡¬í”„íŠ¸ ---
PROMPT_TMPL = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë†ì—… ì‘ë¬¼ì¬ë°° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ 'ë¬¸ë§¥'ë§Œ ì‚¬ìš©í•´ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

[ë¬¸ë§¥]
{context}

ê·œì¹™:
- ë¬¸ë§¥ì— ì—†ëŠ” ì •ë³´/ì¶”ì¸¡/í•œì ê¸ˆì§€.
- í•œê¸€ë¡œë§Œ ì‘ì„±.
- ë‹¨ê³„/ì„¤ëª…ì€ "í•œ ë¬¸ì¥ì”© ì¤„ë°”ê¿ˆ".
- ë¬¸ë§¥ì— ê·¼ê±° ì—†ìœ¼ë©´: "ì£¼ì–´ì§„ ì •ë³´ë¡œëŠ” ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

ì§ˆë¬¸: {question}
ë‹µë³€:
"""
rag_prompt = ChatPromptTemplate.from_template(PROMPT_TMPL)

# --- ìƒíƒœ ì •ì˜ ---
class GraphState(TypedDict):
    question: Optional[str]
    vectorstore: Optional[Any]
    context: Optional[str]
    answer: Optional[str]
    # LLMì´ ì°¸ê³ í•œ ë¬¸ì„œë“¤ì˜ ë©”íƒ€(íŒŒì¼/í˜ì´ì§€ ë“±)
    sources: Optional[List[Dict[str, Any]]]

# --- ê³µí†µ í•¨ìˆ˜ ---
def load_vectorstore(db_path: str) -> Any:
    embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL_NAME)
    return FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)

def retrieve_with_meta(vs: Any, question: str, k: int = 5) -> Tuple[str, List[Dict[str, Any]]]:
    """ì»¨í…ìŠ¤íŠ¸(ë¬¸ì„œ ì›ë¬¸)ì™€ ë©”íƒ€ë°ì´í„°(íŒŒì¼ ê²½ë¡œ ë“±)ë¥¼ í•¨ê»˜ ë°˜í™˜ â€” ì ˆëŒ€ ìë¥´ì§€ ì•ŠìŒ"""
    retriever = vs.as_retriever(search_type="similarity", search_kwargs={"k": k})
    docs = retriever.invoke(question) or []
    ctx = "\n\n".join([d.page_content for d in docs])  # ì›ë¬¸ ê·¸ëŒ€ë¡œ í•©ì¹¨

    sources: List[Dict[str, Any]] = []
    for rank, d in enumerate(docs, start=1):
        meta = d.metadata or {}
        src  = meta.get("source") or meta.get("file_path") or meta.get("path")
        page = meta.get("page")
        sources.append({"rank": rank, "source": src, "page": page, "metadata": meta})
    return ctx, sources

def make_llm() -> ChatGroq:
    return ChatGroq(model_name=GROQ_MODEL, temperature=TEMPERATURE, api_key=GROQ_API_KEY)

# --- LangGraph ë…¸ë“œ ---
def load_vs_node(state: GraphState) -> Dict[str, Any]:
    print("ğŸ§© ë…¸ë“œ: ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ")
    vs = load_vectorstore(VECTOR_DB_PATH)
    return {**state, "vectorstore": vs}

def retrieve_node(state: GraphState) -> Dict[str, Any]:
    print("ğŸ§© ë…¸ë“œ: ê²€ìƒ‰")
    if not state.get("vectorstore"):
        raise ValueError("vectorstoreê°€ ì—†ìŠµë‹ˆë‹¤.")
    q = state["question"] or ""
    ctx, sources = retrieve_with_meta(state["vectorstore"], q, k=5)
    return {**state, "context": ctx, "sources": sources}

def generate_node(state: GraphState) -> Dict[str, Any]:
    print("ğŸ§© ë…¸ë“œ: ìƒì„±")
    if not state.get("context") or not state.get("question"):
        raise ValueError("context/question ëˆ„ë½")
    chain = (
        {"context": RunnablePassthrough(), "question": RunnablePassthrough()}
        | rag_prompt
        | make_llm()
        | StrOutputParser()
    )
    ans = chain.invoke({"context": state["context"], "question": state["question"]})
    return {**state, "answer": ans}

# --- ê·¸ë˜í”„ ë¹Œë“œ ---
def build_graph():
    g = StateGraph(GraphState)
    g.add_node("load_vs", load_vs_node)
    g.add_node("retrieve", retrieve_node)
    g.add_node("generate", generate_node)

    g.add_edge("load_vs", "retrieve")
    g.add_edge("retrieve", "generate")
    g.add_edge("generate", END)
    g.set_entry_point("load_vs")
    return g.compile()

# =======================
# CSV ì½ê¸° & ìŠ¤í‚¤ë§ˆ ë³€í™˜
# =======================
def _read_csv_any(path: str) -> pd.DataFrame:
    for enc in ("utf-8-sig", "utf-8", "cp949", "euc-kr"):
        try:
            df = pd.read_csv(path, encoding=enc)
            print(f"[INFO] CSV ì¸ì½”ë”© ê°ì§€: {enc}")
            return df
        except UnicodeDecodeError:
            continue
    # ìµœí›„: ë¬´ì‹œ
    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        data = f.read()
    print("[WARN] utf-8(errors=ignore) ê°•ì œ ì‚¬ìš©")
    from io import StringIO
    return pd.read_csv(StringIO(data))

def _ensure_qa_columns(df: pd.DataFrame) -> pd.DataFrame:
    # ì»¬ëŸ¼ ê³µë°± ì œê±°
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]

    if {"question", "answer"}.issubset(df.columns):
        return df[["question", "answer"]]

    # ì‚¬ìš©ìê°€ ì£¼ì‹  í˜•ì‹ìœ¼ë¡œ ìë™ ë³€í™˜: ì œëª©/ìš”ì•½ê¸€/ì„œë¸Œì œëª©i/ì„œë¸Œë‚´ìš©i
    if "ì œëª©" not in df.columns:
        raise ValueError(f"CSVì— question/answer ì»¬ëŸ¼ì´ ì—†ê³ , 'ì œëª©' ì»¬ëŸ¼ë„ ì—†ìŠµë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {list(df.columns)}")

    def norm(x):
        return "" if pd.isna(x) else str(x).strip()

    def build_answer(row):
        parts = []
        if "ìš”ì•½ê¸€" in df.columns:
            y = norm(row.get("ìš”ì•½ê¸€"))
            if y:
                parts.append(y)
        # ì„œë¸Œì œëª©/ì„œë¸Œë‚´ìš© 1..10
        for i in range(1, 11):
            sj = f"ì„œë¸Œì œëª©{i}"
            sn1 = f"ì„œë¸Œë‚´ìš©{i}"
            sn2 = f" ì„œë¸Œë‚´ìš©{i}"  # ê³µë°± ë¶™ì€ ì¼€ì´ìŠ¤
            title = norm(row.get(sj)) if sj in df.columns else ""
            body  = norm(row.get(sn1)) if sn1 in df.columns else norm(row.get(sn2)) if sn2 in df.columns else ""
            if title or body:
                parts.append(f"{title}. {body}".strip(". ").strip())
        return "\n".join([p for p in parts if p])

    out = pd.DataFrame({
        "question": df["ì œëª©"].astype(str).str.strip(),
        "answer": df.apply(build_answer, axis=1)
    })
    return out

# =======================
# (ì„ íƒ) ë³´ê¸° ì¢‹ê²Œ ë‹¤ë“¬ëŠ” í•¨ìˆ˜ â€” í˜„ì¬ ì¶œë ¥/ë¡œê·¸ì—ëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
# =======================
def _pretty_context(text: str) -> str:
    """PDF ì¶”ì¶œ ì¡ìŒ ì œê±°í•˜ê³  ë¬¸ë‹¨ì„ ë³´ê¸° ì¢‹ê²Œ ë‹¤ë“¬ëŠ”ë‹¤. (ì°¸ê³ ìš©)"""
    if not text:
        return ""
    t = text.replace("\r\n", "\n").replace("\r", "\n")
    t = t.replace("<br>", "\n").replace("<br/>", "\n").replace("<br />", "\n")
    lines = [ln.strip() for ln in t.split("\n")]
    cleaned, seen = [], set()
    for ln in lines:
        if not ln:
            continue
        if re.match(r"^\s*<[^>]+>\s*$", ln):  # ìˆœìˆ˜ íƒœê·¸
            continue
        if re.match(r"^\d{1,4}\s*$", ln):     # ë‹¨ë… ìˆ«ì ë¼ì¸
            continue
        if "ë†ì—…ê¸°ìˆ ê¸¸ì¡ì´" in ln:            # ë¨¸ë¦¿ê¸€/ê¼¬ë¦¿ê¸€
            continue
        if re.match(r"^\s*(<\s*)?(í‘œ|ê·¸ë¦¼)\s*\d+([\-.]\d+)*", ln):  # ìº¡ì…˜ë¥˜
            continue
        if "|" in ln and len(ln) <= 80:       # ë©”íƒ€ í—¤ë”
            continue
        ln = re.sub(r"\s{2,}", " ", ln)
        if ln in seen:
            continue
        seen.add(ln)
        cleaned.append(ln)
    out = "\n".join(cleaned)
    out = re.sub(r"\n\s*\n\s*\n+", "\n\n", out).strip()
    return out

# =======================
# ê³µìš©: ì†ŒìŠ¤ â†’ DataFrame & ë¡œê·¸
# =======================
def _sources_to_dataframe(sources: Optional[List[Dict[str, Any]]]) -> pd.DataFrame:
    rows = []
    for s in (sources or []):
        src = s.get("source")
        fname = os.path.basename(src) if src else "unknown"
        rows.append({"ë²ˆí˜¸": s.get("rank"), "íŒŒì¼ëª…": fname})
    return pd.DataFrame(rows, columns=["ë²ˆí˜¸", "íŒŒì¼ëª…"])

def _append_used_context_log(index: Any,
                             question: str,
                             generated_answer: str,
                             context_raw: str,
                             golden_answer: Optional[str] = None,
                             sources: Optional[List[Dict[str, Any]]] = None) -> None:
    """í™œì„± ë¡œê·¸ íŒŒì¼ì— Q/A/ì»¨í…ìŠ¤íŠ¸ RAWì™€ ì°¸ê³  ì†ŒìŠ¤ ê¸°ë¡."""
    _maybe_roll_log()  # âœ… í¬ê¸° ì´ˆê³¼ ì‹œ ìë™ ë¡¤ì˜¤ë²„
    log_path = _get_active_log_path()
    try:
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(f"[#{index}] ------------------------------------------------\n")
            f.write(f"ì§ˆë¬¸: {question}\n")
            if golden_answer is not None:
                f.write(f"ê³¨ë“ ì…‹ ë‹µë³€ A: {golden_answer}\n")
            f.write(f"LLM ë‹µë³€: {generated_answer}\n")
            f.write("----- CONTEXT START (RAW) -----\n")
            f.write(context_raw if context_raw else "(ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)")
            f.write("\n----- CONTEXT END -----\n\n")

            if sources:
                f.write("----- SOURCES (ë²ˆí˜¸/íŒŒì¼ëª…) -----\n")
                for s in sources:
                    src = s.get("source")
                    fname = os.path.basename(src) if src else "unknown"
                    f.write(f"{s.get('rank')}\t{fname}\n")
                f.write("\n")
    except Exception as e:
        print(f"[ê²½ê³ ] ì»¨í…ìŠ¤íŠ¸ ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨: {e}")

# =======================
# ğŸ”¥ ê³¨ë“ ì…‹ í‰ê°€ í•¨ìˆ˜
# =======================
import numpy as np
def _cosine(a: List[float], b: List[float]) -> float:
    va = np.array(a, dtype=float); vb = np.array(b, dtype=float)
    na = np.linalg.norm(va); nb = np.linalg.norm(vb)
    return float(np.dot(va, vb) / (na * nb)) if na > 0 and nb > 0 else 0.0

def _search_similarity_max(vs: Any, embeddings: HuggingFaceEmbeddings, question: str, k: int = 20) -> float:
    retriever = vs.as_retriever(search_type="similarity", search_kwargs={"k": k})
    docs = retriever.invoke(question) or []
    if not docs:
        return 0.0
    qvec = embeddings.embed_query(question)
    dvecs = embeddings.embed_documents([d.page_content for d in docs])
    return max((_cosine(qvec, dv) for dv in dvecs), default=0.0)

def evaluate_goldenset(app, csv_path: str, threshold: float = 0.75, out_path: str = "evaluation_report.json") -> None:
    # âœ… í‰ê°€ ëª¨ë“œ ì‹œì‘ ì‹œ: í•­ìƒ ìƒˆ ë¡œê·¸ íŒŒì¼ë¡œ êµì²´
    new_log = _force_new_log_file()
    print(f"[LOG] í‰ê°€ìš© ì‹ ê·œ ë¡œê·¸ íŒŒì¼: {os.path.basename(new_log)}")

    # 1) ë°ì´í„° ë¡œë“œ(+ìŠ¤í‚¤ë§ˆ ë³´ì •)
    raw = _read_csv_any(csv_path)
    df = _ensure_qa_columns(raw)

    # (ì˜µì…˜) í‰ê°€ ìƒ˜í”Œ ì œí•œ: .envì— EVAL_SAMPLE_LIMIT=5 â†’ ìƒìœ„ Nê°œë§Œ í‰ê°€
    try:
        sample_limit = int(os.getenv("EVAL_SAMPLE_LIMIT", "0"))
    except ValueError:
        sample_limit = 0

    original_total = len(df)
    if sample_limit > 0 and sample_limit < original_total:
        df = df.head(sample_limit)

    rows = df.to_dict("records")
    total = len(rows)

    print("\n=== ê³¨ë“ ì…‹ í‰ê°€ ì‹œì‘ ===")
    if sample_limit > 0:
        print(f"íŒŒì¼: {csv_path} | ìƒ˜í”Œ ìˆ˜: {total} (ì›ë³¸ {original_total}, ì œí•œ {sample_limit}) | ì„ê³„ê°’: {threshold}\n")
    else:
        print(f"íŒŒì¼: {csv_path} | ìƒ˜í”Œ ìˆ˜: {total} | ì„ê³„ê°’: {threshold}\n")

    # 2) í‰ê°€ ì„ë² ë”© ë¡œë” + ë²¡í„°ìŠ¤í† ì–´
    eval_emb = HuggingFaceEmbeddings(model_name=EMBED_MODEL_NAME)
    try:
        vs = load_vectorstore(VECTOR_DB_PATH)
    except Exception as e:
        print(f"âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨ â†’ ê²€ìƒ‰ ìœ ì‚¬ë„ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì›ì¸: {e}")
        vs = None

    # 3) ë£¨í”„
    results, correct = [], 0
    for i, row in enumerate(rows, start=1):
        q = str(row["question"])
        g = str(row["answer"])
        try:
            state = app.invoke({"question": q})
            a = state.get("answer", "")
        except Exception as e:
            print(f"[{i}/{total}] âŒ ê·¸ë˜í”„ ì˜¤ë¥˜: {e}")
            state = {}
            a = ""

        # ì»¨í…ìŠ¤íŠ¸(ì›ë¬¸ RAW) & ì†ŒìŠ¤ ëª©ë¡
        raw_ctx = state.get("context", "") if isinstance(state, dict) else ""
        srcs = state.get("sources") or []

        # --- ì½˜ì†” ì¶œë ¥ ---
        print(f"[{i}/{total}] â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"ê³¨ë“ ì…‹ Q: {q}")
        print(f"ê³¨ë“ ì…‹ ë‹µë³€ A: {g}")
        print(f"LLM ë‹µë³€: {a}\n")

        print("--- â¬‡ LLMì— ì „ë‹¬ëœ ì»¨í…ìŠ¤íŠ¸(ì›ë¬¸ RAW, ì „ì²´) â¬‡ ---")
        print(raw_ctx if raw_ctx else "(ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)")
        print("--- â¬† ì»¨í…ìŠ¤íŠ¸ ë â¬† ---\n")

        # ì°¸ê³  ì†ŒìŠ¤ DataFrame(ë²ˆí˜¸/íŒŒì¼ëª…)
        src_df = _sources_to_dataframe(srcs)
        if not src_df.empty:
            print("=== ì°¸ê³  ì†ŒìŠ¤(ë²ˆí˜¸/íŒŒì¼ëª…) ===")
            print(src_df.to_string(index=False))
            print()

        # --- íŒŒì¼ ë¡œê·¸ ì €ì¥ (í‰ê°€ ëª¨ë“œë„ ìƒˆ íŒŒì¼ì— ëˆ„ì  ê¸°ë¡) ---
        _append_used_context_log(index=i, question=q, golden_answer=g, generated_answer=a, context_raw=raw_ctx, sources=srcs)

        # ìœ ì‚¬ë„(ê³¨ë“ â†”ìƒì„±)
        try:
            g_vec = eval_emb.embed_query(g)
            a_vec = eval_emb.embed_query(a)
            ans_sim = _cosine(g_vec, a_vec)
        except Exception as e:
            print(f"[{i}/{total}] âŒ ì„ë² ë”© ì˜¤ë¥˜: {e}")
            ans_sim = 0.0

        # ê²€ìƒ‰ ìœ ì‚¬ë„(ì˜µì…˜)
        if vs is not None:
            srch_sim = _search_similarity_max(vs, eval_emb, q, k=20)
        else:
            srch_sim = 0.0

        ok = bool(ans_sim >= threshold)
        correct += int(ok)

        print(f"í‰ê°€ê²°ê³¼: {'âœ…' if ok else 'âŒ'}  sim={ans_sim:.4f}  search_sim_max={srch_sim:.4f}\n")

        results.append({
            "index": i,
            "question": q,
            "golden_answer": g,
            "generated_answer": a,
            "answer_similarity": float(ans_sim),
            "search_similarity_max": float(srch_sim),
            "is_correct": ok
        })

    acc = (correct / total) * 100 if total else 0.0
    print("=== í‰ê°€ ì™„ë£Œ ===")
    print(f"ì •ë‹µ ìˆ˜: {correct}/{total}  ì •í™•ë„: {acc:.2f}%")

    # 4) JSON ì €ì¥
    report = {
        "summary": {
            "original_total": int(original_total),
            "total": int(total),
            "correct": int(correct),
            "accuracy": round(acc, 2),
            "threshold": threshold,
            "embedding_model": EMBED_MODEL_NAME,
            "sample_limit": int(sample_limit),
        },
        "details": results,
    }
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    print(f"ê²°ê³¼ ì €ì¥: {os.path.abspath(out_path)}")

# =======================
# ì±„íŒ… ëª¨ë“œ (ê³¨ë“ ì…‹ ì •ë³´ ë¹„ë…¸ì¶œ)
# =======================
def chat(app) -> None:
    """
    ì½˜ì†” ì±„íŒ…:
    - ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ â†’ LLM ë‹µë³€ ì¶œë ¥
    - LLMì´ ì°¸ê³ í•œ ì»¨í…ìŠ¤íŠ¸(ì›ë¬¸ RAW, ì „ì²´)ì™€ ì°¸ê³  ì†ŒìŠ¤(ë²ˆí˜¸/íŒŒì¼ëª…) í‘œì‹œ
    - used_context_log.txtì— ë™ì¼ í¬ë§·ìœ¼ë¡œ ì €ì¥ (ê³¨ë“ ì…‹ ì •ë³´ ë¹„ê¸°ë¡)
    ì¢…ë£Œ: ë¹ˆ ì¤„ ì…ë ¥ ë˜ëŠ” 'exit'/'quit'
    """
    print("\n=== ì±„íŒ… ëª¨ë“œ ì‹œì‘ ===")
    # âœ… ì±„íŒ… ëª¨ë“œ: ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ì„ ì„ íƒí•´ ê³„ì† ëˆ„ì í•  ìˆ˜ ìˆê²Œ ì•ˆë‚´
    files = list_log_files()
    if files:
        print("\n[ë¡œê·¸] ê¸°ì¡´ íŒŒì¼ ëª©ë¡ (ìµœì‹ ìˆœ, ì¸ë±ìŠ¤ ì„ íƒ ê°€ëŠ¥):")
        for i, name in enumerate(files):
            print(f"  {i}: {name}")
        sel = input("ê¸°ì¡´ ë¡œê·¸ ì‚¬ìš©? ì¸ë±ìŠ¤ ì…ë ¥(ì—”í„°=ìƒˆ íŒŒì¼): ").strip()
        if sel:
            try:
                choose_log_file(int(sel))
                print(f"[ë¡œê·¸] í™œì„± íŒŒì¼: {get_active_log_file()}")
            except Exception as e:
                print(f"[ë¡œê·¸] ì„ íƒ ì‹¤íŒ¨ â†’ ìƒˆ íŒŒì¼ ì‚¬ìš©: {e}")
                _force_new_log_file()
                print(f"[ë¡œê·¸] í™œì„± íŒŒì¼: {get_active_log_file()}")
        else:
            _force_new_log_file()
            print(f"[ë¡œê·¸] ì‹ ê·œ íŒŒì¼ ìƒì„±: {get_active_log_file()}")
    else:
        _force_new_log_file()
        print(f"[ë¡œê·¸] ì‹ ê·œ íŒŒì¼ ìƒì„±: {get_active_log_file()}")

    print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. (ì¢…ë£Œ: ë¹ˆ ì¤„ ë˜ëŠ” exit/quit)\n")
    turn = 1
    while True:
        try:
            q = input("ì§ˆë¬¸> ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\n[ì±„íŒ… ì¢…ë£Œ]")
            break

        if not q or q.lower() in {"exit", "quit"}:
            print("[ì±„íŒ… ì¢…ë£Œ]")
            break

        try:
            state = app.invoke({"question": q})
            a = state.get("answer", "")
            raw_ctx = state.get("context", "") if isinstance(state, dict) else ""
            srcs = state.get("sources") or []

            print("ë‹µë³€:")
            if a:
                for paragraph in a.strip().split("\n"):
                    if paragraph.strip():
                        print(f"\n{paragraph.strip()}")
            else:
                print("(ë‹µë³€ ì—†ìŒ)")
            print("\n--- â¬‡ LLMì— ì „ë‹¬ëœ ì»¨í…ìŠ¤íŠ¸(ì›ë¬¸ RAW, ì „ì²´) â¬‡ ---")
            print(raw_ctx if raw_ctx else "(ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ)")
            print("--- â¬† ì»¨í…ìŠ¤íŠ¸ ë â¬† ---\n")

            # ì°¸ê³  ì†ŒìŠ¤ DataFrame(ë²ˆí˜¸/íŒŒì¼ëª…)
            src_df = _sources_to_dataframe(srcs)
            if not src_df.empty:
                print("=== ì°¸ê³  ì†ŒìŠ¤(ë²ˆí˜¸/íŒŒì¼ëª…) ===")
                print(src_df.to_string(index=False))
                print()

            # âœ… ì±„íŒ… ëª¨ë“œë§Œ ë¡œê·¸ ëˆ„ì  ê¸°ë¡ (ìë™ ë¡¤ë§ í¬í•¨)
            _append_used_context_log(index=f"chat-{turn}", question=q, generated_answer=a, context_raw=raw_ctx, sources=srcs)
            turn += 1
        except Exception as e:
            print(f"[ì˜¤ë¥˜] {e}")

# =======================
# ë©”ì¸
# =======================
def main():
    print("==== ëª¨ë“œ ì„ íƒ ====")
    print("1) ì±„íŒ…")
    print("2) í‰ê°€")
    choice = input("ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” [1/2]: ").strip()

    app = build_graph()

    if choice == "1":
        chat(app)
    elif choice == "2":
        print(f"[RUN] ê³¨ë“ ì…‹ CSV: {GOLDENì…‹_CSV}")
        evaluate_goldenset(app, csv_path=GOLDENì…‹_CSV, threshold=SIM_THRESHOLD, out_path="evaluation_report.json")
    else:
        print("ì˜¬ë°”ë¥´ì§€ ì•Šì€ ì„ íƒì…ë‹ˆë‹¤. ê¸°ë³¸ê°’(í‰ê°€)ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        print(f"[RUN] ê³¨ë“ ì…‹ CSV: {GOLDENì…‹_CSV}")
        evaluate_goldenset(app, csv_path=GOLDENì…‹_CSV, threshold=SIM_THRESHOLD, out_path="evaluation_report.json")

if __name__ == "__main__":
    # ë³€ìˆ˜ëª… ì˜¤íƒ€ ë°©ì§€: ìœ„ main()ì—ì„œ ì‚¬ìš©í•  ìƒìˆ˜ ì´ë¦„ êµì •
    GOLDENì…‹_CSV = GOLDENSET_CSV
    main()
