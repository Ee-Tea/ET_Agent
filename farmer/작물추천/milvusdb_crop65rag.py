# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì„í¬íŠ¸ ì„¹ì…˜: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ëª¨ë“ˆì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import os  # íŒŒì¼ ê²½ë¡œ, í™˜ê²½ ë³€ìˆ˜ ë“± ìš´ì˜ì²´ì œ ê¸°ëŠ¥ì— ì ‘ê·¼
import sys  # ì§„í–‰ë¥  ì¶œë ¥ìš©
import time  # ETA ê³„ì‚°ìš©
import math  # ì‹œê°„ í¬ë§· ë“±ì— ì‚¬ìš©
from typing import TypedDict, Optional, List
from pathlib import Path  # íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œë¥¼ ê°ì²´ì§€í–¥ì ìœ¼ë¡œ ë‹¤ë£¨ê¸° ìœ„í•´ ì‚¬ìš©
from dotenv import load_dotenv, find_dotenv  # .env ë¡œë”
from collections import defaultdict  # âœ¨ íŒŒì¼ë³„ë¡œ ë¬¸ì„œë¥¼ ê·¸ë£¹í™”í•˜ê¸° ìœ„í•´ ì‚¬ìš©í•©ë‹ˆë‹¤.

# LangChainê³¼ ê´€ë ¨ëœ í´ë˜ìŠ¤ë“¤ì„ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from langchain_community.document_loaders import TextLoader, PyPDFLoader  # íŒŒì¼ ë¡œë”
from langchain_text_splitters import RecursiveCharacterTextSplitter  # í…ìŠ¤íŠ¸ ë¶„í• ê¸°
from langchain_huggingface import HuggingFaceEmbeddings  # ì„ë² ë”© ëª¨ë¸
from langchain_community.vectorstores import Milvus  # Milvus ë²¡í„°ìŠ¤í† ì–´
from langchain_core.documents import Document  # ë¬¸ì„œ êµ¬ì¡°

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv(find_dotenv())

# Milvus / Embedding ì„¤ì •
MILVUS_URI = os.getenv("MILVUS_URI", "http://localhost:19530")
MILVUS_TOKEN = os.getenv("MILVUS_TOKEN", "root:milvus")
MILVUS_COLLECTION = os.getenv("MILVUS_COLLECTION", "test")
EMBED_MODEL_NAME = os.getenv("EMBED_MODEL_NAME", "jhgan/ko-sroberta-multitask")

# ì…ë ¥ ë¬¸ì„œ í´ë”
DOCS_DIR = Path(os.getenv("DOCS_DIR", r"C:\Rookies_project\cropinfo"))
DOCS_DIR.mkdir(parents=True, exist_ok=True)

# ì²­í¬/ì„ë² ë”© íŒŒë¼ë¯¸í„°
CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", "800"))
CHUNK_OVERLAP = int(os.getenv("CHUNK_OVERLAP", "120"))

# âœ¨ ì„ë² ë”© ì§„í–‰ë¥  ì„¤ì •(í™˜ê²½ë³€ìˆ˜ë¡œ ì¡°ì • ê°€ëŠ¥)
EMBED_BATCH_SIZE = int(os.getenv("EMBED_BATCH_SIZE", "32"))
EMBED_PROGRESS_INTERVAL = float(os.getenv("EMBED_PROGRESS_INTERVAL", "0.2"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Embeddings
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
embedding_model = HuggingFaceEmbeddings(
    model_name=EMBED_MODEL_NAME,
    model_kwargs={"device": "cpu"}
)
EMBEDDING_DIM = len(embedding_model.embed_query("test"))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _format_eta(seconds: Optional[float]) -> str:
    if not seconds or seconds < 0 or math.isinf(seconds) or math.isnan(seconds):
        return "--:--"
    m, s = divmod(int(seconds), 60)
    if m >= 60:
        h, m = divmod(m, 60)
        return f"{h:02d}:{m:02d}:{s:02d}"
    return f"{m:02d}:{s:02d}"

def _render_progress(prefix: str, done: int, total: int, start_ts: float, task_name: Optional[str] = None) -> None:
    done = min(done, total)
    percent = int((done / total) * 100) if total else 100
    elapsed = time.time() - start_ts
    rate = (done / elapsed) if elapsed > 0 else None
    remain = ((total - done) / rate) if rate else None
    eta = _format_eta(remain)
    bar_len = 24
    filled = int(bar_len * percent / 100)
    bar = "â–ˆ" * filled + "â–‘" * (bar_len - filled)
    task_str = f"| {task_name}" if task_name else ""
    full_line = f"{prefix} [{bar}] {percent:3d}%  ({done}/{total})  ETA {eta}{task_str}"
    padded_line = full_line.ljust(120)

    sys.stdout.write(f"\r{padded_line}")
    sys.stdout.flush()
    
    if done >= total:
        sys.stdout.write("\n")
        
class ProgressEmbeddings:
    # âœ¨ __init__ ìƒì„±ìì—ì„œ total_textsì™€ task_nameì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.
    def __init__(self, base: HuggingFaceEmbeddings, batch_size: int = 32, desc: str = "ì„ë² ë”©"):
        self.base = base
        self.batch_size = max(1, batch_size)
        self.desc = desc
        # ì´ˆê¸°í™” ì‹œì—ëŠ” ë¹„ì›Œë‘ê±°ë‚˜ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.
        self.task_name = ""
        self.total_texts = 1
        self._last_print = 0.0

    # âœ¨ íŒŒì¼ ì •ë³´ë¥¼ ê°±ì‹ í•˜ëŠ” update_task ë©”ì„œë“œì…ë‹ˆë‹¤.
    def update_task(self, task_name: str, total_texts: int):
        """ì§„í–‰ë¥  í‘œì‹œì¤„ì— í‘œì‹œë  ì‘ì—… ì´ë¦„ê³¼ ì „ì²´ ê°œìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        self.task_name = task_name
        self.total_texts = max(total_texts, 1)
        self._last_print = 0.0

    def embed_query(self, text: str) -> List[float]:
        return self.base.embed_query(text)

    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        n = len(texts)
        # âœ¨ __init__ì´ ì•„ë‹Œ update_taskì—ì„œ ì„¤ì •ëœ ê°’ìœ¼ë¡œ totalì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        total = self.total_texts
        start_ts = time.time()
        results: List[List[float]] = []
        processed = 0

        task_str = f" ({self.task_name})" if self.task_name else ""
        print(f"ğŸ§® {self.desc}{task_str} ì‹œì‘: ì´ {total}ê°œ ì²­í¬ | ë°°ì¹˜ {self.batch_size}")

        for i in range(0, n, self.batch_size):
            batch = texts[i:i + self.batch_size]
            emb = self.base.embed_documents(batch)
            results.extend(emb)
            processed = min(i + len(batch), total)

            now = time.time()
            if now - self._last_print >= EMBED_PROGRESS_INTERVAL or processed == total:
                _render_progress(f"ğŸ”„ {self.desc}", processed, total, start_ts, task_name=self.task_name)
                self._last_print = now

        _render_progress(f"âœ… {self.desc}", total, total, start_ts, task_name=self.task_name)
        return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìƒíƒœ ì •ì˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class IngestState(TypedDict):
    docsPath: str
    files: List[str]
    rawDocs: List[Document]
    vectorstore: Optional[Milvus]
    inserted: int
    collectionName: str


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LangGraph ë…¸ë“œë“¤
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from langgraph.graph import StateGraph, END
from langchain_core.runnables.graph import MermaidDrawMethod
from pymilvus import connections, MilvusClient, DataType

def ensure_milvus_node(state: IngestState) -> IngestState:
    print("ğŸ§© ë…¸ë“œ: ensure_milvus (ì»¬ë ‰ì…˜ í™•ì¸)")

    if "default" in connections.list_connections():
        connections.disconnect("default")
    connections.connect(host="localhost", port="19530")

    client = MilvusClient(uri=MILVUS_URI, token=MILVUS_TOKEN)
    if client.has_collection(MILVUS_COLLECTION):
        print(f"  â†ª ê¸°ì¡´ ì»¬ë ‰ì…˜ '{MILVUS_COLLECTION}' ì‚­ì œ")
        client.drop_collection(MILVUS_COLLECTION)
    print(f"  â†ª Milvus ì—°ê²° ë° ì»¬ë ‰ì…˜ ì¤€ë¹„ ì™„ë£Œ.")
    return state  
    
def list_files_node(state: IngestState) -> IngestState:
    print("ğŸ§© ë…¸ë“œ: list_files")
    docs_path = Path(state["docsPath"])
    allow_ext = {".txt", ".md", ".pdf"}
    files = [str(p) for p in sorted(docs_path.rglob("*")) if p.is_file() and p.suffix.lower() in allow_ext]
    print(f"  â†ª ëŒ€ìƒ íŒŒì¼ {len(files)}ê°œ")
    if not files:
        print("  âš ï¸ 'ingest_docs' í´ë”ì— .txt/.md/.pdf íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
    return {**state, "files": files}


def load_and_ingest_node(state: IngestState) -> IngestState:
    print("ğŸ§© ë…¸ë“œ: load_and_ingest_node (ë¬¸ì„œ ë¡œë“œ & Milvusì— ì¸ì œìŠ¤íŠ¸)")
    all_docs: List[Document] = []
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        length_function=len,
    )

    # --- 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë”© & ì²­í¬ ë¶„í•  ---
    # (ì´ ë¶€ë¶„ì€ ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•©ë‹ˆë‹¤)
    files_to_process = state["files"]
    total_files = len(files_to_process)
    if total_files == 0:
        print(" Â âš ï¸ ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {**state, "inserted": 0, "rawDocs": [], "vectorstore": None}

    print(f"\n--- [ 1ë‹¨ê³„: ë¬¸ì„œ ë¡œë”© & ì²­í¬ ë¶„í•  ] ---")
    load_start_ts = time.time()
    completion_logs = []
    
    for i, fp in enumerate(files_to_process):
        path = Path(fp)
        _render_progress("ğŸ”„ ë¡œë“œ & ì²­í¬", i, total_files, load_start_ts, task_name=path.name)
        try:
            if path.suffix.lower() in [".txt", ".md"]:
                docs = TextLoader(str(path), autodetect_encoding=True).load()
            elif path.suffix.lower() == ".pdf":
                docs = PyPDFLoader(str(path)).load()
            else:
                continue

            chunks = text_splitter.split_documents(docs)
            all_docs.extend(chunks)
            completion_logs.append(f"  - {path.name} ë¡œë“œ ì™„ë£Œ ({len(chunks)}ê°œ ì²­í¬)")
        except Exception as e:
            completion_logs.append(f"  - {path.name} âŒ ë¡œë“œ ì˜¤ë¥˜")
            sys.stdout.write("\n")
            print(f" Â â””â”€ âŒ ì˜¤ë¥˜ ë°œìƒ: {path.name} | {e}")
            
    _render_progress("âœ… ë¡œë“œ & ì²­í¬", total_files, total_files, load_start_ts, task_name="ì™„ë£Œ")
    
    print("\n--- ê°œë³„ íŒŒì¼ ë¡œë“œ ê²°ê³¼ ---")
    for log_entry in completion_logs:
        print(log_entry)
    print("--------------------------\n")

    if not all_docs:
        print(" Â âš ï¸ ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return {**state, "inserted": 0, "rawDocs": [], "vectorstore": None}

    # --- 2ë‹¨ê³„: ì„ë² ë”© & DB ì‚½ì… ---
    print(f"--- [ 2ë‹¨ê³„: ì„ë² ë”© & DB ì‚½ì… ] ---")
    
    # ëª¨ë“  ì²­í¬ë¥¼ ì›ë³¸ íŒŒì¼ ì´ë¦„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•©ë‹ˆë‹¤. (ì´ ë¶€ë¶„ì€ ìˆ˜ì •í•  í•„ìš” ì—†ìŠµë‹ˆë‹¤)
    docs_by_source = defaultdict(list)
    for doc in all_docs:
        source_name = os.path.basename(doc.metadata.get("source", "unknown"))
        docs_by_source[source_name].append(doc)
    
    # âœ¨ 1. ë£¨í”„ ì‹œì‘ ì „ì— ProgressEmbeddings ê°ì²´ë¥¼ í•œ ë²ˆë§Œ ìƒì„±í•©ë‹ˆë‹¤.
    progress_embedder = ProgressEmbeddings(
        base=embedding_model,
        batch_size=EMBED_BATCH_SIZE,
        desc="ì„ë² ë”©"
    )

    vectorstore = None
    inserted_count = 0
    
    total_source_files = len(docs_by_source)
    processed_source_files = 0
    # íŒŒì¼ ê·¸ë£¹ë³„ë¡œ ìˆœíšŒí•˜ë©° ì„ë² ë”© ë° ì‚½ì… ì§„í–‰
    for source_name, doc_list in docs_by_source.items():
        processed_source_files += 1
        print(f"\n[{processed_source_files}/{total_source_files}] '{source_name}' íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...")
        try:
            # âœ¨ 2. ë£¨í”„ ì•ˆì—ì„œëŠ” ê°ì²´ì˜ ì •ë³´ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
            progress_embedder.update_task(
                task_name=source_name,
                total_texts=len(doc_list)
            )

            if vectorstore is None:
                # ì²˜ìŒì—ëŠ” vectorstoreë¥¼ ìƒì„±í•˜ë©´ì„œ progress_embedderë¥¼ ë“±ë¡í•©ë‹ˆë‹¤.
                vectorstore = Milvus.from_documents(
                    documents=doc_list,
                    embedding=progress_embedder,
                    collection_name=state["collectionName"],
                    connection_args={"host": "localhost", "port": "19530"}
                )
            else:
                # âœ¨ 3. ë‘ ë²ˆì§¸ íŒŒì¼ë¶€í„°ëŠ” embedding ì¸ìë¥¼ ë„˜ê¸°ì§€ ì•ŠìŠµë‹ˆë‹¤.
                # vectorstoreëŠ” ë‚´ë¶€ì— ì €ì¥ëœ progress_embedderë¥¼ ìë™ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
                vectorstore.add_documents(doc_list)
            
            inserted_count += len(doc_list)

        except Exception as e:
            print(f"âŒ '{source_name}' íŒŒì¼ ì„ë² ë”©/ì‚½ì… ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    print("\nâœ… ëª¨ë“  íŒŒì¼ì˜ ì„ë² ë”© ë° ë²¡í„°ìŠ¤í† ì–´ ì‚½ì… ì™„ë£Œ.")

    return {**state, "inserted": inserted_count, "rawDocs": all_docs, "vectorstore": vectorstore}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê·¸ë˜í”„ ë¹Œë“œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_graph():
    g = StateGraph(IngestState)
    g.add_node("ensure_milvus", ensure_milvus_node)
    g.add_node("list_files", list_files_node)
    g.add_node("load_and_ingest", load_and_ingest_node)

    g.set_entry_point("ensure_milvus")
    g.add_edge("ensure_milvus", "list_files")
    g.add_edge("list_files", "load_and_ingest")
    g.add_edge("load_and_ingest", END)

    return g.compile()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def main():
    print("ğŸš€ LangGraph ê¸°ë°˜ Milvus Ingest íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    agent_app = build_graph()

    try:
        graph_image_path = "milvus_agent_workflow_rag.png"
        png_bytes = agent_app.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)
        with open(graph_image_path, "wb") as f:
            f.write(png_bytes)
        print(f"\nâœ… LangGraph êµ¬ì¡°ê°€ '{graph_image_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ê·¸ë˜í”„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    initial_state: IngestState = {
        "docsPath": str(DOCS_DIR),
        "files": [],
        "rawDocs": [],
        "vectorstore": None,
        "inserted": 0,
        "collectionName": MILVUS_COLLECTION,
    }

    final_state = agent_app.invoke(initial_state)

    print("\nğŸ“¦ ê²°ê³¼ ìš”ì•½")
    print(f"  - ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜: {len(final_state['files'])}")
    print(f"  - Milvus ì»¬ë ‰ì…˜: {final_state['collectionName']}")
    print(f"  - ì‚½ì…ëœ ì²­í¬ ìˆ˜: {final_state['inserted']}")

if __name__ == "__main__":
    main()
