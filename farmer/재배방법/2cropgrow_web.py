import os
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional, TypedDict
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_groq import ChatGroq
from langgraph.graph import StateGraph, END
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.runnables.graph import MermaidDrawMethod

# --- 1. í™˜ê²½ ì„¤ì • ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
if not TAVILY_API_KEY:
    raise ValueError("TAVILY_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

print(f"OPENAI_API_KEY ë¡œë“œ ì™„ë£Œ: {OPENAI_API_KEY[:5]}...")
print(f"TAVILY_API_KEY ë¡œë“œ ì™„ë£Œ: {TAVILY_API_KEY[:5]}...")

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ ë° ë²¡í„° DB ì €ì¥ ê²½ë¡œ
CSV_FILE_PATH = 'data/ë†ë¦¼ìˆ˜ì‚°ì‹í’ˆêµìœ¡ë¬¸í™”ì •ë³´ì›_ì˜ë†ê°€ì´ë“œ ì¬ë°°ì •ë³´_20230911.csv'
VECTOR_DB_PATH = 'faiss_crop_guide_db'

if not os.path.exists('data'):
    os.makedirs('data')

# --- 2. LLM ë° í”„ë¡¬í”„íŠ¸ ì„¤ì • ---
llm = ChatGroq(model_name="llama3-70b-8192",
               temperature=0.3,
               api_key=OPENAI_API_KEY)

# ì§ˆë¬¸ ë¶„ë¥˜ë¥¼ ìœ„í•œ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸
CLASSIFY_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ 'ë†ì—… ë° ì‘ë¬¼ ì¬ë°° ë°©ë²•'ì— ê´€ë ¨ì´ ìˆëŠ”ì§€ ì—†ëŠ”ì§€ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ê·œì¹™ì— ë”°ë¼ ë‹µë³€í•˜ì„¸ìš”.
- ì§ˆë¬¸ì´ ë†ì—… ë˜ëŠ” ì‘ë¬¼ ì¬ë°°ì— ê´€ë ¨ì´ ìˆë‹¤ë©´, 'agriculture'ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.
- ê·¸ ì™¸ì˜ ëª¨ë“  ì¼ë°˜ì ì¸ ì§ˆë¬¸ì´ë¼ë©´, 'other'ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.
- ë‹µë³€ì€ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

ì§ˆë¬¸: {question}
ë‹µë³€:
"""
classify_prompt = ChatPromptTemplate.from_template(CLASSIFY_PROMPT_TEMPLATE)

# RAG í”„ë¡¬í”„íŠ¸ (ê¸°ì¡´ê³¼ ë™ì¼)
RAG_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë†ì—… ì‘ë¬¼ ì¬ë°° ë°©ë²• ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 

ë‹¤ìŒì€ ì‘ë¬¼ ì¬ë°°ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. ì œê³µëœ ë‹¤ìŒì˜ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.
{context}

ë‹¹ì‹ ì´ ì§€í‚¬ ê·œì¹™ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
- ì œê³µëœ ì •ë³´ì— ì—†ëŠ” ì •ë³´, ì €ì˜ ìƒì‹, ì¶”ì¸¡, ê±°ì§“ ì •ë³´, í•œì ë“±ì€ ì ˆëŒ€ ë‹µë³€ì— ë„£ì§€ ë§ˆì„¸ìš”.
- ëª¨ë“  ë‹µë³€ì€ í•œê¸€ë¡œë§Œ ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. í•œê¸€ì´ ì•„ë‹ˆë©´ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ê³ , í•œê¸€ë¡œë§Œ ë‹µë³€ì„ ì™„ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
- ê° ì¬ë°° ë‹¨ê³„ë‚˜ ì„¤ëª…ì€ ë°˜ë“œì‹œ "í•œ ë¬¸ì¥ì”© ì¤„ë°”ê¿ˆ"í•´ì„œ ì¨ì£¼ì„¸ìš”.
- ë‹µë³€ì´ ë¶ˆê°€ëŠ¥í•˜ê±°ë‚˜ ì œê³µëœ ì •ë³´ì— ê´€ë ¨ ì •ë³´ê°€ ì—†ìœ¼ë©´ "ì£¼ì–´ì§„ ì •ë³´ë¡œëŠ” ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³ ë§Œ ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.
- ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ë“¯, ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.

ì§ˆë¬¸: {question}
ë‹µë³€:
"""
rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT_TEMPLATE)

# ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ê¸° ìœ„í•œ ìƒˆë¡œìš´ í”„ë¡¬í”„íŠ¸
WEB_SEARCH_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë“¤ì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°€ì¥ ì •í™•í•˜ê³  ì™„ì „í•œ ë‹µë³€ì„ ì œê³µí•´ ì£¼ì„¸ìš”.

ë‹µë³€ ê·œì¹™
1. **ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ**: ì¹œê·¼í•˜ê³  ëª…í™•í•œ ë¬¸ì²´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
2. **ì •ë³´ì˜ ì¶œì²˜ ëª…ì‹œ**: ê²€ìƒ‰ ê²°ê³¼ì— ì œì‹œëœ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì„¸ìš”. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ê²€ìƒ‰ ê²°ê³¼ì— ì—†ë‹¤ë©´, 'ê²€ìƒ‰ ê²°ê³¼ì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ëª…í™•í•˜ê²Œ ë§í•´ì•¼ í•©ë‹ˆë‹¤.
3. **í•µì‹¬ ìš”ì•½ ë° ì •ë¦¬**: ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¤‘ë³µë˜ëŠ” í•µì‹¬ ë‚´ìš©ë“¤ì„ ì¢…í•©í•˜ì—¬ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
4. **êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ**: ë‹µë³€ì€ ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ì •ë³´(ì˜ˆ: ë‚ ì§œ, ìˆ«ì, ê¸°ê´€ëª… ë“±)ë¥¼ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ ì£¼ì„¸ìš”.
5. **í•œê¸€ë¡œë§Œ ë‹µë³€**: ëª¨ë“  ë‹µë³€ì€ í•œê¸€ë¡œë§Œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

ì§ˆë¬¸: {question}
ë‹µë³€:
"""
web_search_prompt = ChatPromptTemplate.from_template(WEB_SEARCH_PROMPT_TEMPLATE)

# Tavily ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„¤ì •
tavily_tool = TavilySearchResults(max_results=5, api_key = TAVILY_API_KEY)

# --- 3. LangGraph ìƒíƒœ ì •ì˜ ---
class GraphState(TypedDict):
    question: Optional[str]
    documents: Optional[List[Dict[str, Any]]]
    splits: Optional[List[Dict[str, Any]]]
    vectorstore: Optional[FAISS]
    context: Optional[str]
    answer: Optional[str]
    search_results: Optional[str]
    classification: Optional[str]

# --- 4. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ì •ì˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
def load_csv_data(file_path: str) -> List[Dict[str, Any]]:
    print("---ê¸°ëŠ¥: ë°ì´í„° ë¡œë“œ ì‹œì‘---")
    loader = CSVLoader(file_path=file_path, encoding='utf-8')
    documents = loader.load()
    print(f"ë¡œë“œëœ ë¬¸ì„œ ê°œìˆ˜: {len(documents)}ê°œ")
    return documents

def split_documents(documents: List[Dict[str, Any]], chunk_size: int = 1000, chunk_overlap: int = 200) -> List[Dict[str, Any]]:
    print("---ê¸°ëŠ¥: ë¬¸ì„œ ë¶„í•  ì‹œì‘---")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        length_function=len,
        is_separator_regex=False,
    )
    splits = text_splitter.split_documents(documents)
    print(f"ë¶„í• ëœ ì²­í¬ ê°œìˆ˜: {len(splits)}ê°œ")
    return splits

def embed_and_store_vector_db(splits: List[Dict[str, Any]], db_path: str) -> FAISS:
    print("---ê¸°ëŠ¥: ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥ ì‹œì‘---")
    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")

    if not os.path.exists(db_path):
        vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
        vectorstore.save_local(db_path)
        print(f"ë²¡í„° DBë¥¼ '{db_path}' ê²½ë¡œì— ìƒˆë¡œ ìƒì„± ë° ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    else:
        vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
        print(f"'{db_path}' ê²½ë¡œì—ì„œ ê¸°ì¡´ ë²¡í„° DBë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    return vectorstore

def retrieve_relevant_chunks(vectorstore: FAISS, question: str) -> str:
    print("---ê¸°ëŠ¥: ê´€ë ¨ ì²­í¬ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œì‘---")
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 5})
    docs = retriever.invoke(question)
    context = "\n\n".join([doc.page_content for doc in docs])
    print(f"ê²€ìƒ‰ëœ ì²­í¬ ìˆ˜: {len(docs)}ê°œ")
    return context

def generate_answer_with_llm(context: str, question: str, llm: ChatGroq, prompt_template: ChatPromptTemplate) -> str:
    print("---ê¸°ëŠ¥: ë‹µë³€ ìƒì„± ì‹œì‘---")
    rag_chain_internal = (
        {"context": RunnablePassthrough(), "question": RunnablePassthrough()}
        | prompt_template
        | llm
        | StrOutputParser()
    )
    inputs = {"context": context, "question": question}
    answer = rag_chain_internal.invoke(inputs)
    return answer

# --- 5. LangGraph ë…¸ë“œ í•¨ìˆ˜ ì •ì˜ ---
def load_data_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ë°ì´í„° ë¡œë“œ (Load Data) ì‹¤í–‰---")
    documents = load_csv_data(CSV_FILE_PATH)
    return {**state, "documents": documents}

def split_documents_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ë¬¸ì„œ ë¶„í•  (Split Documents) ì‹¤í–‰---")
    if "documents" not in state or not state["documents"]: 
        raise ValueError("ë¬¸ì„œ ë¶„í• ì„ ìœ„í•´ ë¡œë“œëœ ë¬¸ì„œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    splits = split_documents(state["documents"])
    return {**state, "splits": splits} 

def embed_and_store_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ì„ë² ë”© ë° ë²¡í„° DB ì €ì¥ (Embed & Store) ì‹¤í–‰---")
    if "splits" not in state or not state["splits"]:
        raise ValueError("ì„ë² ë”©ì„ ìœ„í•´ ë¶„í• ëœ ì²­í¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    vectorstore = embed_and_store_vector_db(state["splits"], VECTOR_DB_PATH)
    return {**state, "vectorstore": vectorstore}

def retrieve_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ê²€ìƒ‰ (Retrieve) ì‹¤í–‰---")
    if "vectorstore" not in state or not state["vectorstore"]:
        raise ValueError("ê²€ìƒ‰ì„ ìœ„í•´ ë²¡í„° DBê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    question = state["question"] 
    vectorstore = state["vectorstore"]
    context = retrieve_relevant_chunks(vectorstore, question)
    return {**state, "context": context}

def generate_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ìƒì„± (Generate) ì‹¤í–‰---")
    if ("context" not in state or not state["context"] or 
        "question" not in state or not state["question"]):
        raise ValueError("ë‹µë³€ ìƒì„±ì„ ìœ„í•´ ë¬¸ë§¥ê³¼ ì§ˆë¬¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    context = state["context"]
    question = state["question"]
    answer = generate_answer_with_llm(context, question, llm, rag_prompt)
    return {**state, "answer": answer}

def web_search_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ì›¹ ê²€ìƒ‰ (Web Search) ì‹¤í–‰---")
    question = state["question"]
    
    # 1. Tavily ê²€ìƒ‰ ì‹¤í–‰
    search_results = tavily_tool.invoke({"query": question})
    search_results_str = "\n".join([str(res) for res in search_results])

    # 2. ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¼ì • í¬ê¸°ë¡œ ì˜ë¼ëƒ„ (í† í° ì œí•œ íšŒí”¼)
    # 2000ìëŠ” ì•½ 500~700 í† í°ì— í•´ë‹¹í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬ ê°€ëŠ¥
    truncated_search_results = search_results_str[:2000]
    print(f"ê²€ìƒ‰ ê²°ê³¼ë¥¼ {len(truncated_search_results)}ìë¡œ ì˜ë¼ëƒ„.")
    print(f"ì˜ë¦° ê²€ìƒ‰ ê²°ê³¼: {truncated_search_results[:100]}...")
    
    # 3. ì˜ë¦° ê²€ìƒ‰ ê²°ê³¼ë¡œ ë‹µë³€ ìƒì„±
    web_answer = generate_answer_with_llm(truncated_search_results, question, llm, web_search_prompt)
    
    return {**state, "answer": web_answer}

def classify_question_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ì§ˆë¬¸ ë¶„ë¥˜ (Classify Question) ì‹¤í–‰---")
    question = state["question"]
    chain = classify_prompt | llm | StrOutputParser()
    classification = chain.invoke({"question": question})
    print(f"ë¶„ë¥˜ ê²°ê³¼: '{classification.strip()}'")
    return {**state, "classification": classification.strip()}

# --- 6. LangGraph ì›Œí¬í”Œë¡œìš° ë¹Œë“œ ë° ì»´íŒŒì¼ ---
def build_initial_setup_graph():
    """ì´ˆê¸° ë¬¸ì„œ ë¡œë”© ë° ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•ì„ ìœ„í•œ ê·¸ë˜í”„ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤."""
    print("ğŸ“š ì´ˆê¸° ì„¤ì •(ë¬¸ì„œ ë¡œë”© ë° ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•) íë¦„ êµ¬ì„± ì¤‘...")
    initial_builder = StateGraph(GraphState)
    initial_builder.add_node("load_data", load_data_node)
    initial_builder.add_node("split_documents", split_documents_node)
    initial_builder.add_node("embed_and_store", embed_and_store_node)
    initial_builder.set_entry_point("load_data")
    initial_builder.add_edge("load_data", "split_documents")
    initial_builder.add_edge("split_documents", "embed_and_store")
    initial_builder.add_edge("embed_and_store", END)
    return initial_builder.compile()

def build_query_graph():
    """ì§ˆë¬¸ ë¶„ë¥˜, RAG, ì›¹ ê²€ìƒ‰ì„ í†µí•©í•œ ë©”ì¸ ì§ˆì˜ ê·¸ë˜í”„ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤."""
    print("ğŸ“š ë©”ì¸ ì§ˆì˜ íë¦„ êµ¬ì„± ì¤‘...")
    query_builder = StateGraph(GraphState)
    
    # ë…¸ë“œ ì¶”ê°€
    query_builder.add_node("classify_question", classify_question_node)
    query_builder.add_node("retrieve", retrieve_node)
    query_builder.add_node("generate", generate_node)
    query_builder.add_node("web_search", web_search_node)
    
    # ì‹œì‘ì  ì„¤ì •
    query_builder.set_entry_point("classify_question")
    
    # **ë³€ê²½ë¨**: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¼ ë¼ìš°íŒ… ë¡œì§ì„ ë³€ê²½í•©ë‹ˆë‹¤.
    def route_classification(state: GraphState):
        if state.get("classification") == "agriculture":
            # ë†ì—… ê´€ë ¨ ì§ˆë¬¸ -> RAGë¡œ ë°”ë¡œ ì´ë™
            return "agriculture"
        else:
            # ê¸°íƒ€ ì§ˆë¬¸ -> ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ë°”ë¡œ ì´ë™
            return "other"
            
    query_builder.add_conditional_edges(
        "classify_question",
        route_classification,
        {
            "agriculture": "retrieve",
            "other": "web_search"
        }
    )
    
    # **ë³€ê²½ë¨**: RAG íŒŒì´í”„ë¼ì¸ ì´í›„ ë¬´ì¡°ê±´ ì¢…ë£Œí•˜ë„ë¡ ë³€ê²½ (ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜í•˜ì§€ ì•ŠìŒ)
    query_builder.add_edge("retrieve", "generate")
    query_builder.add_edge("generate", END)
    
    # ì›¹ ê²€ìƒ‰ í›„ ì¢…ë£Œ
    query_builder.add_edge("web_search", END)
    
    return query_builder.compile()

# --- 7. ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„ ---
if __name__ == "__main__":
    print("\n---ë†ì‘ë¬¼ ì±—ë´‡ ì—ì´ì „íŠ¸ ì‹œì‘ (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit' ì…ë ¥)---")

    # 1. ì´ˆê¸° ì„¤ì •: ë°ì´í„° ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶• (í•œ ë²ˆë§Œ ì‹¤í–‰)
    setup_graph = build_initial_setup_graph()
    initial_state = {"question": "setup"}
    setup_result = setup_graph.invoke(initial_state)
    vectorstore = setup_result.get("vectorstore")

    # 2. ë©”ì¸ ì§ˆì˜ ê·¸ë˜í”„ ì¤€ë¹„ (ë²¡í„°ìŠ¤í† ì–´ ì£¼ì…)
    app = build_query_graph()

    # ê·¸ë˜í”„ ì‹œê°í™” ë° ì €ì¥
    graph_image_path = "agent_workflow.png"
    try:
        graph_data = app.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)
        with open(graph_image_path, "wb") as f:
            f.write(graph_data)
        print(f"\nâœ… LangGraph êµ¬ì¡°ê°€ '{graph_image_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"ê·¸ë˜í”„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("Graphviz ì„¤ì¹˜ ë° ì‹œìŠ¤í…œ PATH ì„¤ì •ì„ í™•ì¸í•˜ê±°ë‚˜, ì¸í„°ë„· ì—°ê²° ìƒíƒœë¥¼ ì ê²€í•´ì£¼ì„¸ìš”.")

    while True:
        user_question = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        if user_question.lower() in ["exit", "quit"]:
            print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not user_question.strip():
            print("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue

        try:
            # ë²¡í„°ìŠ¤í† ì–´ë¥¼ stateì— í•¨ê»˜ ì „ë‹¬í•©ë‹ˆë‹¤.
            final_state = app.invoke({"question": user_question, "vectorstore": vectorstore})
            print("\n---ì±—ë´‡ ë‹µë³€---")
            print(final_state['answer'])

        except Exception as e:
            print(f"\nì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    print("\n---ë†ì‘ë¬¼ ì±—ë´‡ ì—ì´ì „íŠ¸ ì¢…ë£Œ---")