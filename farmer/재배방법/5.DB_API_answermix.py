import os
import re
import requests
import xml.etree.ElementTree as ET
import pandas as pd
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional, TypedDict

# Langchain ë° LangGraph ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_groq import ChatGroq
from langgraph.graph import StateGraph, END
from langchain_community.tools.tavily_search import TavilySearchResults

# --- 1. í™˜ê²½ ì„¤ì • ---
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY")
PESTICIDE_API_KEY = os.getenv("PESTICIDE_API_KEY")

# API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ê²½ê³  ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ê³  ì¢…ë£Œí•©ë‹ˆë‹¤.
if not OPENAI_API_KEY:
    print("ì˜¤ë¥˜: OPENAI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()
if not TAVILY_API_KEY:
    print("ì˜¤ë¥˜: TAVILY_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()
if not PESTICIDE_API_KEY:
    print("ì˜¤ë¥˜: PESTICIDE_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

# í†µí•©í•  ê°œë³„ ë²¡í„° DB ì €ì¥ ê²½ë¡œë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
DATA_DB_CONFIG = {
    "cultivation": "faiss_crop_guide_db",
    "fertilizer": "faiss_crop_fer_db",
    "pest_disease": "faiss_crop_pest_db",
}

# --- 2. LLM ë° í”„ë¡¬í”„íŠ¸ ì„¤ì • ---
llm = ChatGroq(model_name="llama3-70b-8192",
               temperature=0.7,
               api_key=OPENAI_API_KEY)

llm_keyword = ChatGroq(model_name="llama3-8b-8192",
                       temperature=0.0,
                       api_key=OPENAI_API_KEY)

# ì§ˆë¬¸ ë¶„ë¥˜ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸
CLASSIFY_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ ì–´ë–¤ ì£¼ì œì— ê´€í•œ ê²ƒì¸ì§€ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ê·œì¹™ì— ë”°ë¼ ë‹µë³€í•˜ì„¸ìš”.
- ì§ˆë¬¸ì´ 'ë†ì•½'ì— ê´€ë ¨ì´ ìˆë‹¤ë©´, 'pesticide'ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.
- ì§ˆë¬¸ì´ ë†ì—…(ë†ì‘ë¬¼ ì¬ë°°, ë¹„ë£Œ, ë³‘í•´ì¶© ë“±)ì— ê´€ë ¨ì´ ìˆë‹¤ë©´, 'agriculture'ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.
- ê·¸ ì™¸ì˜ ëª¨ë“  ì¼ë°˜ì ì¸ ì§ˆë¬¸ì´ë¼ë©´, 'other'ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.
- ë‹µë³€ì€ í•œ ë‹¨ì–´ë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

ì§ˆë¬¸: {question}
ë‹µë³€:
"""
classify_prompt = ChatPromptTemplate.from_template(CLASSIFY_PROMPT_TEMPLATE)

# RAG í”„ë¡¬í”„íŠ¸
RAG_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë†ì—… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë‹¤ìŒì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ê¸° ìœ„í•´ ìˆ˜ì§‘ëœ ì •ë³´ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ ì£¼ì„¸ìš”.
---
{context}
---

ë‹¹ì‹ ì´ ì§€ì¼œì•¼ í•  ê·œì¹™ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
1.  **ì •ë³´ì˜ ìš°ì„ ìˆœìœ„**:
    * ë§Œì•½ APIì—ì„œ ì œê³µëœ ë†ì•½ ì •ë³´ê°€ ìˆë‹¤ë©´, ë°˜ë“œì‹œ ê·¸ ì •ë³´ë¥¼ ë‹µë³€ì— ìš°ì„ ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
    * ë‚´ë¶€ DB ì •ë³´ëŠ” API ì •ë³´ê°€ ì—†ì„ ë•Œë§Œ ì‚¬ìš©í•˜ê±°ë‚˜, API ì •ë³´ë¥¼ ë³´ì¶©í•˜ëŠ” ìš©ë„ë¡œë§Œ í™œìš©í•˜ì„¸ìš”.
    * APIì—ì„œ ì°¾ì€ ì •ë³´ì™€ ë‚´ë¶€ DB ì •ë³´ê°€ ì„œë¡œ ë‹¤ë¥¼ ê²½ìš°, **ë¬´ì¡°ê±´ API ì •ë³´ë¥¼ ë”°ë¥´ì„¸ìš”.**
2.  **êµ¬ì²´ì ì¸ ì •ë³´ ì œê³µ**:
    * ë†ì•½ ì •ë³´ì— ëŒ€í•´ì„œëŠ” ìƒí‘œëª…, í¬ì„ë°°ìˆ˜, ì•ˆì „ì‚¬ìš©ê¸°ì¤€(ìˆ˜í™• ì „ ì¼ìˆ˜, íšŸìˆ˜)ì„ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.
    * ë°­ ì´ë‘ ê°„ê²©ì— ëŒ€í•œ ì •ë³´ê°€ ìˆë‹¤ë©´, 'ë‘ ì¤„ ì´ë‘'ê³¼ 'í•œ ì¤„ ì´ë‘'ì˜ êµ¬ì²´ì ì¸ ë‘ë‘‘ ë„“ì´, ê³ ë‘ ê°„ê²©ì„ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•´ì„œ ì„¤ëª…í•˜ì„¸ìš”.
3.  **ì •í™•ì„± ë° ì¶œì²˜ ì¤€ìˆ˜**:
    * ì œê³µëœ ì •ë³´ì— ì—†ëŠ” ë‚´ìš©, ìƒì‹, ì¶”ì¸¡, ê±°ì§“ ì •ë³´ëŠ” ì ˆëŒ€ ë‹µë³€ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
    * ë‹µë³€ì´ ë¶ˆê°€ëŠ¥í•˜ê±°ë‚˜ ê´€ë ¨ ì •ë³´ê°€ ì—†ë‹¤ë©´ "ì£¼ì–´ì§„ ì •ë³´ë¡œëŠ” ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³ ë§Œ ë‹µë³€í•˜ì„¸ìš”.
4.  **ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•œ ë‹µë³€**:
    * ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì²´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
    * ê° ì¬ë°° ë‹¨ê³„ë‚˜ ì„¤ëª…ì€ "í•œ ë¬¸ì¥ì”© ì¤„ë°”ê¿ˆ"í•´ì„œ ì¨ì£¼ì„¸ìš”.
    * ëª¨ë“  ë‹µë³€ì€ í•œê¸€ë¡œë§Œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ì§ˆë¬¸: {question}
ë‹µë³€:
"""
rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT_TEMPLATE)

# ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸
WEB_SEARCH_PROMPT_TEMPLATE = """
ë‹¹ì‹ ì€ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê²€ìƒ‰ ê²°ê³¼ë“¤ì„ í™œìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°€ì¥ ì •í™•í•˜ê³  ì™„ì „í•œ ë‹µë³€ì„ ì œê³µí•´ ì£¼ì„¸ìš”.

ë‹µë³€ ê·œì¹™
1. **ì¹œì ˆí•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ**: ì¹œê·¼í•˜ê³  ëª…í™•í•œ ë¬¸ì²´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
2. **ì •ë³´ì˜ ì¶œì²˜ ëª…ì‹œ**: ê²€ìƒ‰ ê²°ê³¼ì— ì œì‹œëœ ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì„¸ìš”. ë§Œì•½ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ê²€ìƒ‰ ê²°ê³¼ì— ì—†ë‹¤ë©´, 'ê²€ìƒ‰ ê²°ê³¼ì— í•´ë‹¹ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ëª…í™•í•˜ê²Œ ë§í•´ì•¼ í•©ë‹ˆë‹¤.
3. **í•µì‹¬ ìš”ì•½ ë° ì •ë¦¬**: ì—¬ëŸ¬ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¤‘ë³µë˜ëŠ” í•µì‹¬ ë‚´ìš©ë“¤ì„ ì¢…í•©í•˜ì—¬ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
4. **êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ**: ë‹µë³€ì€ ê°€ëŠ¥í•œ í•œ êµ¬ì²´ì ì¸ ì •ë³´(ì˜ˆ: ë‚ ì§œ, ìˆ«ì, ê¸°ê´€ëª… ë“±)ë¥¼ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ ì£¼ì„¸ìš”.
5. **í•œê¸€ë¡œë§Œ ë‹µë³€**: ëª¨ë“  ë‹µë³€ì€ í•œê¸€ë¡œë§Œ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

ì§ˆë¬¸: {question}
ë‹µë³€:
"""
web_search_prompt = ChatPromptTemplate.from_template(WEB_SEARCH_PROMPT_TEMPLATE)

# í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸
KEYWORD_EXTRACT_PROMPT = ChatPromptTemplate.from_template(
    "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì—ì„œ ì‘ë¬¼ëª…, ë³‘í•´ì¶©ëª…ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì¶”ì¶œí•´. ë‹¤ë¥¸ ë§ì€ í•˜ì§€ë§ˆ.\nì§ˆë¬¸: {question}\ní‚¤ì›Œë“œ:"
)

tavily_tool = TavilySearchResults(max_results=5, api_key=TAVILY_API_KEY)

# --- 3. LangGraph ìƒíƒœ ì •ì˜ ---
class GraphState(TypedDict):
    question: Optional[str]
    vectorstore: Optional[FAISS]
    context: Optional[str]
    answer: Optional[str]
    classification: Optional[str]
    keywords: Optional[str]
    api_result: Optional[str]
    next_step: Optional[str]
    source_context: Optional[str]
    combined_context: Optional[str]

# --- 4. í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ì •ì˜ ---
def retrieve_relevant_chunks(vectorstore: FAISS, question: str) -> str:
    """ë²¡í„° DBì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë¬¸ë§¥ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
    retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 5})
    docs = retriever.invoke(question)
    context = "\n\n".join([doc.page_content for doc in docs])
    return context

def generate_answer_with_llm(context: str, question: str, llm: ChatGroq, prompt_template: ChatPromptTemplate) -> str:
    """LLMì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    rag_chain_internal = (
        {"context": RunnablePassthrough(), "question": RunnablePassthrough()}
        | prompt_template
        | llm
        | StrOutputParser()
    )
    inputs = {"context": context, "question": question}
    answer = rag_chain_internal.invoke(inputs)
    return answer

# ë†ì•½ API í˜¸ì¶œ í•¨ìˆ˜
def call_pesticide_api(crop_name: str = "", disease_name: str = ""):
    """ë†ì•½ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ë†ì•½ ì •ë³´ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
    BASE_URL = "https://psis.rda.go.kr/openApi/service.do"
    if not PESTICIDE_API_KEY:
        return pd.DataFrame()
    params = {
        "apiKey": PESTICIDE_API_KEY,
        "serviceCode": "SVC01",
        "serviceType": "AA001",
        "displayCount": 10,
        "startPoint": 1,
        "cropName": crop_name,
        "diseaseWeedName": disease_name,
        "similarFlag" : "Y",
    }
    try:
        res = requests.get(BASE_URL, params=params)
        res.raise_for_status()
        root = ET.fromstring(res.text)
        rows = []
        for item in root.findall(".//item"):
            rows.append({
                "ì‘ë¬¼ëª…": item.findtext("cropName"),
                "ë³‘í•´ì¶©": item.findtext("diseaseWeedName"),
                "ìš©ë„": item.findtext("useName"),
                "ìƒí‘œëª…": item.findtext("pestiBrandName"),
                "ì‚¬ìš©ë°©ë²•": item.findtext("pestiUse"),
                "í¬ì„ë°°ìˆ˜": item.findtext("dilutUnit"),
                "ì•ˆì „ì‚¬ìš©ê¸°ì¤€(ìˆ˜í™• ì¼ ì „)": item.findtext("useSuittime"),
                "ì•ˆì „ì‚¬ìš©ê¸°ì¤€(íšŒ ì´ë‚´)": item.findtext("useNum"),
            })
        df = pd.DataFrame(rows)
        return df
    except (requests.exceptions.RequestException, ET.ParseError) as e:
        print(f"API í˜¸ì¶œ ë˜ëŠ” XML íŒŒì‹± ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

# --- 5. LangGraph ë…¸ë“œ í•¨ìˆ˜ ì •ì˜ ---
def load_and_merge_dbs_node(state: GraphState) -> Dict[str, Any]:
    """ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê°œë³„ ë²¡í„° DBë¥¼ ë¡œë“œí•˜ì—¬ í•˜ë‚˜ë¡œ í†µí•©í•©ë‹ˆë‹¤."""
    print("\n---ë…¸ë“œ: ë²¡í„° DB ë¡œë“œ ë° í†µí•© ì‹¤í–‰---")
    embeddings = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask")
    all_dbs_exist = all(os.path.exists(path) for path in DATA_DB_CONFIG.values())

    if not all_dbs_exist:
        raise FileNotFoundError(
            "í•„ìš”í•œ ë²¡í„° DB í´ë” ì¤‘ í•˜ë‚˜ ì´ìƒì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. "
            "ë¨¼ì € ê°œë³„ DBë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: 'faiss_crop_guide_db')"
        )
    
    print("ê°œë³„ ë²¡í„° DBë¥¼ ë¡œë“œí•˜ì—¬ í†µí•© ì¤‘...")
    first_db_path = list(DATA_DB_CONFIG.values())[0]
    vectorstore = FAISS.load_local(first_db_path, embeddings, allow_dangerous_deserialization=True)

    for key, db_path in list(DATA_DB_CONFIG.items())[1:]:
        print(f"'{key}' DB ë³‘í•© ì¤‘...")
        other_vectorstore = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
        vectorstore.merge_from(other_vectorstore)
    
    print("í†µí•©ëœ ë²¡í„° DB ë¡œë“œ ì™„ë£Œ.\n")
    return {**state, "vectorstore": vectorstore}

def classify_question_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ì§ˆë¬¸ ë¶„ë¥˜ ì‹¤í–‰---")
    question = state["question"]
    chain = classify_prompt | llm | StrOutputParser()
    classification = chain.invoke({"question": question})
    classification_str = classification.strip()
    print(f"ì§ˆë¬¸ì´ '{classification_str}'ë¡œ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return {**state, "classification": classification_str}

def extract_and_retrieve_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: í‚¤ì›Œë“œ ì¶”ì¶œ ë° DB ê²€ìƒ‰ ì‹¤í–‰---")
    question = state["question"]
    vectorstore = state["vectorstore"]

    # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
    keyword_chain = KEYWORD_EXTRACT_PROMPT | llm_keyword | StrOutputParser()
    keywords = keyword_chain.invoke({"question": question})
    print(f"ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")

    # 2. í†µí•© DB ê²€ìƒ‰
    print("í†µí•© DBì—ì„œ ê´€ë ¨ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
    context = retrieve_relevant_chunks(vectorstore, question)

    return {**state, "keywords": keywords, "context": context}

def call_api_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: API í˜¸ì¶œ (Call API) ì‹¤í–‰---")
    keywords_str = state.get("keywords")
    api_result = "ì™¸ë¶€ APIì—ì„œ ì–»ì€ ì¶”ê°€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
    
    crop_name = ""
    disease_name = ""
    if keywords_str:
        # í‚¤ì›Œë“œ ë¬¸ìì—´ì„ ì‰¼í‘œë¡œ ë¶„í• í•˜ê³  ê³µë°± ì œê±°
        parsed_keywords = [k.strip() for k in keywords_str.split(',') if k.strip()]
        # ì²« ë²ˆì§¸ í‚¤ì›Œë“œë¥¼ ì‘ë¬¼ëª…ìœ¼ë¡œ, ë‘ ë²ˆì§¸ í‚¤ì›Œë“œë¥¼ ë³‘í•´ì¶©ëª…ìœ¼ë¡œ í• ë‹¹
        crop_name = parsed_keywords[0] if len(parsed_keywords) > 0 else ""
        disease_name = parsed_keywords[1] if len(parsed_keywords) > 1 else ""
    
    print(f"API í˜¸ì¶œì— ì‚¬ìš©ë  ì‘ë¬¼ëª…: {crop_name}, ë³‘í•´ì¶©ëª…: {disease_name}")
    
    # ì‘ë¬¼ëª…ê³¼ ë³‘í•´ì¶©ëª…ì´ ëª¨ë‘ ë¹„ì–´ìˆì§€ ì•Šì„ ê²½ìš°ì—ë§Œ API í˜¸ì¶œ
    if crop_name and disease_name:
        df = call_pesticide_api(crop_name=crop_name, disease_name=disease_name)
        if not df.empty:
            api_result = "ì™¸ë¶€ API ê²°ê³¼:\n" + df.to_string(index=False)
    
    print(f"API í˜¸ì¶œ ê²°ê³¼: \n{api_result[:500]}...")
    return {**state, "api_result": api_result}

def combine_and_check_for_web_search_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ì •ë³´ í†µí•© ë° ì›¹ ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ íŒë‹¨ ì‹¤í–‰---")
    question = state["question"]
    db_context = state.get("context", "")
    api_result = state.get("api_result", "")
    
    combined_context = ""
    source_context = ""
    
    # ë‚´ë¶€ DB ì •ë³´ê°€ ìˆì„ ê²½ìš°
    if db_context:
        combined_context += f"ë‚´ë¶€ DB ì •ë³´:\n{db_context}\n\n"
        source_context += f"**[ì°¸ê³  ìë£Œ - ë‚´ë¶€ DB]**\n{db_context}\n\n"
    
    # API ì •ë³´ê°€ ìˆì„ ê²½ìš°
    is_api_successful = "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in api_result and len(api_result.strip()) > 100
    if is_api_successful:
        combined_context += f"ì™¸ë¶€ API ì •ë³´:\n{api_result}\n\n"
        source_context += f"**[ì°¸ê³  ìë£Œ - ë†ì•½ API]**\n{api_result}\n\n"

    # API ê²°ê³¼ê°€ ì„±ê³µì ìœ¼ë¡œ ê²€ìƒ‰ë˜ì—ˆê±°ë‚˜, í†µí•©ëœ ì •ë³´ê°€ ì˜ë¯¸ìˆëŠ” ë‚´ìš©ì´ ìˆì„ ê²½ìš° ë‹µë³€ ìƒì„±
    if is_api_successful or len(combined_context.strip()) > 100:
        print("í†µí•© ì •ë³´ê°€ ì¶©ë¶„í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.")
        return {**state, "combined_context": combined_context, "source_context": source_context, "next_step": "generate"}
    else:
        print("í†µí•© ì •ë³´ê°€ ë¶ˆì¶©ë¶„í•˜ì—¬ ì›¹ ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        return {**state, "combined_context": combined_context, "source_context": source_context, "next_step": "web_search"}


def generate_answer_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ìµœì¢… ë‹µë³€ ìƒì„± ì‹¤í–‰---")
    question = state["question"]
    combined_context = state["combined_context"]
    
    print("í†µí•©ëœ ì •ë³´ë¡œ ë‹µë³€ ìƒì„± ì¤‘...")
    final_answer = generate_answer_with_llm(combined_context, question, llm, rag_prompt)

    return {**state, "answer": final_answer}

def web_search_node(state: GraphState) -> Dict[str, Any]:
    print("\n---ë…¸ë“œ: ì›¹ ê²€ìƒ‰ ì‹¤í–‰---")
    question = state["question"]
    combined_context = state.get("combined_context", "")

    print("ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
    search_results = tavily_tool.invoke({"query": question})
    search_results_str = "\n".join([str(res) for res in search_results])
    
    final_context = f"{combined_context}\n\nì›¹ ê²€ìƒ‰ ê²°ê³¼:\n{search_results_str}"
    
    print("ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘...")
    web_answer = generate_answer_with_llm(final_context, question, llm, web_search_prompt)
    
    source_context = state.get("source_context", "")
    source_context += f"**[ì°¸ê³  ìë£Œ - ì›¹ ê²€ìƒ‰]**\n{search_results_str}"

    return {**state, "answer": web_answer, "source_context": source_context}


# --- 6. LangGraph ì›Œí¬í”Œë¡œìš° ë¹Œë“œ ë° ì»´íŒŒì¼ ---
def build_initial_setup_graph():
    """ì´ˆê¸° ë¬¸ì„œ ë¡œë”© ë° ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•ì„ ìœ„í•œ ê·¸ë˜í”„ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤."""
    initial_builder = StateGraph(GraphState)
    initial_builder.add_node("load_and_merge_dbs", load_and_merge_dbs_node)
    initial_builder.set_entry_point("load_and_merge_dbs")
    initial_builder.add_edge("load_and_merge_dbs", END)
    return initial_builder.compile()

def build_query_graph():
    """ì§ˆë¬¸ ë¶„ë¥˜, RAG, ì›¹ ê²€ìƒ‰ì„ í†µí•©í•œ ë©”ì¸ ì§ˆì˜ ê·¸ë˜í”„ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤."""
    query_builder = StateGraph(GraphState)
    
    query_builder.add_node("classify_question", classify_question_node)
    query_builder.add_node("extract_and_retrieve", extract_and_retrieve_node)
    query_builder.add_node("call_api", call_api_node)
    query_builder.add_node("combine_and_check_for_web_search", combine_and_check_for_web_search_node)
    query_builder.add_node("generate_answer", generate_answer_node)
    query_builder.add_node("web_search", web_search_node)
    
    query_builder.set_entry_point("classify_question")
    
    def route_classification(state: GraphState):
        classification = state.get("classification")
        if classification == "other":
            return "web_search"
        else:
            return "extract_and_retrieve"
            
    query_builder.add_conditional_edges(
        "classify_question",
        route_classification,
        { "web_search": "web_search", "extract_and_retrieve": "extract_and_retrieve"}
    )
    
    query_builder.add_edge("extract_and_retrieve", "call_api")
    query_builder.add_edge("call_api", "combine_and_check_for_web_search")

    def route_sufficiency(state: GraphState):
        next_step = state.get("next_step")
        return next_step
        
    query_builder.add_conditional_edges(
        "combine_and_check_for_web_search",
        route_sufficiency,
        {
            "generate": "generate_answer",
            "web_search": "web_search",
        }
    )

    query_builder.add_edge("web_search", END)
    query_builder.add_edge("generate_answer", END)

    return query_builder.compile()

# --- 7. ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
if __name__ == "__main__":
    print("ğŸŒ± ë†ì‘ë¬¼ ì±—ë´‡ ì—ì´ì „íŠ¸ ì‹œì‘...")
    print("--------------------------------------------------")
    
    print("ì±—ë´‡ ì‹œìŠ¤í…œì„ ì¤€ë¹„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... (í†µí•© ë²¡í„° DB ë¡œë“œ)")
    setup_graph = build_initial_setup_graph()
    initial_state = {"question": "setup"}
    try:
        setup_result = setup_graph.invoke(initial_state)
        vectorstore = setup_result.get("vectorstore")
    except Exception as e:
        print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        exit()
        
    print("ì±—ë´‡ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!\n")
    
    rag_app = build_query_graph()

    print("ì´ì œ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”. (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit' ì…ë ¥)")
    print("--------------------------------------------------")

    while True:
        prompt = input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”: ")
        if prompt.lower() in ["exit", "quit"]:
            print("ì±—ë´‡ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        print("ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘...")
        try:
            final_state = rag_app.invoke({"question": prompt, "vectorstore": vectorstore})
            response = final_state.get('answer', "ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            source_context = final_state.get('source_context', "ì°¸ê³  ìë£Œê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            print("\n------------------- ë‹µë³€ -------------------")
            print(response)
            print("-------------------------------------------\n")
            print("\n------------------- ì°¸ê³  ìë£Œ -------------------")
            print(source_context)
            print("-------------------------------------------\n")

        except Exception as e:
            print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")