import os
import pandas as pd
from glob import glob
from typing import List
from dotenv import load_dotenv

from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_milvus import Milvus
from pymilvus import utility, connections, FieldSchema, CollectionSchema, DataType
from langchain_core.documents import Document

load_dotenv()

# === ì„¤ì • ===
DATA_DIR = "./data/cropinfo" 
COLLECTION_NAME = "crop_info"
EMBED_MODEL_NAME = "jhgan/ko-sroberta-multitask"
CHUNK_SIZE = 800
CHUNK_OVERLAP = 100

def load_documents() -> List[Document]:
    """
    ì§€ì •ëœ ë””ë ‰í„°ë¦¬ì—ì„œ ëª¨ë“  PDF íŒŒì¼ì„ Document ê°ì²´ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
    """
    all_docs = []
    
    # 1. PDF íŒŒì¼ ë¡œë“œ
    pdf_paths = sorted(glob(os.path.join(DATA_DIR, "*.pdf")))
    for p in pdf_paths:
        try:
            docs = PyPDFLoader(p).load()
            # â— ìˆ˜ì •ëœ ë¶€ë¶„: ê²½ë¡œ êµ¬ë¶„ìë¥¼ '/'ë¡œ í†µì¼
            normalized_path = p.replace(os.sep, '/')
            for doc in docs:
                doc.metadata['source'] = normalized_path
            print(f"âœ… PDF íŒŒì¼ ë¡œë“œ: {os.path.basename(p)} (ì´ í˜ì´ì§€ ìˆ˜: {len(docs)})")
            all_docs.extend(docs)
        except Exception as e:
            print(f"â— PDF íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {p} -> ì˜¤ë¥˜: {e}")

    if not all_docs:
        raise FileNotFoundError(f"'{DATA_DIR}' ë””ë ‰í„°ë¦¬ì—ì„œ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
    print(f"ğŸ“š ì´ ë¡œë“œëœ ë¬¸ì„œ ìˆ˜: {len(all_docs)}")
    return all_docs

def split_documents(documents: List[Document]) -> List[Document]:
    """
    ë¬¸ì„œë¥¼ ì‘ì€ ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    """
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", ". ", "? ", "! ", "\n", " "],
    )
    chunks = splitter.split_documents(documents)
    print(f"âœ‚ï¸ ì´ ìƒì„±ëœ ì²­í¬ ìˆ˜: {len(chunks)}")
    return chunks

def build_vectorstore(documents: List[Document]) -> None:
    """
    Milvusì— ë²¡í„°ìŠ¤í† ì–´ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.
    """
    print("ğŸ§  ë²¡í„°ìŠ¤í† ì–´ ì¤€ë¹„ ì¤‘...")

    # ğŸ”„ ê¸°ì¡´ ì—°ê²° í™•ì¸ ë° ëŠê¸° (ì¤‘ë³µ ì—°ê²° ë°©ì§€)
    if "default" in connections.list_connections():
        print("ğŸ”„ ê¸°ì¡´ ì—°ê²°ì„ ëŠê³  ìƒˆ ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        connections.disconnect("default")

    # Milvus ì—°ê²° ì„¤ì •
    connections.connect(alias="default", host="localhost", port="19530")
    
    # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    embedding_model = HuggingFaceEmbeddings(
        model_name=EMBED_MODEL_NAME,
        model_kwargs={"device": "cpu"}
    )
    
    # âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ í™•ì¸ ë° ë°ì´í„° ì‚½ì… ë¡œì§
    if utility.has_collection(COLLECTION_NAME):
        print(f"ğŸ”„ '{COLLECTION_NAME}' ì»¬ë ‰ì…˜ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. ë°ì´í„° ì‚½ì…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
    else:
        print(f"ğŸ†• ìƒˆë¡œìš´ ì»¬ë ‰ì…˜ '{COLLECTION_NAME}'ì„ ìƒì„±í•˜ê³  ë°ì´í„°ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤...")
        
        # Milvus ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
        Milvus.from_documents(
            documents=documents,
            embedding=embedding_model,
            collection_name=COLLECTION_NAME,
            connection_args={"host": "localhost", "port": "19530"}
        )
    
    print("âœ… ë²¡í„°ìŠ¤í† ì–´ êµ¬ì¶•ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    try:
        docs = load_documents()
        chunks = split_documents(docs)
        build_vectorstore(chunks)
        print("ğŸ‰ ëª¨ë“  ë¬¸ì„œê°€ ì²˜ë¦¬ë˜ì–´ Milvusì— ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"â— ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")