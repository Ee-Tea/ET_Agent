# build_index.py
import os
from glob import glob
from typing import List, Any

from dotenv import load_dotenv
load_dotenv()

# === ì„¤ì • ===
PDF_DIR = os.getenv("PDF_DIR", "./cropinfo")
VECTOR_DB_PATH = os.getenv("VECTOR_DB_PATH", "faiss_pdf_db")
EMBED_MODEL_NAME = os.getenv("EMBED_MODEL_NAME", "jhgan/ko-sroberta-multitask")
CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", "900"))
CHUNK_OVERLAP = int(os.getenv("CHUNK_OVERLAP", "150"))

# === LangChain ===
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS

def load_all_pdfs(pdf_dir: str) -> List[Any]:
    paths = sorted(glob(os.path.join(pdf_dir, "*.pdf")))
    if not paths:
        raise FileNotFoundError(f"PDFê°€ ì—†ìŠµë‹ˆë‹¤: {pdf_dir}")
    all_docs = []
    for p in paths:
        try:
            docs = PyPDFLoader(p).load()  # page ë‹¨ìœ„ Document ë¦¬ìŠ¤íŠ¸
            all_docs.extend(docs)
            print(f"âœ… ë¡œë“œ: {os.path.basename(p)} (pages={len(docs)})")
        except Exception as e:
            print(f"â— ë¡œë“œ ì‹¤íŒ¨: {p} -> {e}")
    print(f"ğŸ“š ì´ í˜ì´ì§€ ë¬¸ì„œ ìˆ˜: {len(all_docs)}")
    return all_docs

def split_documents(documents: List[Any]) -> List[Any]:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP, length_function=len
    )
    splits = splitter.split_documents(documents)
    print(f"âœ‚ï¸ ì²­í¬ ìˆ˜: {len(splits)}")
    return splits

def build_or_update_faiss(splits: List[Any], db_path: str) -> None:
    embeddings = HuggingFaceEmbeddings(model_name=EMBED_MODEL_NAME)

    if os.path.exists(db_path):
        print(f"ğŸ“¦ ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ: {db_path}")
        vs = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
        print("â• ìƒˆ ì²­í¬ ì¶”ê°€ í›„ ì¸ë±ìŠ¤ ì €ì¥â€¦")
        vs.add_documents(splits)
        vs.save_local(db_path)
    else:
        print("ğŸ§± ìƒˆ ì¸ë±ìŠ¤ ìƒì„±â€¦")
        vs = FAISS.from_documents(splits, embeddings)
        vs.save_local(db_path)
    print(f"âœ… ì €ì¥ ì™„ë£Œ: {db_path}")

if __name__ == "__main__":
    print("ğŸš€ ì¸ë±ìŠ¤ ë¹Œë“œ ì‹œì‘")
    docs = load_all_pdfs(PDF_DIR)
    splits = split_documents(docs)
    build_or_update_faiss(splits, VECTOR_DB_PATH)
    print("ğŸ‰ ì¸ë±ìŠ¤ ë¹Œë“œ ì™„ë£Œ")
