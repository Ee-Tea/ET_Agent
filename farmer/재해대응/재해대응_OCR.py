import os
import pickle
import numpy as np
import pandas as pd
import faiss
import torch
from tqdm import tqdm
from typing import TypedDict, List, Optional
from sentence_transformers import SentenceTransformer, util
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langgraph.graph import StateGraph, END
from langchain_groq import ChatGroq
from dotenv import load_dotenv

load_dotenv()

# ===== 1. ìƒíƒœ ì •ì˜ =====
class RAGState(TypedDict):
    query: str
    documents: Optional[List[str]]
    answer: Optional[str]

# ===== 2. ë¬¸ì„œ ê²€ìƒ‰ê¸° =====
text_model = SentenceTransformer("jhgan/ko-sroberta-multitask")

def l2_normalize(vec):
    norm = np.linalg.norm(vec)
    return vec / norm if norm > 0 else vec

index = faiss.read_index("multimodal_rag.index")
with open("multimodal_rag.pkl", "rb") as f:
    documents = pickle.load(f)

def retrieve_docs(state: RAGState) -> RAGState:
    query = state["query"]
    text_vec = text_model.encode([query])[0]
    text_vec = l2_normalize(text_vec)
    D, I = index.search(np.array([text_vec]).astype("float32"), k=5)
    scored_docs = []
    for idx, dist in zip(I[0], D[0]):
        similarity = 1 - dist
        doc = documents[idx]
        scored_docs.append(f"[ìœ ì‚¬ë„: {similarity:.4f}] {doc}")
    return {**state, "documents": scored_docs}

# ===== 3. LLM ì²´ì¸ ì •ì˜ =====
prompt = PromptTemplate.from_template("""
ë„ˆëŠ” ë†ì‘ë¬¼ ì¬í•´ ëŒ€ì‘ ì „ë¬¸ê°€ì•¼.
ë‹¤ìŒ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µë³€í•´ì¤˜.
ì´ê±¸ ì‚¬ìš©í•˜ëŠ” ì‚¬ëŒì€ ë†ì‚¬ì— ëŒ€í•´ ì˜ ëª¨ë¥´ê³  ì •ë³´ê°€ í•„ìš”í•œ ì‚¬ëŒë“¤ì´ì•¼.
íƒœí’, í­ì—¼ ê°™ì€ ì¬í•´ë¡œë¶€í„° ì‘ë¬¼ì„ ì–´ë–»ê²Œ ë³´í˜¸í•˜ê³  ê´€ë¦¬í•´ì•¼ í• ì§€,
ì‹œê¸°ë³„ë¡œ ì–´ë–¤ ì‘ì—…ì´ ì¤‘ìš”í•œì§€ ì„¤ëª…í•´ì¤˜.

âš ï¸ ë¬¸ì„œëŠ” í‘œ í˜•ì‹ì—ì„œ ì´ë¯¸ì§€ë¡œ ì¶”ì¶œëœ ë‚´ìš©ì´ë¼ ì¤„ë°”ê¿ˆ ì—†ì´ ë‹¨ìˆœ ë‚˜ì—´ëœ ê²½ìš°ê°€ ë§ì•„.
âš ï¸ ì¤‘ìš”í•˜ì§€ ì•Šì€ ë°˜ë³µ(1ì›”~12ì›” ë“±)ì€ ìƒëµí•˜ê³  í•µì‹¬ ì‘ì—… ìœ„ì£¼ë¡œ ìš”ì•½í•´ì¤˜.

â“ ì§ˆë¬¸: {question}

ğŸ“„ ë¬¸ì„œ:
{context}

ğŸ“¢ ë‹µë³€:
""")

llm = ChatGroq(
    model="meta-llama/llama-4-scout-17b-16e-instruct",
    temperature=0.7
)

rag_chain = prompt | llm | StrOutputParser()

def generate_answer(state: RAGState) -> RAGState:
    question = state.get("query", "")
    documents = state.get("documents", [])
    context = "\n\n".join(documents) if documents else "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    answer = rag_chain.invoke({"question": question, "context": context})
    return {**state, "answer": answer}

# ===== 4. LangGraph êµ¬ì„± =====
graph = StateGraph(RAGState)
graph.add_node("RetrieveDocs", retrieve_docs)
graph.add_node("GenerateAnswer", generate_answer)
graph.set_entry_point("RetrieveDocs")
graph.add_edge("RetrieveDocs", "GenerateAnswer")
graph.add_edge("GenerateAnswer", END)
graph = graph.compile()

try:
    graph_image_path = "agent_workflow.png"
    with open(graph_image_path, "wb") as f:
        f.write(graph.get_graph().draw_mermaid_png())
    print(f"\nLangGraph êµ¬ì¡°ê°€ '{graph_image_path}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    print(f"ê·¸ë˜í”„ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# ===== 5. í‰ê°€ ì½”ë“œ =====
def evaluate_on_golden_set(csv_path: str):
    df = pd.read_csv(csv_path)  # question, answer ì»¬ëŸ¼ í•„ìˆ˜
    results = []

    for i, row in tqdm(df.iterrows(), total=len(df)):
        query = row["question"]
        ground_truth = row["answer"]

        input_state = {
            "query": query,
            "documents": None,
            "answer": None
        }

        try:
            result = graph.invoke(input_state)
            rag_answer = result["answer"]

            emb1 = text_model.encode(ground_truth, convert_to_tensor=True)
            emb2 = text_model.encode(rag_answer, convert_to_tensor=True)
            similarity = util.pytorch_cos_sim(emb1, emb2).item()

            results.append({
                "question": query,
                "ë‹µë³€(ì •ë‹µ)": ground_truth,
                "LLM ìƒì„± ë‹µë³€": rag_answer,
                "ìœ ì‚¬ë„": round(similarity, 4)
            })

            # âœ… ì‹¤ì‹œê°„ ì¶œë ¥
            print(f"\nğŸŸ¡ ì§ˆë¬¸: {query}")
            print(f"âœ… ì •ë‹µ: {ground_truth}")
            print(f"ğŸ¤– LLM ë‹µë³€: {rag_answer}")
            print(f"ğŸ“ˆ ìœ ì‚¬ë„: {round(similarity, 4)}")

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {type(e).__name__} - {e}")
            results.append({
                "question": query,
                "ë‹µë³€(ì •ë‹µ)": ground_truth,
                "LLM ìƒì„± ë‹µë³€": f"[ì˜¤ë¥˜ ë°œìƒ] {e}",
                "ìœ ì‚¬ë„": -1
            })

    # âœ… CSV ì €ì¥
    pd.DataFrame(results).to_csv("rag_eval_results.csv", index=False)
    print("\nâœ… rag_eval_results.csv íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!")

# ===== 6. ë‹¨ì¼ ì‹¤í–‰ =====
if __name__ == "__main__":
    csv_path = "ê³¨ë“ ì…‹.csv"
    print("ğŸš€ ê³¨ë“ ì…‹ ê¸°ë°˜ RAG í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...\n")
    evaluate_on_golden_set(csv_path)
