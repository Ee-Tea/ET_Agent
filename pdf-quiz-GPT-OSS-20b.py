import os
import glob
from typing import List, Dict, Any, TypedDict
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from langgraph.graph import StateGraph, END
import json
import re
from collections import Counter
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from datetime import datetime

# Ollama API ì‚¬ìš©
import requests
from langchain_community.embeddings import HuggingFaceEmbeddings

class GraphState(TypedDict):
    """ê·¸ë˜í”„ ìƒíƒœ ì •ì˜"""
    query: str
    documents: List[Document]
    context: str
    quiz_questions: List[Dict[str, Any]]
    quiz_count: int
    difficulty: str
    error: str
    used_sources: List[str]
    generation_attempts: int
    target_quiz_count: int
    subject_area: str
    validated_questions: List[Dict[str, Any]]

class InfoProcessingExamRAG:
    """
    ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì¶œì œê¸°ì¤€ì— ë§ëŠ” 50ë¬¸ì œ ìë™ ì¶œì œ ì‹œìŠ¤í…œ (gpt-oss-20b ë²„ì „)
    ë³‘ë ¬ ì²˜ë¦¬ ë° ì¦ë¶„ ìƒì„± ì§€ì›
    """
    
    # ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ 5ê°œ ê³¼ëª© ì •ì˜
    SUBJECT_AREAS = {
        "ì†Œí”„íŠ¸ì›¨ì–´ì„¤ê³„": {
            "count": 10,
            "keywords": ["ìš”êµ¬ì‚¬í•­", "UI ì„¤ê³„", "ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ê³„", "ì¸í„°í˜ì´ìŠ¤", "UML", "ê°ì²´ì§€í–¥", "ë””ìì¸íŒ¨í„´", "ëª¨ë“ˆí™”", "ê²°í•©ë„", "ì‘ì§‘ë„"]
        },
        "ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œ": {
            "count": 10,
            "keywords": ["ìë£Œêµ¬ì¡°", "ìŠ¤íƒ", "í", "ë¦¬ìŠ¤íŠ¸", "í†µí•©êµ¬í˜„", "ëª¨ë“ˆ", "íŒ¨í‚¤ì§•", "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤", "ì•Œê³ ë¦¬ì¦˜", "ì¸í„°í˜ì´ìŠ¤"]
        },
        "ë°ì´í„°ë² ì´ìŠ¤êµ¬ì¶•": {
            "count": 10,
            "keywords": ["SQL", "íŠ¸ë¦¬ê±°", "DML", "DDL", "DCL", "ì •ê·œí™”", "ê´€ê³„í˜•ëª¨ë¸", "E-Rëª¨ë¸", "ë°ì´í„°ëª¨ë¸ë§", "ë¬´ê²°ì„±"]
        },
        "í”„ë¡œê·¸ë˜ë°ì–¸ì–´í™œìš©": {
            "count": 10,
            "keywords": ["ê°œë°œí™˜ê²½", "í”„ë¡œê·¸ë˜ë°ì–¸ì–´", "ë¼ì´ë¸ŒëŸ¬ë¦¬", "ìš´ì˜ì²´ì œ", "ë„¤íŠ¸ì›Œí¬", "ë°ì´í„°íƒ€ì…", "ë³€ìˆ˜", "ì—°ì‚°ì"]
        },
        "ì •ë³´ì‹œìŠ¤í…œêµ¬ì¶•ê´€ë¦¬": {
            "count": 10,
            "keywords": ["ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œë°©ë²•ë¡ ", "í”„ë¡œì íŠ¸ê´€ë¦¬", "ë³´ì•ˆ", "ì‹œìŠ¤í…œë³´ì•ˆ", "ë„¤íŠ¸ì›Œí¬ë³´ì•ˆ", "í…Œì¼ëŸ¬ë§", "ìƒëª…ì£¼ê¸°ëª¨ë¸"]
        }
    }
    
    def __init__(self, data_folder="data", max_workers=3, model_name="llama2:7b"):
        """
        ì´ˆê¸°í™”
        
        Args:
            data_folder: PDF íŒŒì¼ì´ ìˆëŠ” í´ë”
            max_workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
            model_name: Ollama ëª¨ë¸ëª…
        """
        self.data_folder = data_folder
        self.max_workers = max_workers
        self.model_name = model_name
        os.makedirs(self.data_folder, exist_ok=True)
        
        self.embeddings_model = None
        self.vectorstore = None
        self.retriever = None
        self.workflow = None
        
        self.files_in_vectorstore = []
        self.lock = threading.Lock()
        
        self._initialize_models()
        self._build_graph()

    def _initialize_models(self):
        """ì„ë² ë”© ë° Ollama ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            print("ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
            self.embeddings_model = HuggingFaceEmbeddings(
                model_name="jhgan/ko-sroberta-multitask",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
            print("âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            
            print("Ollama gpt-oss-20b ëª¨ë¸ ì—°ê²° í™•ì¸ ì¤‘...")
            
            # Ollama ì„œë²„ ì—°ê²° í™•ì¸
            try:
                response = requests.get("http://localhost:11434/api/tags", timeout=5)
                models = response.json().get("models", [])
                
                gpt_oss_available = any(self.model_name in model.get("name", "") for model in models)
                
                if not gpt_oss_available:
                    print(f"âš ï¸ Ollamaì—ì„œ {self.model_name} ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    print(f"ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì„¸ìš”: ollama pull {self.model_name}")
                    raise Exception(f"{self.model_name} ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
                
                print(f"âœ… Ollama {self.model_name} ëª¨ë¸ ì—°ê²° í™•ì¸ ì™„ë£Œ")
                
            except requests.exceptions.RequestException:
                print("âŒ Ollama ì„œë²„ê°€ ì‹¤í–‰ë˜ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
                print("Ollamaë¥¼ ì‹¤í–‰í•˜ì„¸ìš”: ollama serve")
                raise
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def _generate_text(self, prompt: str, max_tokens: int = 2048) -> str:
        """Ollama gpt-oss-20bë¡œ í…ìŠ¤íŠ¸ ìƒì„±"""
        try:
            response = requests.post(
                'http://localhost:11434/api/generate',
                json={
                    'model': self.model_name,
                    'prompt': prompt,
                    'stream': False,
                    'options': {
                        'num_predict': max_tokens,
                        'temperature': 0.1,
                        'top_p': 0.9,
                    }
                },
                timeout=300  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
            )
            
            if response.status_code == 200:
                return response.json().get('response', '')
            else:
                print(f"Ollama API ì˜¤ë¥˜: {response.status_code}")
                return ""
                
        except Exception as e:
            print(f"í…ìŠ¤íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")
            return ""

    def _build_vectorstore_from_all_pdfs(self) -> bool:
        """PDFë¥¼ ë¡œë“œí•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±/ì—…ë°ì´íŠ¸"""
        pdf_files = self.get_pdf_files()
        if not pdf_files:
            print(f"'{self.data_folder}' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        if self.vectorstore and set(self.files_in_vectorstore) == set(pdf_files):
            print("ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤ (íŒŒì¼ ë³€ê²½ ì—†ìŒ).")
            return True

        print("ìƒˆë¡œìš´ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        all_documents = []
        for pdf_path in pdf_files:
            try:
                print(f"  - ë¡œë”©: {os.path.basename(pdf_path)}")
                loader = PyPDFLoader(pdf_path)
                documents = loader.load()
                for doc in documents:
                    doc.metadata['source_file'] = os.path.basename(pdf_path)
                all_documents.extend(documents)
            except Exception as e:
                error_msg = str(e)
                if "cryptography" in error_msg and "is required" in error_msg:
                    print(f"    [ì•”í˜¸í™” ì˜¤ë¥˜] {os.path.basename(pdf_path)} íŒŒì¼ì€ ì•”í˜¸í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                    print("    í•´ë‹¹ íŒŒì¼ì„ ì½ìœ¼ë ¤ë©´ 'pip install pypdf[crypto]'ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                else:
                    print(f"    [ì˜¤ë¥˜] {os.path.basename(pdf_path)} íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
                continue
        
        if not all_documents:
            print("ë¬¸ì„œë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(all_documents)
        
        self.vectorstore = FAISS.from_documents(splits, self.embeddings_model)
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": 15})
        
        self.files_in_vectorstore = pdf_files
        print(f"ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ. ì´ {len(pdf_files)}ê°œ PDF, {len(splits)}ê°œ ì²­í¬.")
        return True

    def get_pdf_files(self) -> List[str]:
        """data í´ë”ì—ì„œ PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        return glob.glob(os.path.join(self.data_folder, "*.pdf"))

    def list_available_pdfs(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ PDF íŒŒì¼ ëª©ë¡ ì¶œë ¥"""
        pdf_files = self.get_pdf_files()
        if not pdf_files:
            print(f"'{self.data_folder}' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\n=== '{self.data_folder}' í´ë”ì˜ PDF íŒŒì¼ ëª©ë¡ ===")
        for i, file_path in enumerate(pdf_files, 1):
            filename = os.path.basename(file_path)
            file_size = os.path.getsize(file_path) / 1024
            print(f"{i}. {filename} ({file_size:.1f} KB)")

    def _retrieve_documents(self, state: GraphState) -> GraphState:
        """ë¬¸ì„œ ê²€ìƒ‰ ë° ì¶œì²˜ ë¶„ì„ ë…¸ë“œ"""
        try:
            query = state["query"]
            subject_area = state.get("subject_area", "")
            
            enhanced_query = f"{subject_area} {query}"
            
            documents = self.retriever.invoke(enhanced_query)
            source_files = [doc.metadata.get('source_file', 'Unknown') for doc in documents]
            used_sources = list(Counter(source_files).keys())
            return {**state, "documents": documents, "used_sources": used_sources}
        except Exception as e:
            return {**state, "error": f"ë¬¸ì„œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}"}

    def _prepare_context(self, state: GraphState) -> GraphState:
        """ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ë…¸ë“œ"""
        documents = state["documents"]
        context = "\n\n".join([doc.page_content for doc in documents])
        return {**state, "context": context}

    def _generate_quiz_incremental(self, state: GraphState) -> GraphState:
        """ì¦ë¶„ ë°©ì‹ìœ¼ë¡œ ë¬¸ì œ ìƒì„± - gpt-oss-20b ì‚¬ìš©"""
        try:
            context = state["context"]
            target_quiz_count = state.get("target_quiz_count", 5)
            difficulty = state.get("difficulty", "ì¤‘ê¸‰")
            generation_attempts = state.get("generation_attempts", 0)
            
            validated_questions = state.get("validated_questions", [])
            subject_area = state.get("subject_area", "")
            
            needed_count = target_quiz_count - len(validated_questions)
            
            if needed_count <= 0:
                print(f"[{subject_area}] ì´ë¯¸ ëª©í‘œ ë¬¸ì œ ìˆ˜({target_quiz_count}ê°œ)ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                return {**state, "quiz_questions": validated_questions}
            
            if not context.strip():
                return {**state, "error": "ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”."}
            
            generate_count = max(needed_count * 2, 5)
            
            print(f"[{subject_area}] ë¬¸ì œ ìƒì„± ì¤‘... ({generate_count}ê°œ)")
            
            prompt = f"""Create {generate_count} multiple-choice questions in Korean for {subject_area} based on this content:

{context[:3000]}

Format as JSON:
{{
  "questions": [
    {{
      "question": "ë¬¸ì œ",
      "options": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3", "ì„ íƒì§€4"],
      "answer": "ì •ë‹µë²ˆí˜¸",
      "explanation": "í•´ì„¤",
      "subject": "{subject_area}"
    }}
  ]
}}"""
            
            response = self._generate_text(prompt, max_tokens=2048)
            
            if not response:
                return {**state, "error": "Ollama gpt-oss-20bê°€ ì‘ë‹µì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}
            
            new_questions = self._parse_quiz_response(response, subject_area)
            
            if not new_questions:
                return {**state, "error": "Ollama gpt-oss-20bê°€ ìœ íš¨í•œ ë¬¸ì œë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}
            
            print(f"  â†’ ìƒˆë¡œ ìƒì„±ëœ ë¬¸ì œ {len(new_questions)}ê°œ")
            
            return {
                **state,
                "quiz_questions": new_questions,
                "validated_questions": validated_questions,
                "generation_attempts": generation_attempts + 1
            }
        except Exception as e:
            return {**state, "error": f"ë¬¸ì œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}

    def _validate_quiz_incremental(self, state: GraphState) -> GraphState:
        """ì¦ë¶„ ê²€ì¦ - ìµœì í™”ë¨"""
        subject_area = state.get("subject_area", "")
        previously_validated = state.get("validated_questions", [])
        new_questions = state.get("quiz_questions", [])
        target_quiz_count = state.get("target_quiz_count", 5)
        generation_attempts = state.get("generation_attempts", 0)

        if not new_questions:
            return {**state, "validated_questions": previously_validated}

        newly_validated = []
        needed = target_quiz_count - len(previously_validated)
        
        # ê°„ë‹¨í•œ ê²€ì¦ - ëª¨ë“  ë¬¸ì œë¥¼ ìœ íš¨í•˜ë‹¤ê³  ê°€ì • (ì†ë„ í–¥ìƒ)
        for q in new_questions[:needed]:
            newly_validated.append(q)
        
        all_validated = previously_validated + newly_validated
        print(f"[{subject_area}] ê²€ì¦ ì™„ë£Œ: {len(newly_validated)}ê°œ ì¶”ê°€")
        
        need_more_questions = (len(all_validated) < target_quiz_count and 
                              generation_attempts < 10)  # ì‹œë„ íšŸìˆ˜ ì¤„ì„
        
        return {
            **state,
            "validated_questions": all_validated,
            "quiz_questions": all_validated,
            "need_more_questions": need_more_questions
        }

    def _check_completion(self, state: GraphState) -> str:
        """ë¬¸ì œ ìƒì„± ì™„ë£Œ ì—¬ë¶€ë¥¼ ì²´í¬í•˜ëŠ” ì¡°ê±´ë¶€ ë…¸ë“œ"""
        validated_count = len(state.get("validated_questions", []))
        target_count = state.get("target_quiz_count", 5)
        generation_attempts = state.get("generation_attempts", 0)
        subject_area = state.get("subject_area", "")
        
        if validated_count >= target_count:
            print(f"[{subject_area}] ëª©í‘œ ë¬¸ì œ ìˆ˜ {target_count}ê°œ ë‹¬ì„±! âœ“")
            return "complete"
        elif generation_attempts < 15:
            print(f"[{subject_area}] ì¶”ê°€ ìƒì„± í•„ìš” (í˜„ì¬: {validated_count}ê°œ/{target_count}ê°œ, ì‹œë„: {generation_attempts+1}íšŒ)")
            return "generate_more"
        else:
            print(f"[{subject_area}] ìµœëŒ€ ì‹œë„ íšŸìˆ˜(15íšŒ)ì— ë„ë‹¬. í˜„ì¬ê¹Œì§€ {validated_count}ê°œ ìƒì„±.")
            return "complete"

    def _parse_quiz_response(self, response: str, subject_area: str = "") -> List[Dict[str, Any]]:
        """Ollama gpt-oss-20b ì‘ë‹µì—ì„œ JSON í˜•ì‹ì˜ ë¬¸ì œë¥¼ íŒŒì‹±"""
        try:
            json_block_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_block_match:
                json_str = json_block_match.group(1)
            else:
                json_str_match = re.search(r'\{.*\}', response.strip(), re.DOTALL)
                if not json_str_match:
                    return []
                json_str = json_str_match.group(0)

            json_str = json_str.replace('\\u312f', '').replace('\\n', ' ')
            data = json.loads(json_str)
            
            if "questions" not in data or not isinstance(data["questions"], list):
                return []
            
            for question in data["questions"]:
                if "options" in question and isinstance(question["options"], list):
                    numbered_options = []
                    for i, option_text in enumerate(question["options"], 1):
                        cleaned_text = re.sub(r'^\s*\d+\.\s*', '', option_text).strip()
                        numbered_options.append(f"  {i}. {cleaned_text}")
                    question["options"] = numbered_options
                
                if "subject" not in question:
                    question["subject"] = subject_area
            
            return data.get("questions", [])
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return []
        except Exception as e:
            print(f"ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def _build_graph(self):
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        workflow = StateGraph(GraphState)
        workflow.add_node("retrieve", self._retrieve_documents)
        workflow.add_node("prepare_context", self._prepare_context)
        workflow.add_node("generate_quiz", self._generate_quiz_incremental)
        workflow.add_node("validate_quiz", self._validate_quiz_incremental)
        
        workflow.set_entry_point("retrieve")
        workflow.add_edge("retrieve", "prepare_context")
        workflow.add_edge("prepare_context", "generate_quiz")
        workflow.add_edge("generate_quiz", "validate_quiz")
        
        workflow.add_conditional_edges(
            "validate_quiz",
            self._check_completion,
            {
                "generate_more": "generate_quiz",
                "complete": END
            }
        )
        
        self.workflow = workflow.compile()

    def generate_subject_quiz_parallel(self, subject_area: str, target_count: int = 10, difficulty: str = "ì¤‘ê¸‰") -> Dict[str, Any]:
        """íŠ¹ì • ê³¼ëª©ì˜ ë¬¸ì œë¥¼ ë³‘ë ¬ë¡œ ìƒì„±"""
        if subject_area not in self.SUBJECT_AREAS:
            return {"error": f"ìœ íš¨í•˜ì§€ ì•Šì€ ê³¼ëª©: {subject_area}"}
        
        keywords = self.SUBJECT_AREAS[subject_area]["keywords"]
        
        print(f"\n=== {subject_area} ë¬¸ì œ ìƒì„± ì‹œì‘ (ëª©í‘œ: {target_count}ê°œ, Ollama gpt-oss-20b ì‚¬ìš©) ===")
        
        keyword_combinations = []
        for i in range(0, len(keywords), 2):
            combo = " ".join(keywords[i:i+3])
            keyword_combinations.append(combo)
        
        all_validated_questions = []
        
        # ë‹¨ìˆœí™”ëœ ë³‘ë ¬ ì²˜ë¦¬
        with ThreadPoolExecutor(max_workers=2) as executor:
            futures = []
            
            for combo in keyword_combinations:
                future = executor.submit(self._generate_with_keywords, 
                                       combo, subject_area, target_count, difficulty)
                futures.append(future)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for future in as_completed(futures):
                try:
                    result = future.result(timeout=60)
                    if "questions" in result and result["questions"]:
                        all_validated_questions.extend(result["questions"])
                        if len(all_validated_questions) >= target_count:
                            break
                except Exception as e:
                    print(f"  â†’ í‚¤ì›Œë“œ ì‹¤íŒ¨: {e}")
        
        final_questions = all_validated_questions[:target_count]
        
        return {
            "subject_area": subject_area,
            "difficulty": difficulty,
            "requested_count": target_count,
            "quiz_count": len(final_questions),
            "questions": final_questions,
            "status": "SUCCESS" if len(final_questions) >= target_count else "PARTIAL"
        }

    def _generate_with_keywords(self, query: str, subject_area: str, needed_count: int, difficulty: str) -> Dict[str, Any]:
        """íŠ¹ì • í‚¤ì›Œë“œë¡œ ë¬¸ì œ ìƒì„± (ìŠ¤ë ˆë“œ ì•ˆì „)"""
        try:
            initial_state = {
                "query": query,
                "quiz_count": needed_count,
                "target_quiz_count": needed_count,
                "difficulty": difficulty,
                "generation_attempts": 0,
                "quiz_questions": [],
                "validated_questions": [],
                "subject_area": subject_area
            }
            
            result = self.workflow.invoke(initial_state)
            
            if result.get("error"):
                return {"error": result["error"]}
            
            return {
                "questions": result.get("validated_questions", []),
                "used_sources": result.get("used_sources", [])
            }
            
        except Exception as e:
            return {"error": str(e)}

    def generate_full_exam_parallel(self, difficulty: str = "ì¤‘ê¸‰") -> Dict[str, Any]:
        """ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì „ì²´ 50ë¬¸ì œë¥¼ ë³‘ë ¬ë¡œ ìƒì„± (gpt-oss-20b ì‚¬ìš©)"""
        if not self._build_vectorstore_from_all_pdfs():
            return {"error": f"'{self.data_folder}' í´ë”ì— PDFê°€ ì—†ì–´ ë¬¸ì œë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        print("\n" + "="*80)
        print("  ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ 50ë¬¸ì œ ìë™ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤! (Ollama gpt-oss-20b + ë³‘ë ¬ ì²˜ë¦¬)")
        print("  âš ï¸  ê° ê³¼ëª©ë³„ë¡œ ë°˜ë“œì‹œ 10ë¬¸ì œì”© ìƒì„±í•©ë‹ˆë‹¤.")
        print("="*80)
        
        start_time = time.time()
        
        full_exam_result = {
            "exam_title": "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ëª¨ì˜ê³ ì‚¬ (gpt-oss-20b ë²„ì „)",
            "total_questions": 0,
            "difficulty": difficulty,
            "subjects": {},
            "all_questions": [],
            "generation_summary": {},
            "failed_subjects": [],
            "model_info": "Ollama gpt-oss-20b"
        }
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = {}
            
            for subject_area, subject_info in self.SUBJECT_AREAS.items():
                target_count = subject_info["count"]
                print(f"ğŸ“š [{subject_area}] ê³¼ëª© ë¬¸ì œ ìƒì„± ì‹œì‘... (ëª©í‘œ: {target_count}ë¬¸ì œ, Ollama gpt-oss-20b ì‚¬ìš©)")
                
                future = executor.submit(
                    self.generate_subject_quiz_parallel,
                    subject_area=subject_area,
                    target_count=target_count,
                    difficulty=difficulty
                )
                futures[future] = subject_area
            
            completed_subjects = 0
            for future in as_completed(futures):
                subject_area = futures[future]
                completed_subjects += 1
                
                try:
                    subject_result = future.result(timeout=1800)  # 30ë¶„ íƒ€ì„ì•„ì›ƒ
                    
                    if "error" in subject_result:
                        print(f"âŒ [{completed_subjects}/5] {subject_area}: ì‹¤íŒ¨")
                        full_exam_result["failed_subjects"].append({
                            "subject": subject_area,
                            "error": subject_result["error"]
                        })
                    else:
                        questions = subject_result["questions"]
                        actual_count = len(questions)
                        
                        full_exam_result["subjects"][subject_area] = {
                            "requested_count": 10,
                            "actual_count": actual_count,
                            "questions": questions,
                            "status": subject_result.get("status", "UNKNOWN")
                        }
                        
                        full_exam_result["all_questions"].extend(questions)
                        print(f"âœ… [{completed_subjects}/5] {subject_area}: {actual_count}/10ë¬¸ì œ ì™„ë£Œ")
                        
                except Exception as e:
                    print(f"âŒ [{completed_subjects}/5] {subject_area}: ì˜ˆì™¸ ë°œìƒ - {e}")
                    full_exam_result["failed_subjects"].append({
                        "subject": subject_area,
                        "error": str(e)
                    })
        
        total_generated = len(full_exam_result["all_questions"])
        elapsed_time = time.time() - start_time
        
        full_exam_result["total_questions"] = total_generated
        full_exam_result["generation_summary"] = {
            "target_total": 50,
            "actual_total": total_generated,
            "success_rate": f"{total_generated/50*100:.1f}%",
            "successful_subjects": 5 - len(full_exam_result["failed_subjects"]),
            "failed_subjects": len(full_exam_result["failed_subjects"]),
            "completion_status": "COMPLETE" if total_generated >= 50 else "PARTIAL",
            "generation_time": f"{elapsed_time:.1f}ì´ˆ"
        }
        
        print(f"\n" + "="*80)
        print(f"ğŸ¯ ìµœì¢… ê²°ê³¼: {total_generated}/50ë¬¸ì œ ìƒì„± ì™„ë£Œ! (Ollama gpt-oss-20b ì‚¬ìš©)")
        print(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ")
        print(f"âœ… ì„±ê³µí•œ ê³¼ëª©: {5 - len(full_exam_result['failed_subjects'])}/5ê°œ")
        print(f"âŒ ì‹¤íŒ¨í•œ ê³¼ëª©: {len(full_exam_result['failed_subjects'])}/5ê°œ")
        
        if full_exam_result["failed_subjects"]:
            print(f"\nì‹¤íŒ¨í•œ ê³¼ëª©:")
            for failed in full_exam_result["failed_subjects"]:
                print(f"  - {failed['subject']}")
        
        print("="*80)
        
        return full_exam_result

    def save_exam_to_json(self, exam_result: Dict[str, Any], filename: str = None):
        """50ë¬¸ì œ ì‹œí—˜ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"ì •ë³´ì²˜ë¦¬ê¸°ì‚¬_50ë¬¸ì œ_gptoss_{timestamp}.json"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(exam_result, f, ensure_ascii=False, indent=2)
            
            total_questions = exam_result.get("total_questions", 0)
            print(f"\n" + "="*60)
            print(f"  ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ëª¨ì˜ê³ ì‚¬ ({total_questions}ë¬¸ì œ)ê°€ '{filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            print("="*60)
            
            for subject, info in exam_result.get("subjects", {}).items():
                if "error" not in info:
                    print(f"  - {subject}: {info['actual_count']}/{info['requested_count']}ë¬¸ì œ")
                else:
                    print(f"  - {subject}: ìƒì„± ì‹¤íŒ¨")
                    
        except Exception as e:
            print(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")

    def display_exam_summary(self, exam_result: Dict[str, Any]):
        """ì‹œí—˜ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*80)
        print(f"  {exam_result.get('exam_title', 'ì‹œí—˜')} ìƒì„± ì™„ë£Œ!")
        print("="*80)
        
        summary = exam_result.get("generation_summary", {})
        print(f"ğŸ“Š ì „ì²´ ë¬¸ì œ ìˆ˜: {summary.get('actual_total', 0)}/{summary.get('target_total', 50)}ë¬¸ì œ")
        print(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {exam_result.get('model_info', 'Unknown')}")
        print(f"ğŸ“ˆ ì„±ê³µë¥ : {summary.get('success_rate', '0%')}")
        print(f"â±ï¸  ì†Œìš” ì‹œê°„: {summary.get('generation_time', 'N/A')}")
        print(f"âœ… ì„±ê³µí•œ ê³¼ëª©: {summary.get('successful_subjects', 0)}/5ê°œ")
        print(f"âŒ ì‹¤íŒ¨í•œ ê³¼ëª©: {summary.get('failed_subjects', 0)}/5ê°œ")
        print(f"ğŸ¯ ì™„ì„±ë„: {summary.get('completion_status', 'UNKNOWN')}")
        
        print("\n[ê³¼ëª©ë³„ ìƒì„¸ ê²°ê³¼]")
        for subject, info in exam_result.get("subjects", {}).items():
            status_icon = "âœ…" if info.get("status") == "SUCCESS" else "âš ï¸" if info.get("status") == "PARTIAL" else "âŒ"
            if "error" not in info:
                print(f"  {status_icon} {subject}: {info['actual_count']}/{info['requested_count']}ë¬¸ì œ")
            else:
                print(f"  {status_icon} {subject}: ìƒì„± ì‹¤íŒ¨")
        
        failed_subjects = exam_result.get("failed_subjects", [])
        if failed_subjects:
            print(f"\nâš ï¸  ì‹¤íŒ¨í•œ ê³¼ëª©ì´ ìˆìŠµë‹ˆë‹¤:")
            for failed in failed_subjects:
                print(f"   - {failed['subject']}: PDF ë¬¸ì„œì— ê´€ë ¨ ë‚´ìš©ì´ ë¶€ì¡±í•˜ê±°ë‚˜ í‚¤ì›Œë“œê°€ ì í•©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            print(f"   ğŸ’¡ í•´ê²° ë°©ì•ˆ: í•´ë‹¹ ê³¼ëª©ì˜ ìƒì„¸í•œ PDF ìë£Œë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")
        
        print()

    def generate_subject_quiz(self, subject_area: str, target_count: int = 10, difficulty: str = "ì¤‘ê¸‰") -> Dict[str, Any]:
        """íŠ¹ì • ê³¼ëª©ì˜ ë¬¸ì œë¥¼ ìƒì„±"""
        return self.generate_subject_quiz_parallel(subject_area, target_count, difficulty)

    def generate_full_exam(self, difficulty: str = "ì¤‘ê¸‰", parallel: bool = True) -> Dict[str, Any]:
        """ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì „ì²´ 50ë¬¸ì œë¥¼ ìƒì„±"""
        if parallel:
            return self.generate_full_exam_parallel(difficulty)
        else:
            # ìˆœì°¨ ì²˜ë¦¬ - ê°„ë‹¨í•œ ë²„ì „
            if not self._build_vectorstore_from_all_pdfs():
                return {"error": f"'{self.data_folder}' í´ë”ì— PDFê°€ ì—†ìŠµë‹ˆë‹¤."}
            
            start_time = time.time()
            full_exam_result = {
                "exam_title": "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ëª¨ì˜ê³ ì‚¬",
                "total_questions": 0,
                "difficulty": difficulty,
                "subjects": {},
                "all_questions": [],
                "generation_summary": {},
                "failed_subjects": [],
                "model_info": "Ollama gpt-oss-20b"
            }
            
            total_generated = 0
            
            for subject_area, subject_info in self.SUBJECT_AREAS.items():
                target_count = subject_info["count"]
                print(f"[{subject_area}] ì‹œì‘...")
                
                subject_result = self.generate_subject_quiz_parallel(
                    subject_area=subject_area,
                    target_count=target_count,
                    difficulty=difficulty
                )
                
                if "error" in subject_result:
                    full_exam_result["failed_subjects"].append({
                        "subject": subject_area,
                        "error": subject_result["error"]
                    })
                else:
                    questions = subject_result["questions"]
                    actual_count = len(questions)
                    total_generated += actual_count
                    
                    full_exam_result["subjects"][subject_area] = {
                        "requested_count": target_count,
                        "actual_count": actual_count,
                        "questions": questions,
                        "status": subject_result.get("status", "UNKNOWN")
                    }
                    
                    full_exam_result["all_questions"].extend(questions)
                    print(f"âœ… [{subject_area}] ì™„ë£Œ: {actual_count}ê°œ")
            
            elapsed_time = time.time() - start_time
            
            full_exam_result["total_questions"] = total_generated
            full_exam_result["generation_summary"] = {
                "target_total": 50,
                "actual_total": total_generated,
                "success_rate": f"{total_generated/50*100:.1f}%",
                "successful_subjects": 5 - len(full_exam_result["failed_subjects"]),
                "failed_subjects": len(full_exam_result["failed_subjects"]),
                "completion_status": "COMPLETE" if total_generated >= 50 else "PARTIAL",
                "generation_time": f"{elapsed_time:.1f}ì´ˆ"
            }
            
            return full_exam_result


# --- ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ ---
def interactive_menu(rag_system):
    """ì‚¬ìš©ìì™€ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë©”ë‰´ ì‹œìŠ¤í…œ"""
    while True:
        print("\n=== ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ 50ë¬¸ì œ ìë™ ì¶œì œ ì‹œìŠ¤í…œ ===")
        print("1. ì „ì²´ 50ë¬¸ì œ ìƒì„± (ë³‘ë ¬)")
        print("2. ì „ì²´ 50ë¬¸ì œ ìƒì„± (ìˆœì°¨)")
        print("3. íŠ¹ì • ê³¼ëª©ë§Œ ìƒì„±")
        print("4. PDF ëª©ë¡ ë³´ê¸°")
        print("0. ì¢…ë£Œ")
        
        choice = input("ì„ íƒ: ").strip()
        
        if choice == "1":
            difficulty = input("ë‚œì´ë„ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰): ").strip() or "ì¤‘ê¸‰"
            print(f"50ë¬¸ì œ ìƒì„± ì‹œì‘... (ë‚œì´ë„: {difficulty})")
            
            exam_result = rag_system.generate_full_exam(difficulty=difficulty, parallel=True)
            
            if "error" not in exam_result:
                rag_system.display_exam_summary(exam_result)
                if input("JSON ì €ì¥? (y/n): ").strip().lower() == 'y':
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"ì •ë³´ì²˜ë¦¬ê¸°ì‚¬_50ë¬¸ì œ_{difficulty}_{timestamp}.json"
                    rag_system.save_exam_to_json(exam_result, filename)
            else:
                print(f"ì˜¤ë¥˜: {exam_result['error']}")
        
        elif choice == "2":
            difficulty = input("ë‚œì´ë„ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰): ").strip() or "ì¤‘ê¸‰"
            print(f"50ë¬¸ì œ ìƒì„± ì‹œì‘... (ë‚œì´ë„: {difficulty})")
            
            exam_result = rag_system.generate_full_exam(difficulty=difficulty, parallel=False)
            
            if "error" not in exam_result:
                rag_system.display_exam_summary(exam_result)
                if input("JSON ì €ì¥? (y/n): ").strip().lower() == 'y':
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"ì •ë³´ì²˜ë¦¬ê¸°ì‚¬_50ë¬¸ì œ_{difficulty}_{timestamp}.json"
                    rag_system.save_exam_to_json(exam_result, filename)
            else:
                print(f"ì˜¤ë¥˜: {exam_result['error']}")
        
        elif choice == "3":
            subjects = list(rag_system.SUBJECT_AREAS.keys())
            for i, subject in enumerate(subjects, 1):
                print(f"{i}. {subject}")
            
            try:
                subject_choice = int(input("ê³¼ëª© ë²ˆí˜¸: "))
                if 1 <= subject_choice <= len(subjects):
                    selected_subject = subjects[subject_choice - 1]
                    target_count = int(input("ë¬¸ì œ ìˆ˜: ") or "10")
                    difficulty = input("ë‚œì´ë„: ").strip() or "ì¤‘ê¸‰"
                    
                    print(f"{selected_subject} {target_count}ë¬¸ì œ ìƒì„± ì¤‘...")
                    
                    subject_result = rag_system.generate_subject_quiz(
                        subject_area=selected_subject,
                        target_count=target_count,
                        difficulty=difficulty
                    )
                    
                    if "error" not in subject_result:
                        questions = subject_result["questions"]
                        print(f"âœ… {len(questions)}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ")
                        
                        if input("ë¯¸ë¦¬ë³´ê¸°? (y/n): ").strip().lower() == 'y':
                            for i, q in enumerate(questions[:2], 1):
                                print(f"\n[ë¬¸ì œ {i}] {q.get('question', '')}")
                                for option in q.get('options', []):
                                    print(f"{option}")
                                print(f"ì •ë‹µ: {q.get('answer', '')}")
                        
                        if input("JSON ì €ì¥? (y/n): ").strip().lower() == 'y':
                            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                            filename = f"{selected_subject}_{len(questions)}ë¬¸ì œ_{timestamp}.json"
                            with open(filename, 'w', encoding='utf-8') as f:
                                json.dump(subject_result, f, ensure_ascii=False, indent=2)
                            print(f"ì €ì¥ë¨: {filename}")
                    else:
                        print(f"ì˜¤ë¥˜: {subject_result['error']}")
                else:
                    print("ì˜ëª»ëœ ë²ˆí˜¸")
            except ValueError:
                print("ìˆ«ì ì…ë ¥")

        elif choice == "4":
            rag_system.list_available_pdfs()
            
        elif choice == "0":
            print("ì¢…ë£Œ")
            break
            
        else:
            print("ì˜ëª»ëœ ì„ íƒ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        print("ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ 50ë¬¸ì œ ìë™ ì¶œì œ ì‹œìŠ¤í…œ (Ollama gpt-oss-20b) ì´ˆê¸°í™” ì¤‘...")
        
        rag_system = InfoProcessingExamRAG(
            data_folder="data", 
            max_workers=2  # ì›Œì»¤ ìˆ˜ ì¤„ì„
        )
        
        print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ¤– ëª¨ë¸: Ollama gpt-oss-20b")
        print(f"ğŸ“ ë°ì´í„°: '{rag_system.data_folder}'")
        
        interactive_menu(rag_system)
        
    except Exception as e:
        print(f"ì˜¤ë¥˜: {e}")
        print("ğŸ’¡ í•´ê²°: Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš” (ollama serve)")


if __name__ == "__main__":
    main()