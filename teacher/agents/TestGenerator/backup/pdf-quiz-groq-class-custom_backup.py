import os
import json
import re
from typing import List, Dict, Any, TypedDict
from abc import ABC, abstractmethod
from langchain.prompts import PromptTemplate
from langchain.schema import Document
from langgraph.graph import StateGraph, END
import time
from datetime import datetime

# .env íŒŒì¼ ë¡œë“œë¥¼ ìœ„í•œ ì„í¬íŠ¸
from dotenv import load_dotenv

# Groq ê´€ë ¨ ì„í¬íŠ¸
from langchain_groq import ChatGroq
from langchain_community.embeddings import HuggingFaceEmbeddings

try:
    from openai import OpenAI
except ImportError:
    OpenAI = None  # openai íŒ¨í‚¤ì§€ê°€ ì—†ìœ¼ë©´ None ì²˜ë¦¬

# ìƒìˆ˜ ì •ì˜
DEFAULT_MODEL = "moonshotai/kimi-k2-instruct"
DEFAULT_TEMPERATURE = 0.2
DEFAULT_BASE_URL = "https://api.groq.com/openai/v1"
DEFAULT_TIMEOUT = 120
DEFAULT_MAX_RETRIES = 3
DEFAULT_MAX_TOKENS = 2048
MAX_GENERATION_ATTEMPTS = 15
MAX_ROUNDS = 10

# ê²½ë¡œ ìƒìˆ˜
DEFAULT_DATA_FOLDER = os.path.join(os.path.dirname(__file__), "data")
DEFAULT_SAVE_DIR = os.path.join(os.path.dirname(__file__), "test")

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ìƒìˆ˜
WEAKNESS_ANALYSIS_PROMPT = """ë‹¹ì‹ ì€ ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì‹œí—˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ í•™ìŠµì ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì·¨ì•½ì ì„ ë¶„ì„í•˜ê³  ë§ì¶¤í˜• í•™ìŠµì´ í•„ìš”í•œ í•µì‹¬ ê°œë…ë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

[í•™ìŠµì ë¶„ì„ ë°ì´í„°]
{analysis_text}

ë‹¤ìŒ í•­ëª©ë“¤ì„ ë¶„ì„í•´ì„œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:

1. weakness_concepts: í•™ìŠµìê°€ ì·¨ì•½í•œ í•µì‹¬ ê°œë…ë“¤ (êµ¬ì²´ì ì¸ ê¸°ìˆ  ìš©ì–´ë‚˜ ê°œë…ëª…ìœ¼ë¡œ, 5-10ê°œ)
2. subject_focus: ì§‘ì¤‘í•´ì•¼ í•  ê³¼ëª© ì˜ì—­ë“¤
3. difficulty_level: ì¶”ì²œ ë‚œì´ë„ ("ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰")
4. question_types: í•„ìš”í•œ ë¬¸ì œ ìœ í˜•ë“¤
5. learning_priorities: ìš°ì„ ì ìœ¼ë¡œ í•™ìŠµí•´ì•¼ í•  ìˆœì„œ

ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì¶œì œ ê¸°ì¤€ì— ë§ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ê°œë…ë“¤ì„ ì¶”ì¶œí•˜ë˜, ë‹¤ìŒê³¼ ê°™ì€ ì˜ì—­ì—ì„œ ì„ ë³„í•˜ì„¸ìš”:
- ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ê³„: ìš”êµ¬ì‚¬í•­ ë¶„ì„, UML, ë””ìì¸íŒ¨í„´, ìë£Œíë¦„ë„ ë“±
- ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œ: ìë£Œêµ¬ì¡°, ì•Œê³ ë¦¬ì¦˜, í”„ë¡œê·¸ë˜ë° ë“±  
- ë°ì´í„°ë² ì´ìŠ¤: SQL, ì •ê·œí™”, íŠ¸ëœì­ì…˜ ë“±
- í”„ë¡œê·¸ë˜ë°ì–¸ì–´: ì–¸ì–´ë³„ íŠ¹ì„±, ë¼ì´ë¸ŒëŸ¬ë¦¬ ë“±
- ì •ë³´ì‹œìŠ¤í…œ: ë³´ì•ˆ, ë„¤íŠ¸ì›Œí¬, í”„ë¡œì íŠ¸ê´€ë¦¬ ë“±

ì¶œë ¥ ì˜ˆì‹œ:
{{
  "weakness_concepts": ["ìë£Œíë¦„ë„", "ë¯¸ë“¤ì›¨ì–´", "SQL ì¡°ì¸", "ì •ê·œí™”", "UML ë‹¤ì´ì–´ê·¸ë¨"],
  "subject_focus": ["ì†Œí”„íŠ¸ì›¨ì–´ì„¤ê³„", "ë°ì´í„°ë² ì´ìŠ¤êµ¬ì¶•"],
  "difficulty_level": "ì¤‘ê¸‰",
  "question_types": ["ê°œë…ì´í•´", "ì‘ìš©ë¬¸ì œ"],
  "learning_priorities": ["ìë£Œíë¦„ë„ êµ¬ì„±ìš”ì†Œ ì´í•´", "ë¯¸ë“¤ì›¨ì–´ ì—­í• ê³¼ ê¸°ëŠ¥", "SQL ì¡°ì¸ ìœ í˜•ë³„ íŠ¹ì§•"]
}}

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:"""

# ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ê³¼ëª© ì •ì˜
SUBJECT_AREAS = {
    "ì†Œí”„íŠ¸ì›¨ì–´ì„¤ê³„": {
        "count": 5,
        "keywords": ["ìš”êµ¬ì‚¬í•­", "UI ì„¤ê³„", "ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ê³„", "ì¸í„°í˜ì´ìŠ¤", "UML", "ê°ì²´ì§€í–¥", "ë””ìì¸íŒ¨í„´", "ëª¨ë“ˆí™”", "ê²°í•©ë„", "ì‘ì§‘ë„"]
    },
    "ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œ": {
        "count": 5,
        "keywords": ["ìë£Œêµ¬ì¡°", "ìŠ¤íƒ", "í", "ë¦¬ìŠ¤íŠ¸", "í†µí•©êµ¬í˜„", "ëª¨ë“ˆ", "íŒ¨í‚¤ì§•", "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤", "ì•Œê³ ë¦¬ì¦˜", "ì¸í„°í˜ì´ìŠ¤"]
    },
    "ë°ì´í„°ë² ì´ìŠ¤êµ¬ì¶•": {
        "count": 5,
        "keywords": ["SQL", "íŠ¸ë¦¬ê±°", "DML", "DDL", "DCL", "ì •ê·œí™”", "ê´€ê³„í˜•ëª¨ë¸", "E-Rëª¨ë¸", "ë°ì´í„°ëª¨ë¸ë§", "ë¬´ê²°ì„±"]
    },
    "í”„ë¡œê·¸ë˜ë°ì–¸ì–´í™œìš©": {
        "count": 5,
        "keywords": ["ê°œë°œí™˜ê²½", "í”„ë¡œê·¸ë˜ë°ì–¸ì–´", "ë¼ì´ë¸ŒëŸ¬ë¦¬", "ìš´ì˜ì²´ì œ", "ë„¤íŠ¸ì›Œí¬", "ë°ì´í„°íƒ€ì…", "ë³€ìˆ˜", "ì—°ì‚°ì"]
    },
    "ì •ë³´ì‹œìŠ¤í…œêµ¬ì¶•ê´€ë¦¬": {
        "count": 5,
        "keywords": ["ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œë°©ë²•ë¡ ", "í”„ë¡œì íŠ¸ê´€ë¦¬", "ë³´ì•ˆ", "ì‹œìŠ¤í…œë³´ì•ˆ", "ë„¤íŠ¸ì›Œí¬ë³´ì•ˆ", "í…Œì¼ëŸ¬ë§", "ìƒëª…ì£¼ê¸°ëª¨ë¸"]
    }
}

def extract_quiz_params(
    user_question: str,
    model: str = DEFAULT_MODEL,
    temperature: float = DEFAULT_TEMPERATURE,
    groq_api_key: str = None,
    base_url: str = DEFAULT_BASE_URL
) -> dict:
    """ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ save_to_file, filename, difficulty, modeë¥¼ LLMì„ í†µí•´ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    if OpenAI is None:
        raise ImportError("openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. 'pip install openai'ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
    
    load_dotenv()
    api_key = groq_api_key or os.getenv("GROQAI_API_KEY") or os.getenv("GROQ_API_KEY")
    if not api_key:
        raise ValueError("GROQAI_API_KEY í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” groq_api_key ì¸ìê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    client = OpenAI(base_url=base_url, api_key=api_key)
    
    prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì•„ë˜ 4ê°€ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.

- save_to_file: ë¬¸ì œ ìƒì„± ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€ (True/False)
- filename: ì €ì¥í•  íŒŒì¼ëª… (ì‚¬ìš©ìê°€ ëª…ì‹œí•˜ì§€ ì•Šìœ¼ë©´ null)
- difficulty: ë‚œì´ë„ ("ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰" ì¤‘ í•˜ë‚˜, ëª…ì‹œ ì—†ìœ¼ë©´ "ì¤‘ê¸‰")
- mode: "full_exam" ë˜ëŠ” "subject_quiz" ë˜ëŠ” "weakness_quiz" ì¤‘ í•˜ë‚˜

ì˜ˆì‹œ: {{"save_to_file": true, "filename": "ë‚´ë¬¸ì œ.json", "difficulty": "ê³ ê¸‰", "mode": "weakness_quiz"}}

ì‚¬ìš©ì ì§ˆë¬¸: {user_question}"""
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": user_question}
            ],
            temperature=temperature
        )
        content = response.choices[0].message.content
        match = re.search(r'\{[\s\S]*\}', content)
        return json.loads(match.group(0)) if match else {}
    except Exception:
        return {}

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

class BaseAgent(ABC):
    """ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ìƒì†ë°›ì•„ì•¼ í•˜ëŠ” ê¸°ë³¸ ì¶”ìƒ í´ë˜ìŠ¤ì…ë‹ˆë‹¤."""
    
    @property
    @abstractmethod
    def name(self) -> str:
        """ì—ì´ì „íŠ¸ì˜ ê³ ìœ í•œ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        pass
    
    @property
    @abstractmethod
    def description(self) -> str:
        """ì—ì´ì „íŠ¸ì˜ ì—­í• ì— ëŒ€í•œ ì„¤ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        pass
    
    @abstractmethod
    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """ì—ì´ì „íŠ¸ì˜ ì£¼ëœ ë¡œì§ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤."""
        pass


class GraphState(TypedDict):
    """ê·¸ë˜í”„ ìƒíƒœ ì •ì˜"""
    query: str
    documents: List[Document]
    context: str
    quiz_questions: List[Dict[str, Any]]
    quiz_count: int
    difficulty: str
    error: str
    used_sources: List[str]
    generation_attempts: int
    target_quiz_count: int
    subject_area: str
    validated_questions: List[Dict[str, Any]]
    weakness_analysis: Dict[str, Any]  # ì·¨ì•½ì  ë¶„ì„ ê²°ê³¼
    weakness_concepts: List[str]  # ì¶”ì¶œëœ ì·¨ì•½ì  ê°œë…ë“¤


class InfoProcessingExamAgent(BaseAgent):
    """
    ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì¶œì œê¸°ì¤€ì— ë§ëŠ” 25ë¬¸ì œ ìë™ ì¶œì œ ì—ì´ì „íŠ¸ (ìˆœì°¨ ì²˜ë¦¬ ë²„ì „)
    LLM ê¸°ë°˜ ì·¨ì•½ì  ë¶„ì„ ë° ë§ì¶¤í˜• ë¬¸ì œ ìƒì„±
    """
    
    # ì „ì—­ ìƒìˆ˜ ì‚¬ìš©
    
    def __init__(self, data_folder=DEFAULT_DATA_FOLDER, groq_api_key=None):
        """ì´ˆê¸°í™”"""
        self.data_folder = data_folder
        os.makedirs(self.data_folder, exist_ok=True)
        
        # Groq API í‚¤ ì„¤ì •
        if groq_api_key:
            os.environ["GROQ_API_KEY"] = groq_api_key
        elif not os.getenv("GROQ_API_KEY"):
            raise ValueError("Groq API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # RAG ì—”ì§„ ì´ˆê¸°í™”
        from rag_engine import RAGEngine
        self.rag_engine = RAGEngine(data_folder=data_folder)
        
        # RAG ì—”ì§„ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        print("ğŸ”¨ RAG ì—”ì§„ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì¤‘...")
        if not self.rag_engine.build_vectorstore_from_all_pdfs():
            raise ValueError(f"'{data_folder}' í´ë”ì—ì„œ PDF íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("âœ… RAG ì—”ì§„ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™” ì™„ë£Œ")
        
        self.llm = None
        self.workflow = None
        
        self._initialize_models()
        self._build_graph()
            
    @property
    def name(self) -> str:
        """ì—ì´ì „íŠ¸ì˜ ê³ ìœ í•œ ì´ë¦„ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return "InfoProcessingExamAgent"

    @property
    def description(self) -> str:
        """ì—ì´ì „íŠ¸ì˜ ì—­í• ì— ëŒ€í•œ ì„¤ëª…ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì¶œì œê¸°ì¤€ì— ë§ëŠ” 25ë¬¸ì œë¥¼ ìë™ìœ¼ë¡œ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤. PDF ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ 5ê°œ ê³¼ëª©ë³„ë¡œ ë¬¸ì œë¥¼ ìƒì„±í•˜ë©°, LLMì„ í™œìš©í•˜ì—¬ í•™ìŠµìì˜ ì·¨ì•½ì ì„ ìë™ ë¶„ì„í•˜ê³  ë§ì¶¤í˜• ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."

    def execute(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì—ì´ì „íŠ¸ì˜ ì£¼ëœ ë¡œì§ì„ ì‹¤í–‰í•˜ëŠ” ë©”ì„œë“œì…ë‹ˆë‹¤.
        
        Args:
            input_data (Dict[str, Any]): ì—ì´ì „íŠ¸ ì‹¤í–‰ì— í•„ìš”í•œ ì…ë ¥ ë°ì´í„°
                - mode: "full_exam", "subject_quiz", "weakness_quiz"
                - difficulty: "ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰" (ê¸°ë³¸ê°’: "ì¤‘ê¸‰")
                - subject_area: íŠ¹ì • ê³¼ëª©ëª… (subject_quiz ëª¨ë“œì¼ ë•Œ)
                - target_count: ìƒì„±í•  ë¬¸ì œ ìˆ˜ (subject_quiz, weakness_quiz ëª¨ë“œì¼ ë•Œ)
                - save_to_file: JSON íŒŒì¼ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
                - filename: ì €ì¥í•  íŒŒì¼ëª… (ì„ íƒì‚¬í•­)
                - analysis_file_path: ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œ (weakness_quiz ëª¨ë“œì¼ ë•Œ)
                - raw_analysis_text: ë¶„ì„ í…ìŠ¤íŠ¸ (weakness_quiz ëª¨ë“œì¼ ë•Œ)
                
        Returns:
            Dict[str, Any]: ì—ì´ì „íŠ¸ ì‹¤í–‰ ê²°ê³¼ ë°ì´í„°
                - success: ì„±ê³µ ì—¬ë¶€
                - result: ìƒì„±ëœ ì‹œí—˜ ë°ì´í„°
                - error: ì˜¤ë¥˜ ë©”ì‹œì§€ (ì‹¤íŒ¨ì‹œ)
                - file_path: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ (ì €ì¥ì‹œ)
        """
        try:
            # ì…ë ¥ ë°ì´í„° ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •
            mode = input_data.get("mode", "full_exam")
            difficulty = input_data.get("difficulty", "ì¤‘ê¸‰")
            save_to_file = input_data.get("save_to_file", False)
            filename = input_data.get("filename")
            
            # RAG ì—”ì§„ ìƒíƒœ í™•ì¸
            vectorstore_info = self.rag_engine.get_vectorstore_info()
            if not vectorstore_info.get("is_initialized", False):
                return {
                    "success": False,
                    "error": f"RAG ì—”ì§„ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                }
            
            if mode == "full_exam":
                # ì „ì²´ 25ë¬¸ì œ ìƒì„±
                result = self._generate_full_exam(difficulty)
            elif mode == "subject_quiz":
                # íŠ¹ì • ê³¼ëª© ë¬¸ì œ ìƒì„±
                subject_area = input_data.get("subject_area")
                target_count = input_data.get("target_count", 5)
                
                if not subject_area or subject_area not in SUBJECT_AREAS:
                    return {
                        "success": False,
                        "error": f"ìœ íš¨í•˜ì§€ ì•Šì€ ê³¼ëª©ëª…ì…ë‹ˆë‹¤. ê°€ëŠ¥í•œ ê³¼ëª©: {list(SUBJECT_AREAS.keys())}"
                    }
                
                result = self._generate_subject_quiz(subject_area, target_count, difficulty)
            elif mode == "weakness_quiz":
                # ì·¨ì•½ì  ê¸°ë°˜ ë¬¸ì œ ìƒì„±
                result = self._generate_weakness_quiz(input_data, difficulty)
            else:
                return {
                    "success": False,
                    "error": "ìœ íš¨í•˜ì§€ ì•Šì€ ëª¨ë“œì…ë‹ˆë‹¤. 'full_exam', 'subject_quiz', 'weakness_quiz' ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
                }
            
            # ì˜¤ë¥˜ í™•ì¸
            if "error" in result:
                return {
                    "success": False,
                    "error": result["error"]
                }
            
            response = {
                "success": True,
                "result": result
            }
            
            # íŒŒì¼ ì €ì¥ ìš”ì²­ ì‹œ
            if save_to_file:
                try:
                    file_path = self._save_to_json(result, filename)
                    response["file_path"] = file_path
                except Exception as e:
                    response["save_error"] = str(e)
            
            return response
            
        except Exception as e:
            return {
                "success": False,
                "error": f"ì—ì´ì „íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            }

    def analyze_weakness_with_llm(self, analysis_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ ë¶„ì„ ë°ì´í„°ì—ì„œ ì·¨ì•½ì ì„ ë¶„ì„í•˜ê³  í•™ìŠµ ê°œë…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            analysis_data: ë¶„ì„ ê²°ê³¼ ë°ì´í„°
            
        Returns:
            ì·¨ì•½ì  ë¶„ì„ ê²°ê³¼
        """
        try:
            # ë¶„ì„ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            analysis_text = self._convert_analysis_to_text(analysis_data)
            
            analysis_prompt = PromptTemplate(
                input_variables=["analysis_text"],
                template=WEAKNESS_ANALYSIS_PROMPT
            )
            
            prompt = analysis_prompt.format(analysis_text=analysis_text)
            
            response = self.llm.invoke(prompt)
            response_content = response.content if hasattr(response, 'content') else str(response)
            
            # JSON ì¶”ì¶œ
            match = re.search(r'\{.*\}', response_content, re.DOTALL)
            if match:
                weakness_analysis = json.loads(match.group(0))
                return weakness_analysis
            else:
                return {"error": "LLM ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
                
        except Exception as e:
            return {"error": f"ì·¨ì•½ì  LLM ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"}

    def _convert_analysis_to_text(self, analysis_data: Dict[str, Any]) -> str:
        """ë¶„ì„ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        try:
            text_parts = []
            
            # overall_assessmentì—ì„œ ì •ë³´ ì¶”ì¶œ
            overall = analysis_data.get("analysis", {}).get("overall_assessment", {})
            if overall.get("weaknesses"):
                text_parts.append(f"ì·¨ì•½ì : {overall['weaknesses']}")
            if overall.get("strengths"):
                text_parts.append(f"ê°•ì : {overall['strengths']}")
            
            # detailed_analysisì—ì„œ ì •ë³´ ì¶”ì¶œ
            detailed = analysis_data.get("analysis", {}).get("detailed_analysis", [])
            for item in detailed:
                concept_path = item.get("concept_path", "")
                mistake_type = item.get("mistake_type", "")
                analysis = item.get("analysis", "")
                
                detail_text = f"ê°œë…ê²½ë¡œ: {concept_path}, ì‹¤ìˆ˜ìœ í˜•: {mistake_type}, ë¶„ì„: {analysis}"
                text_parts.append(detail_text)
            
            return "\n\n".join(text_parts)
            
        except Exception:
            # ì›ë³¸ ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            return str(analysis_data)

    def _extract_weakness_concepts_from_analysis(self, analysis_data: Dict[str, Any]) -> List[str]:
        """
        ë¶„ì„ ê²°ê³¼ JSONì—ì„œ ì·¨ì•½ì  ê°œë…ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            analysis_data: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
            
        Returns:
            ì·¨ì•½ì  ê°œë… ë¦¬ìŠ¤íŠ¸
        """
        try:
            weakness_concepts = []
            
            # detailed_analysisì—ì„œ ê°œë… ì¶”ì¶œ
            detailed_analysis = analysis_data.get("analysis", {}).get("detailed_analysis", [])
            for item in detailed_analysis:
                analysis_text = item.get("analysis", "")
                if analysis_text:
                    # ë¶„ì„ í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ê°œë… ì¶”ì¶œ
                    # ì˜ˆ: "ìë£Œ íë¦„ë„(DFD)ì˜ êµ¬ì„± ìš”ì†Œ", "ë¯¸ë“¤ì›¨ì–´(Middleware)ì˜ ì •ì˜" ë“±
                    concepts = self._extract_concepts_from_text(analysis_text)
                    weakness_concepts.extend(concepts)
            
            # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
            unique_concepts = list(set(weakness_concepts))
            
            # ë¹ˆ ë¬¸ìì—´ì´ë‚˜ ë„ˆë¬´ ì§§ì€ ê°œë… ì œê±°
            filtered_concepts = [concept for concept in unique_concepts if concept and len(concept.strip()) > 1]
            
            # ì˜ë¯¸ ìˆëŠ” ê¸°ìˆ  ê°œë…ë§Œ í•„í„°ë§
            meaningful_concepts = []
            for concept in filtered_concepts:
                # ê¸°ìˆ  ìš©ì–´ ì‚¬ì „ì— ìˆëŠ” ê°œë…ë“¤ ìš°ì„  ì„ íƒ
                if any(tech_term.lower() in concept.lower() for tech_term in [
                    "ìë£Œ íë¦„ë„", "dfd", "ë¯¸ë“¤ì›¨ì–´", "middleware", "í”„ë¡œì„¸ìŠ¤", "process",
                    "ìë£Œ ì €ì¥ì†Œ", "data store", "ì¢…ë‹¨ì ", "terminator", "sql", "ì •ê·œí™”",
                    "uml", "ë‹¤ì´ì–´ê·¸ë¨", "íŠ¸ëœì­ì…˜", "ë³´ì•ˆ", "ë„¤íŠ¸ì›Œí¬", "ì•Œê³ ë¦¬ì¦˜",
                    "ìš”êµ¬ì‚¬í•­", "ì„¤ê³„", "ê°œë°œ", "í…ŒìŠ¤íŠ¸", "êµ¬í˜„", "ëª¨ë“ˆ", "ì¸í„°í˜ì´ìŠ¤",
                    "ê°ì²´ì§€í–¥", "íŒ¨í„´", "ë°ì´í„°ë² ì´ìŠ¤", "ê´€ê³„í˜•", "ì •ê·œí™”", "ë¬´ê²°ì„±"
                ]):
                    meaningful_concepts.append(concept)
                # 3ê¸€ì ì´ìƒì˜ í•œê¸€ ê°œë… ì¤‘ ì˜ë¯¸ ìˆëŠ” ê²ƒë“¤
                elif len(concept) >= 3 and all(ord(c) > 127 for c in concept):
                    # ì¼ë°˜ì ì¸ ì¡°ì‚¬ë‚˜ ë¶€ì‚¬ ì œì™¸
                    if concept not in ["ëŒ€í•œ", "ì„¤ëª…ì„", "ì±…ì„ìì—", "ìœ í˜•ì—", "íŠ¹ì§•ì„", "í•™ìƒì€", "ì´í•´í•˜ì§€", "ì˜¤í•´í–ˆìŠµë‹ˆë‹¤", "ì›ì¹™ê³¼", "ì¶©ë¶„íˆ", "í†µí•œ", "ìœ„í•œ", "ìˆëŠ”", "í•˜ëŠ”", "ë˜ëŠ”", "ìˆëŠ”", "í•˜ëŠ”", "ë˜ëŠ”"]:
                        meaningful_concepts.append(concept)
            
            # ì˜ë¯¸ ìˆëŠ” ê°œë…ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ê¸°ìˆ  ê°œë… ë°˜í™˜
            if not meaningful_concepts:
                meaningful_concepts = [
                    "ìë£Œ íë¦„ë„", "ë¯¸ë“¤ì›¨ì–´", "í”„ë¡œì„¸ìŠ¤", "ìë£Œ ì €ì¥ì†Œ", "SQL", "ì •ê·œí™”",
                    "UML", "ë‹¤ì´ì–´ê·¸ë¨", "íŠ¸ëœì­ì…˜", "ë³´ì•ˆ", "ë„¤íŠ¸ì›Œí¬", "ì•Œê³ ë¦¬ì¦˜"
                ]
            
            return meaningful_concepts[:10]  # ìµœëŒ€ 10ê°œê¹Œì§€ ë°˜í™˜
            
        except Exception as e:
            print(f"ì·¨ì•½ì  ê°œë… ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def _extract_concepts_from_text(self, text: str) -> List[str]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ ê°œë…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: ë¶„ì„ í…ìŠ¤íŠ¸
            
        Returns:
            ì¶”ì¶œëœ ê°œë… ë¦¬ìŠ¤íŠ¸
        """
        try:
            concepts = []
            
            # ê´„í˜¸ ì•ˆì˜ ì˜ë¬¸ ìš©ì–´ ì¶”ì¶œ (ì˜ˆ: "ìë£Œ íë¦„ë„(DFD)", "ë¯¸ë“¤ì›¨ì–´(Middleware)")
            import re
            bracket_pattern = r'([ê°€-í£\s]+)\(([A-Za-z\s]+)\)'
            bracket_matches = re.findall(bracket_pattern, text)
            for korean, english in bracket_matches:
                concepts.append(korean.strip())
                concepts.append(english.strip())
            
            # ì¼ë°˜ì ì¸ ê¸°ìˆ  ìš©ì–´ë“¤ ì¶”ì¶œ
            tech_terms = [
                "ìë£Œ íë¦„ë„", "DFD", "ë¯¸ë“¤ì›¨ì–´", "Middleware", "í”„ë¡œì„¸ìŠ¤", "Process",
                "ìë£Œ ì €ì¥ì†Œ", "Data Store", "ì¢…ë‹¨ì ", "Terminator", "SQL", "ì •ê·œí™”",
                "UML", "ë‹¤ì´ì–´ê·¸ë¨", "íŠ¸ëœì­ì…˜", "ë³´ì•ˆ", "ë„¤íŠ¸ì›Œí¬", "ì•Œê³ ë¦¬ì¦˜",
                "ìš”êµ¬ì‚¬í•­", "ì„¤ê³„", "ê°œë°œ", "í…ŒìŠ¤íŠ¸", "êµ¬í˜„", "ëª¨ë“ˆ", "ì¸í„°í˜ì´ìŠ¤",
                "ê°ì²´ì§€í–¥", "íŒ¨í„´", "ë°ì´í„°ë² ì´ìŠ¤", "ê´€ê³„í˜•", "ë¬´ê²°ì„±", "ì¸ë±ìŠ¤",
                "ë·°", "íŠ¸ë¦¬ê±°", "ì €ì¥í”„ë¡œì‹œì €", "íŠ¸ëœì­ì…˜", "ë™ì‹œì„±", "ë°ë“œë½"
            ]
            
            for term in tech_terms:
                if term.lower() in text.lower():
                    concepts.append(term)
            
            # ì˜ë¯¸ ìˆëŠ” í•œê¸€ ê°œë… ì¶”ì¶œ (3ê¸€ì ì´ìƒ, ì¡°ì‚¬/ë¶€ì‚¬ ì œì™¸)
            meaningful_korean_pattern = r'[ê°€-í£]{3,}'
            korean_matches = re.findall(meaningful_korean_pattern, text)
            
            # ì˜ë¯¸ ì—†ëŠ” ì¡°ì‚¬/ë¶€ì‚¬ ëª©ë¡
            meaningless_words = {
                "ëŒ€í•œ", "ì„¤ëª…ì„", "ì±…ì„ìì—", "ìœ í˜•ì—", "íŠ¹ì§•ì„", "í•™ìƒì€", "ì´í•´í•˜ì§€", 
                "ì˜¤í•´í–ˆìŠµë‹ˆë‹¤", "ì›ì¹™ê³¼", "ì¶©ë¶„íˆ", "í†µí•œ", "ìœ„í•œ", "ìˆëŠ”", "í•˜ëŠ”", 
                "ë˜ëŠ”", "ìˆìŠµë‹ˆë‹¤", "í•©ë‹ˆë‹¤", "ë©ë‹ˆë‹¤", "ì…ë‹ˆë‹¤", "ê²ƒì…ë‹ˆë‹¤", "ê²ƒì„",
                "ê²ƒì´", "ê²ƒì€", "ê²ƒì—", "ê²ƒìœ¼ë¡œ", "ê²ƒì„", "ê²ƒì´", "ê²ƒì€", "ê²ƒì—"
            }
            
            for match in korean_matches:
                if match not in concepts and match not in meaningless_words:
                    # ê¸°ìˆ ì  ë§¥ë½ì—ì„œ ì˜ë¯¸ ìˆëŠ” ë‹¨ì–´ì¸ì§€ í™•ì¸
                    if any(tech_word in match for tech_word in ["ì„¤ê³„", "ê°œë°œ", "í…ŒìŠ¤íŠ¸", "êµ¬í˜„", "ë¶„ì„", "ê´€ë¦¬", "ë³´ì•ˆ", "ë„¤íŠ¸ì›Œí¬", "ë°ì´í„°", "ì‹œìŠ¤í…œ", "í”„ë¡œê·¸ë¨", "ì†Œí”„íŠ¸ì›¨ì–´", "í•˜ë“œì›¨ì–´"]):
                        concepts.append(match)
            
            return concepts
            
        except Exception as e:
            print(f"ê°œë… ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def load_analysis_from_file(self, file_path: str) -> Dict[str, Any]:
        """
        ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            file_path: ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            raise ValueError(f"ë¶„ì„ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

    def _generate_weakness_quiz(self, input_data: Dict[str, Any], difficulty: str) -> Dict[str, Any]:
        """
        LLMì„ í™œìš©í•˜ì—¬ ì·¨ì•½ì ì„ ë¶„ì„í•˜ê³  ë§ì¶¤í˜• ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            input_data: ì…ë ¥ ë°ì´í„°
            difficulty: ë‚œì´ë„
            
        Returns:
            ìƒì„± ê²°ê³¼
        """
        try:
            target_count = input_data.get("target_count", 10)
            
            # ë¶„ì„ ë°ì´í„° ë¡œë“œ
            analysis_data = None
            if "analysis_file_path" in input_data:
                analysis_data = self.load_analysis_from_file(input_data["analysis_file_path"])
            elif "raw_analysis_text" in input_data:
                # í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜
                analysis_data = {"analysis_text": input_data["raw_analysis_text"]}
            else:
                return {"error": "ë¶„ì„ íŒŒì¼ ê²½ë¡œ(analysis_file_path) ë˜ëŠ” ë¶„ì„ í…ìŠ¤íŠ¸(raw_analysis_text)ê°€ í•„ìš”í•©ë‹ˆë‹¤."}
            
            # JSON íŒŒì¼ì—ì„œ ì§ì ‘ ì·¨ì•½ì  ê°œë… ì¶”ì¶œ
            weakness_concepts = self._extract_weakness_concepts_from_analysis(analysis_data)
            
            # LLMì„ ì‚¬ìš©í•˜ì—¬ ì·¨ì•½ì  ë¶„ì„ (ë°±ì—… ë°©ë²•)
            weakness_analysis = None
            if not weakness_concepts:
                weakness_analysis = self.analyze_weakness_with_llm(analysis_data)
                if "error" in weakness_analysis:
                    return {"error": weakness_analysis["error"]}
                weakness_concepts = weakness_analysis.get("weakness_concepts", [])
            
            # ì˜ë¯¸ ìˆëŠ” ê°œë…ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ ê¸°ìˆ  ê°œë… ì‚¬ìš©
            if not weakness_concepts:
                weakness_concepts = [
                    "ìë£Œ íë¦„ë„", "ë¯¸ë“¤ì›¨ì–´", "í”„ë¡œì„¸ìŠ¤", "ìë£Œ ì €ì¥ì†Œ", "SQL", "ì •ê·œí™”",
                    "UML", "ë‹¤ì´ì–´ê·¸ë¨", "íŠ¸ëœì­ì…˜", "ë³´ì•ˆ", "ë„¤íŠ¸ì›Œí¬", "ì•Œê³ ë¦¬ì¦˜"
                ]
                print(f"âš ï¸  ì¶”ì¶œëœ ê°œë…ì´ ì—†ì–´ ê¸°ë³¸ ê¸°ìˆ  ê°œë…ì„ ì‚¬ìš©í•©ë‹ˆë‹¤: {weakness_concepts}")
            
            subject_focus = weakness_analysis.get("subject_focus", []) if weakness_analysis else []
            
            if not weakness_concepts:
                return {"error": "ì·¨ì•½ì  ê°œë…ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            print(f"ğŸ§  ì¶”ì¶œëœ ì·¨ì•½ì  ê°œë…: {weakness_concepts}")
            print(f"ğŸ“š ì§‘ì¤‘ ê³¼ëª©: {subject_focus}")
            print(f"ğŸ¯ ê°œë…ë³„ ë¬¸ì œ ìƒì„± ì‹œì‘...")
            
            # ì·¨ì•½ì  ê°œë…ì„ í™œìš©í•œ ë¬¸ì œ ìƒì„±
            all_questions = []
            
            # ì·¨ì•½ì  ê°œë…ë³„ë¡œ ë¬¸ì œ ìƒì„±
            questions_per_concept = max(1, target_count // len(weakness_concepts))
            remaining_questions = target_count
            
            for i, concept in enumerate(weakness_concepts):
                if remaining_questions <= 0:
                    break
                
                # ë§ˆì§€ë§‰ ê°œë…ì—ì„œëŠ” ë‚¨ì€ ë¬¸ì œ ìˆ˜ë§Œí¼ ìƒì„±
                current_target = questions_per_concept
                if i == len(weakness_concepts) - 1:
                    current_target = remaining_questions
                else:
                    current_target = min(questions_per_concept, remaining_questions)
                
                print(f"  ğŸ“ '{concept}' ê°œë…ìœ¼ë¡œ {current_target}ê°œ ë¬¸ì œ ìƒì„± ì¤‘...")
                
                # ê°œë… ê¸°ë°˜ ë¬¸ì œ ìƒì„±
                result = self._generate_weakness_focused_questions(
                    weakness_concept=concept,
                    target_count=current_target,
                    difficulty=difficulty,
                    subject_areas=subject_focus
                )
                
                if "questions" in result and result["questions"]:
                    # ì¤‘ë³µ ë¬¸ì œ ì œê±°
                    existing_questions = [q.get('question', '') for q in all_questions]
                    new_questions = []
                    
                    for q in result["questions"]:
                        if q.get('question', '') not in existing_questions:
                            q["weakness_concept"] = concept  # ì·¨ì•½ì  ê°œë… íƒœê¹…
                            new_questions.append(q)
                            existing_questions.append(q.get('question', ''))
                    
                    all_questions.extend(new_questions)
                    remaining_questions -= len(new_questions)
                    print(f"    âœ… '{concept}' ê°œë…ìœ¼ë¡œ {len(new_questions)}ê°œ ë¬¸ì œ ìƒì„± ì™„ë£Œ")
                else:
                    print(f"    âŒ '{concept}' ê°œë…ìœ¼ë¡œ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            
            final_questions = all_questions[:target_count]
            
            return {
                "quiz_type": "weakness_based_llm",
                "difficulty": difficulty,
                "weakness_analysis": weakness_analysis if "weakness_analysis" in locals() else {"extracted_concepts": weakness_concepts},
                "weakness_concepts": weakness_concepts,
                "requested_count": target_count,
                "quiz_count": len(final_questions),
                "questions": final_questions,
                "generation_summary": {
                    "analyzed_concepts": len(weakness_concepts),
                    "generated_questions": len(final_questions),
                    "success_rate": f"{len(final_questions)/target_count*100:.1f}%",
                    "focus_subjects": subject_focus
                },
                "status": "SUCCESS" if len(final_questions) >= target_count else "PARTIAL"
            }
            
        except Exception as e:
            return {"error": f"ì·¨ì•½ì  ê¸°ë°˜ ë¬¸ì œ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"}

    def _generate_weakness_focused_questions(self, weakness_concept: str, target_count: int, difficulty: str, subject_areas: List[str] = None) -> Dict[str, Any]:
        """
        íŠ¹ì • ì·¨ì•½ì  ê°œë…ì— ì§‘ì¤‘ëœ ë¬¸ì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            weakness_concept: ì·¨ì•½ì  ê°œë…
            target_count: ìƒì„±í•  ë¬¸ì œ ìˆ˜
            difficulty: ë‚œì´ë„
            subject_areas: ì§‘ì¤‘í•  ê³¼ëª© ì˜ì—­ë“¤
            
        Returns:
            ìƒì„± ê²°ê³¼
        """
        try:
            # ê°œë… ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
            search_query = weakness_concept
            if subject_areas:
                search_query += f" {' '.join(subject_areas)}"
            
            # ê¸°ë³¸ ê³¼ëª© ì˜ì—­ ì„¤ì •
            default_subject = "ì¢…í•©"
            if subject_areas and len(subject_areas) > 0:
                default_subject = subject_areas[0]
            elif weakness_concept in ["ìš”êµ¬ì‚¬í•­", "UI ì„¤ê³„", "ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ê³„", "ì¸í„°í˜ì´ìŠ¤", "UML", "ê°ì²´ì§€í–¥", "ë””ìì¸íŒ¨í„´", "ëª¨ë“ˆí™”", "ê²°í•©ë„", "ì‘ì§‘ë„"]:
                default_subject = "ì†Œí”„íŠ¸ì›¨ì–´ì„¤ê³„"
            elif weakness_concept in ["SQL", "íŠ¸ë¦¬ê±°", "DML", "DDL", "DCL", "ì •ê·œí™”", "ê´€ê³„í˜•ëª¨ë¸", "E-Rëª¨ë¸", "ë°ì´í„°ëª¨ë¸ë§", "ë¬´ê²°ì„±"]:
                default_subject = "ë°ì´í„°ë² ì´ìŠ¤êµ¬ì¶•"
            elif weakness_concept in ["ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œë°©ë²•ë¡ ", "í”„ë¡œì íŠ¸ê´€ë¦¬", "ë³´ì•ˆ", "ì‹œìŠ¤í…œë³´ì•ˆ", "ë„¤íŠ¸ì›Œí¬ë³´ì•ˆ", "í…Œì¼ëŸ¬ë§", "ìƒëª…ì£¼ê¸°ëª¨ë¸"]:
                default_subject = "ì •ë³´ì‹œìŠ¤í…œêµ¬ì¶•ê´€ë¦¬"
            elif weakness_concept in ["ê°œë°œí™˜ê²½", "í”„ë¡œê·¸ë˜ë°ì–¸ì–´", "ë¼ì´ë¸ŒëŸ¬ë¦¬", "ìš´ì˜ì²´ì œ", "ë„¤íŠ¸ì›Œí¬", "ë°ì´í„°íƒ€ì…", "ë³€ìˆ˜", "ì—°ì‚°ì"]:
                default_subject = "í”„ë¡œê·¸ë˜ë°ì–¸ì–´í™œìš©"
            elif weakness_concept in ["ìë£Œêµ¬ì¡°", "ìŠ¤íƒ", "í", "ë¦¬ìŠ¤íŠ¸", "í†µí•©êµ¬í˜„", "ëª¨ë“ˆ", "íŒ¨í‚¤ì§•", "í…ŒìŠ¤íŠ¸ì¼€ì´ìŠ¤", "ì•Œê³ ë¦¬ì¦˜", "ì¸í„°í˜ì´ìŠ¤"]:
                default_subject = "ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œ"
            
            initial_state = {
                "query": search_query,
                "quiz_count": target_count,
                "target_quiz_count": target_count,
                "difficulty": difficulty,
                "generation_attempts": 0,
                "quiz_questions": [],
                "validated_questions": [],
                "subject_area": default_subject,
                "weakness_concepts": [weakness_concept]
            }
            
            result = self.workflow.invoke(initial_state)
            
            if result.get("error"):
                return {"error": result["error"]}
            
            return {
                "questions": result.get("validated_questions", []),
                "used_sources": result.get("used_sources", [])
            }
            
        except Exception as e:
            return {"error": str(e)}

    def _initialize_models(self):
        """LLM ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            self.llm = ChatGroq(
                model=DEFAULT_MODEL,
                temperature=0.0,
                max_tokens=DEFAULT_MAX_TOKENS,
                timeout=DEFAULT_TIMEOUT,
                max_retries=DEFAULT_MAX_RETRIES
            )
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            self.llm.invoke("ì•ˆë…•í•˜ì„¸ìš”")
            
        except Exception as e:
            raise ValueError(f"LLM ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    def _retrieve_documents(self, state: GraphState) -> GraphState:
        """ë¬¸ì„œ ê²€ìƒ‰ ë° ì¶œì²˜ ë¶„ì„ ë…¸ë“œ"""
        try:
            query = state["query"]
            subject_area = state.get("subject_area", "")
            weakness_concepts = state.get("weakness_concepts", [])
            
            print(f"ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘: query='{query}', subject_area='{subject_area}', weakness_concepts={weakness_concepts}")
            
            # RAG ì—”ì§„ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ê²€ìƒ‰
            result = self.rag_engine.retrieve_documents(
                query=query,
                subject_area=subject_area,
                weakness_concepts=weakness_concepts
            )
            
            print(f"ğŸ“‹ RAG ì—”ì§„ ê²°ê³¼: {list(result.keys()) if isinstance(result, dict) else type(result)}")
            if isinstance(result, dict):
                print(f"   - documents í‚¤ ì¡´ì¬: {'documents' in result}")
                print(f"   - documents íƒ€ì…: {type(result.get('documents'))}")
                if 'documents' in result:
                    print(f"   - documents ê¸¸ì´: {len(result['documents']) if result['documents'] else 0}")
            
            if "error" in result:
                print(f"âŒ RAG ì—”ì§„ ì˜¤ë¥˜: {result['error']}")
                return {**state, "error": result["error"]}
            
            if "documents" not in result:
                print(f"âŒ 'documents' í‚¤ê°€ ê²°ê³¼ì— ì—†ìŠµë‹ˆë‹¤!")
                return {**state, "error": "RAG ì—”ì§„ì—ì„œ 'documents' í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
            
            print(f"âœ… ë¬¸ì„œ ê²€ìƒ‰ ì„±ê³µ: {len(result['documents'])}ê°œ ë¬¸ì„œ, {len(result.get('used_sources', []))}ê°œ ì†ŒìŠ¤")
            
            return {
                **state, 
                "documents": result["documents"], 
                "used_sources": result["used_sources"]
            }
        except Exception as e:
            print(f"âŒ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            return {**state, "error": f"ë¬¸ì„œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}"}

    def _prepare_context(self, state: GraphState) -> GraphState:
        """ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ ë…¸ë“œ"""
        documents = state["documents"]
        weakness_concepts = state.get("weakness_concepts", [])
        
        # RAG ì—”ì§„ì„ ì‚¬ìš©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        context = self.rag_engine.prepare_context(
            documents=documents,
            weakness_concepts=weakness_concepts
        )
        
        return {**state, "context": context}

    def _generate_quiz_incremental(self, state: GraphState) -> GraphState:
        """ì·¨ì•½ì  ì§‘ì¤‘ ë¬¸ì œ ìƒì„±"""
        try:
            context = state["context"]
            target_quiz_count = state.get("target_quiz_count", 5)
            validated_questions = state.get("validated_questions", [])
            subject_area = state.get("subject_area", "")
            weakness_concepts = state.get("weakness_concepts", [])
            difficulty = state.get("difficulty", "ì¤‘ê¸‰")
            needed_count = target_quiz_count - len(validated_questions)
            
            if needed_count <= 0:
                return {**state, "quiz_questions": validated_questions}
            
            if not context.strip():
                return {**state, "error": "ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤."}
            
            generate_count = max(needed_count, 3)
            
            # ì·¨ì•½ì  ê°œë… ì§‘ì¤‘ ë¬¸ì œ ìƒì„± í”„ë¡¬í”„íŠ¸
            if weakness_concepts:
                weakness_focus = f"""í•™ìŠµìê°€ íŠ¹íˆ ì–´ë ¤ì›Œí•˜ëŠ” ì·¨ì•½ì  ê°œë…ë“¤: {', '.join(weakness_concepts)}
ì´ ê°œë…ë“¤ì— ëŒ€í•´ í•™ìŠµìì˜ ì´í•´ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆëŠ” ë¬¸ì œë¥¼ ì§‘ì¤‘ì ìœ¼ë¡œ ì¶œì œí•˜ì„¸ìš”.

ì·¨ì•½ì  ê°œë…ë³„ ë¬¸ì œ ìƒì„± ì§€ì¹¨:
- ê°œë…ì˜ ì •ì˜ë‚˜ íŠ¹ì§•ì„ ë¬»ëŠ” ê¸°ë³¸ ë¬¸ì œ
- ê°œë…ì„ ì‹¤ì œ ìƒí™©ì— ì ìš©í•˜ëŠ” ì‘ìš© ë¬¸ì œ  
- ë¹„ìŠ·í•œ ê°œë…ë“¤ê³¼ì˜ ì°¨ì´ì ì„ êµ¬ë¶„í•˜ëŠ” ë¬¸ì œ
- ê°œë…ì˜ êµ¬ì„±ìš”ì†Œë‚˜ ì ˆì°¨ë¥¼ ë¬»ëŠ” ë¬¸ì œ"""
                
                template_text = """ë‹¹ì‹ ì€ ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì¶œì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ í•™ìŠµìì˜ ì·¨ì•½ì ì„ ë³´ê°•í•  ìˆ˜ ìˆëŠ” {subject_area} ê´€ë ¨ ê°ê´€ì‹ ë¬¸ì œ {quiz_count}ê°œë¥¼ ìƒì„±í•˜ì„¸ìš”.

{weakness_focus}

ë‚œì´ë„: {difficulty}

[ë¬¸ì„œ ë‚´ìš©]
{context}

[ì¶œì œ ê¸°ì¤€]
1. ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì‹œí—˜ ì¶œì œ ê¸°ì¤€ì— ë§ëŠ” 4ì§€ì„ ë‹¤ ê°ê´€ì‹ ë¬¸ì œ
2. ì·¨ì•½ì  ê°œë…ì— ëŒ€í•œ ì •í™•í•œ ì´í•´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ë¬¸ì œ
3. ì‹¤ë¬´ì—ì„œ í™œìš© ê°€ëŠ¥í•œ ì‹¤ìš©ì ì¸ ë¬¸ì œ
4. ëª…í™•í•œ ì •ë‹µê³¼ í•´ì„¤ í¬í•¨

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:

{{
  "questions": [
    {{
      "question": "êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ë¬¸ì œ ë‚´ìš©",
      "options": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3", "ì„ íƒì§€4"],
      "answer": "ì •ë‹µ ë²ˆí˜¸(1, 2, 3, 4 ì¤‘ í•˜ë‚˜)",
      "explanation": "ì •ë‹µì— ëŒ€í•œ ìƒì„¸í•œ í•´ì„¤ê³¼ ì·¨ì•½ì  ê°œë… ì„¤ëª…",
      "weakness_focus": "ì§‘ì¤‘í•œ ì·¨ì•½ì  ê°œë…ëª…"
    }}
  ]
}}"""
            else:
                weakness_focus = ""
                template_text = """ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {subject_area} ê³¼ëª©ì˜ ê°ê´€ì‹ ë¬¸ì œ {quiz_count}ê°œë¥¼ ë°˜ë“œì‹œ ìƒì„±í•˜ì„¸ìš”.
ê° ë¬¸ì œëŠ” 4ì§€ì„ ë‹¤, ì •ë‹µ ë²ˆí˜¸ì™€ ê°„ë‹¨í•œ í•´ì„¤ì„ í¬í•¨í•´ì•¼ í•˜ë©°, ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.

[ë¬¸ì„œ]
{context}

[ì¶œë ¥ ì˜ˆì‹œ]
{{
  "questions": [
    {{
      "question": "ë¬¸ì œ ë‚´ìš©",
      "options": ["ì„ íƒì§€1", "ì„ íƒì§€2", "ì„ íƒì§€3", "ì„ íƒì§€4"],
      "answer": "ì •ë‹µ ë²ˆí˜¸(ì˜ˆ: 1)",
      "explanation": "ê°„ë‹¨í•œ í•´ì„¤"
    }}
  ]
}}"""
            
            prompt_template = PromptTemplate(
                input_variables=["context", "quiz_count", "subject_area", "weakness_focus", "difficulty"],
                template=template_text
            )
            
            prompt = prompt_template.format(
                context=context,
                quiz_count=generate_count,
                subject_area=subject_area,
                weakness_focus=weakness_focus,
                difficulty=difficulty
            )
            
            self.llm.temperature = 0.2
            self.llm.max_tokens = 1500
            response = self.llm.invoke(prompt)
            response_content = response.content if hasattr(response, 'content') else str(response)
            
            new_questions = self._parse_quiz_response(response_content, subject_area)
            if not new_questions:
                return {**state, "error": "ìœ íš¨í•œ ë¬¸ì œë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}
            
            return {
                **state,
                "quiz_questions": new_questions,
                "validated_questions": validated_questions,
                "generation_attempts": state.get("generation_attempts", 0) + 1
            }
        except Exception as e:
            return {**state, "error": f"ë¬¸ì œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}

    def _validate_quiz_incremental(self, state: GraphState) -> GraphState:
        """ì·¨ì•½ì  ì§‘ì¤‘ ë¬¸ì œ ê²€ì¦"""
        subject_area = state.get("subject_area", "")
        weakness_concepts = state.get("weakness_concepts", [])
        
        previously_validated = state.get("validated_questions", [])
        new_questions = state.get("quiz_questions", [])
        context = state.get("context", "")
        target_quiz_count = state.get("target_quiz_count", 5)
        generation_attempts = state.get("generation_attempts", 0)

        if not new_questions:
            return {**state, "validated_questions": previously_validated}

        newly_validated = []
        
        # ì·¨ì•½ì  ì§‘ì¤‘ ê²€ì¦ í”„ë¡¬í”„íŠ¸
        validation_template = """ë‹¹ì‹ ì€ ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì¶œì œ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì œê³µëœ 'ë¬¸ì„œ ë‚´ìš©'ì— ê·¼ê±°í•˜ì—¬ 'í€´ì¦ˆ ë¬¸ì œ'ê°€ ì·¨ì•½ì  ë³´ê°•ì— ì í•©í•œì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

[ë¬¸ì„œ ë‚´ìš©]
{context}

[ì·¨ì•½ì  ê°œë…ë“¤]
{weakness_concepts}

[í‰ê°€í•  í€´ì¦ˆ ë¬¸ì œ]
{question_data}

[í‰ê°€ ê¸°ì¤€]
1. ë¬¸ì œê°€ ë¬¸ì„œ ë‚´ìš©ì—ì„œ ì§ì ‘ì ìœ¼ë¡œ í™•ì¸ ê°€ëŠ¥í•œê°€?
2. ì·¨ì•½ì  ê°œë…ì— ëŒ€í•œ ì´í•´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ”ê°€?
3. ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì‹œí—˜ ìˆ˜ì¤€ì— ì í•©í•œ ë‚œì´ë„ì¸ê°€?
4. 4ê°œ ì„ íƒì§€ê°€ ëª…í™•í•˜ê³  ì •ë‹µì´ ìœ ì¼í•œê°€?
5. í•´ì„¤ì´ ì·¨ì•½ì  ê°œë…ì„ ì˜ ì„¤ëª…í•˜ê³  ìˆëŠ”ê°€?

í‰ê°€ ê²°ê³¼ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
{{
  "is_valid": true/false,
  "reason": "í‰ê°€ ì´ìœ  ì„¤ëª…",
  "weakness_relevance": true/false
}}"""
        
        validation_prompt_template = PromptTemplate(
            input_variables=["context", "question_data", "weakness_concepts"],
            template=validation_template
        )
        
        needed = target_quiz_count - len(previously_validated)
        weakness_concepts_str = ', '.join(weakness_concepts) if weakness_concepts else "ì¼ë°˜"
        
        for i, q in enumerate(new_questions):
            if len(newly_validated) >= needed:
                break
                
            try:
                question_str = json.dumps(q, ensure_ascii=False, indent=2)
                prompt = validation_prompt_template.format(
                    context=context[:4000], 
                    question_data=question_str,
                    weakness_concepts=weakness_concepts_str
                )
                
                response = self.llm.invoke(prompt)
                response_str = response.content if hasattr(response, 'content') else str(response)
                
                match = re.search(r'\{.*\}', response_str, re.DOTALL)
                if not match:
                    continue

                validation_result = json.loads(match.group(0))

                # ìœ íš¨ì„±ê³¼ ì·¨ì•½ì  ê´€ë ¨ì„± ëª¨ë‘ í™•ì¸
                if (validation_result.get("is_valid") is True and 
                    validation_result.get("weakness_relevance", True) is True):
                    newly_validated.append(q)

            except Exception:
                continue
        
        all_validated = previously_validated + newly_validated
        
        need_more_questions = (len(all_validated) < target_quiz_count and 
                              generation_attempts < MAX_GENERATION_ATTEMPTS)
        
        return {
            **state,
            "validated_questions": all_validated,
            "quiz_questions": all_validated,
            "need_more_questions": need_more_questions
        }

    def _check_completion(self, state: GraphState) -> str:
        """ë¬¸ì œ ìƒì„± ì™„ë£Œ ì—¬ë¶€ë¥¼ ì²´í¬í•˜ëŠ” ì¡°ê±´ë¶€ ë…¸ë“œ"""
        validated_count = len(state.get("validated_questions", []))
        target_count = state.get("target_quiz_count", 5)
        generation_attempts = state.get("generation_attempts", 0)
        
        if validated_count >= target_count:
            return "complete"
        elif generation_attempts < MAX_GENERATION_ATTEMPTS:
            return "generate_more"
        else:
            return "complete"

    def _parse_quiz_response(self, response: str, subject_area: str = "") -> List[Dict[str, Any]]:
        """ì‘ë‹µì—ì„œ JSON í˜•ì‹ì˜ ë¬¸ì œë¥¼ íŒŒì‹±"""
        try:
            json_block_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_block_match:
                json_str = json_block_match.group(1)
            else:
                json_str_match = re.search(r'\{.*\}', response.strip(), re.DOTALL)
                if not json_str_match:
                    return []
                json_str = json_str_match.group(0)

            json_str = json_str.replace('\\u312f', '').replace('\\n', ' ')
            data = json.loads(json_str)
            
            if "questions" not in data or not isinstance(data["questions"], list):
                return []
            
            for question in data["questions"]:
                if "options" in question and isinstance(question["options"], list):
                    numbered_options = []
                    for i, option_text in enumerate(question["options"], 1):
                        cleaned_text = re.sub(r'^\s*\d+\.\s*', '', option_text).strip()
                        numbered_options.append(f"  {i}. {cleaned_text}")
                    question["options"] = numbered_options
                
                if "subject" not in question:
                    question["subject"] = subject_area
            
            return data.get("questions", [])
        except:
            return []

    def _build_graph(self):
        """LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        workflow = StateGraph(GraphState)
        workflow.add_node("retrieve", self._retrieve_documents)
        workflow.add_node("prepare_context", self._prepare_context)
        workflow.add_node("generate_quiz", self._generate_quiz_incremental)
        workflow.add_node("validate_quiz", self._validate_quiz_incremental)
        
        workflow.set_entry_point("retrieve")
        workflow.add_edge("retrieve", "prepare_context")
        workflow.add_edge("prepare_context", "generate_quiz")
        workflow.add_edge("generate_quiz", "validate_quiz")
        
        workflow.add_conditional_edges(
            "validate_quiz",
            self._check_completion,
            {
                "generate_more": "generate_quiz",
                "complete": END
            }
        )
        
        self.workflow = workflow.compile()

    def _generate_subject_quiz(self, subject_area: str, target_count: int = 5, difficulty: str = "ì¤‘ê¸‰") -> Dict[str, Any]:
        """íŠ¹ì • ê³¼ëª©ì˜ ë¬¸ì œë¥¼ ìˆœì°¨ë¡œ ìƒì„±"""
        if subject_area not in SUBJECT_AREAS:
            return {"error": f"ìœ íš¨í•˜ì§€ ì•Šì€ ê³¼ëª©: {subject_area}"}
        
        keywords = SUBJECT_AREAS[subject_area]["keywords"]
        
        all_validated_questions = []
        
        current_round = 0
        
        while len(all_validated_questions) < target_count and current_round < MAX_ROUNDS:
            current_round += 1
            remaining_needed = target_count - len(all_validated_questions)
            
            # í‚¤ì›Œë“œë¥¼ 2-3ê°œì”© ë¬¶ì–´ì„œ ìˆœì°¨ ì²˜ë¦¬
            for i in range(0, len(keywords), 2):
                if len(all_validated_questions) >= target_count:
                    break
                    
                combo = " ".join(keywords[i:i+3])
                
                result = self._generate_with_keywords(combo, subject_area, remaining_needed, difficulty)
                
                if "questions" in result and result["questions"]:
                    new_questions = []
                    existing_questions = [q.get('question', '') for q in all_validated_questions]
                    
                    for q in result["questions"]:
                        if q.get('question', '') not in existing_questions:
                            new_questions.append(q)
                            existing_questions.append(q.get('question', ''))
                    
                    all_validated_questions.extend(new_questions)
                
                if len(all_validated_questions) >= target_count:
                    break
            
            if current_round < MAX_ROUNDS and len(all_validated_questions) < target_count:
                time.sleep(2)
        
        final_questions = all_validated_questions[:target_count]
        
        return {
            "subject_area": subject_area,
            "difficulty": difficulty,
            "requested_count": target_count,
            "quiz_count": len(final_questions),
            "questions": final_questions,
            "status": "SUCCESS" if len(final_questions) >= target_count else "PARTIAL"
        }

    def _generate_with_keywords(self, query: str, subject_area: str, needed_count: int, difficulty: str) -> Dict[str, Any]:
        """íŠ¹ì • í‚¤ì›Œë“œë¡œ ë¬¸ì œ ìƒì„±"""
        try:
            initial_state = {
                "query": query,
                "quiz_count": needed_count,
                "target_quiz_count": needed_count,
                "difficulty": difficulty,
                "generation_attempts": 0,
                "quiz_questions": [],
                "validated_questions": [],
                "subject_area": subject_area
            }
            
            result = self.workflow.invoke(initial_state)
            
            if result.get("error"):
                return {"error": result["error"]}
            
            return {
                "questions": result.get("validated_questions", []),
                "used_sources": result.get("used_sources", [])
            }
            
        except Exception as e:
            return {"error": str(e)}

    def _generate_full_exam(self, difficulty: str = "ì¤‘ê¸‰") -> Dict[str, Any]:
        """ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ì „ì²´ 25ë¬¸ì œë¥¼ ìˆœì°¨ë¡œ ìƒì„±"""
        start_time = time.time()
        
        full_exam_result = {
            "exam_title": "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ëª¨ì˜ê³ ì‚¬",
            "total_questions": 0,
            "difficulty": difficulty,
            "subjects": {},
            "all_questions": [],
            "generation_summary": {},
            "failed_subjects": [],
            "model_info": "Groq llama-4-scout-17b-16e-instruct with LLM weakness analysis"
        }
        
        total_generated = 0
        
        for i, (subject_area, subject_info) in enumerate(SUBJECT_AREAS.items(), 1):
            target_count = subject_info["count"]
            
            subject_result = self._generate_subject_quiz(
                subject_area=subject_area,
                target_count=target_count,
                difficulty=difficulty
            )
            
            if "error" in subject_result:
                full_exam_result["failed_subjects"].append({
                    "subject": subject_area,
                    "error": subject_result["error"]
                })
            else:
                questions = subject_result["questions"]
                actual_count = len(questions)
                total_generated += actual_count
                
                full_exam_result["subjects"][subject_area] = {
                    "requested_count": target_count,
                    "actual_count": actual_count,
                    "questions": questions,
                    "status": subject_result.get("status", "UNKNOWN")
                }
                
                full_exam_result["all_questions"].extend(questions)
            
            if i < 5:
                time.sleep(2)
        
        elapsed_time = time.time() - start_time
        
        full_exam_result["total_questions"] = total_generated
        full_exam_result["generation_summary"] = {
            "target_total": 25,
            "actual_total": total_generated,
            "success_rate": f"{total_generated/25*100:.1f}%",
            "successful_subjects": 5 - len(full_exam_result["failed_subjects"]),
            "failed_subjects": len(full_exam_result["failed_subjects"]),
            "completion_status": "COMPLETE" if total_generated >= 25 else "PARTIAL",
            "generation_time": f"{elapsed_time:.1f}ì´ˆ"
        }
        
        return full_exam_result

    def _save_to_json(self, exam_result: Dict[str, Any], filename: str = None) -> str:
        """ì‹œí—˜ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
        save_dir = DEFAULT_SAVE_DIR
        os.makedirs(save_dir, exist_ok=True)
        
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            if "exam_title" in exam_result:
                filename = f"ì •ë³´ì²˜ë¦¬ê¸°ì‚¬_25ë¬¸ì œ_{timestamp}.json"
            elif "quiz_type" in exam_result and exam_result["quiz_type"] == "weakness_based_llm":
                concepts = "_".join([c[:10] for c in exam_result.get("weakness_concepts", ["ì·¨ì•½ì "])[:3]])
                count = exam_result.get("quiz_count", 0)
                filename = f"LLMì·¨ì•½ì ë§ì¶¤_{concepts}_{count}ë¬¸ì œ_{timestamp}.json"
            else:
                subject = exam_result.get("subject_area", "ë¬¸ì œ")
                count = exam_result.get("quiz_count", 0)
                filename = f"{subject}_{count}ë¬¸ì œ_{timestamp}.json"
        
        if not os.path.isabs(filename):
            filename = os.path.join(save_dir, filename)
        elif not filename.startswith(save_dir):
            filename = os.path.join(save_dir, os.path.basename(filename))
            
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(exam_result, f, ensure_ascii=False, indent=2)
        
        return filename


# LLM ì·¨ì•½ì  ë¶„ì„ ì „ìš© í¸ì˜ í•¨ìˆ˜ë“¤

def generate_weakness_quiz_from_analysis_llm(
    agent: InfoProcessingExamAgent,
    analysis_file_path: str,
    target_count: int = 10,
    difficulty: str = "ì¤‘ê¸‰",
    save_to_file: bool = True,
    filename: str = None
) -> Dict[str, Any]:
    """
    LLMì„ í™œìš©í•˜ì—¬ ë¶„ì„ ê²°ê³¼ íŒŒì¼ì„ ê¸°ë°˜ìœ¼ë¡œ ì·¨ì•½ì  ë§ì¶¤ ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Args:
        agent: InfoProcessingExamAgent ì¸ìŠ¤í„´ìŠ¤
        analysis_file_path: ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œ
        target_count: ìƒì„±í•  ë¬¸ì œ ìˆ˜
        difficulty: ë‚œì´ë„
        save_to_file: íŒŒì¼ ì €ì¥ ì—¬ë¶€
        filename: ì €ì¥í•  íŒŒì¼ëª…
        
    Returns:
        ìƒì„± ê²°ê³¼
    """
    input_data = {
        "mode": "weakness_quiz",
        "analysis_file_path": analysis_file_path,
        "target_count": target_count,
        "difficulty": difficulty,
        "save_to_file": save_to_file,
        "filename": filename
    }
    
    return agent.execute(input_data)


def generate_weakness_quiz_from_text_llm(
    agent: InfoProcessingExamAgent,
    analysis_text: str,
    target_count: int = 8,
    difficulty: str = "ì¤‘ê¸‰",
    save_to_file: bool = True,
    filename: str = None
) -> Dict[str, Any]:
    """
    LLMì„ í™œìš©í•˜ì—¬ ë¶„ì„ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì·¨ì•½ì  ë§ì¶¤ ë¬¸ì œë¥¼ ìƒì„±í•˜ëŠ” í¸ì˜ í•¨ìˆ˜
    
    Args:
        agent: InfoProcessingExamAgent ì¸ìŠ¤í„´ìŠ¤
        analysis_text: ë¶„ì„ í…ìŠ¤íŠ¸ ë‚´ìš©
        target_count: ìƒì„±í•  ë¬¸ì œ ìˆ˜
        difficulty: ë‚œì´ë„
        save_to_file: íŒŒì¼ ì €ì¥ ì—¬ë¶€
        filename: ì €ì¥í•  íŒŒì¼ëª…
        
    Returns:
        ìƒì„± ê²°ê³¼
    """
    input_data = {
        "mode": "weakness_quiz",
        "raw_analysis_text": analysis_text,
        "target_count": target_count,
        "difficulty": difficulty,
        "save_to_file": save_to_file,
        "filename": filename
    }
    
    return agent.execute(input_data)


# ì—…ë°ì´íŠ¸ëœ ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤
def interactive_menu_llm():
    """LLM ê¸°ë°˜ ì·¨ì•½ì  ë¶„ì„ì„ í¬í•¨í•œ ëŒ€í™”í˜• ë©”ë‰´ ì‹œìŠ¤í…œ"""
    try:
        agent = InfoProcessingExamAgent(
            data_folder=DEFAULT_DATA_FOLDER
        )
        
        print(f"\nğŸ§  {agent.name} ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"ğŸ“– ì„¤ëª…: {agent.description}")
        
        while True:
            print("\n" + "="*70)
            print("  ğŸ§  LLM ê¸°ë°˜ ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ë§ì¶¤í˜• ë¬¸ì œ ìƒì„± ì—ì´ì „íŠ¸")
            print("="*70)
            print("1. ì „ì²´ 25ë¬¸ì œ ìƒì„±")
            print("2. íŠ¹ì • ê³¼ëª©ë§Œ ë¬¸ì œ ìƒì„±")
            print("3. ğŸ§  LLM ì·¨ì•½ì  ë¶„ì„ + ë§ì¶¤ ë¬¸ì œ ìƒì„± (íŒŒì¼)")
            print("4. ğŸ§  LLM ì·¨ì•½ì  ë¶„ì„ + ë§ì¶¤ ë¬¸ì œ ìƒì„± (í…ìŠ¤íŠ¸)")
            print("5. ì‚¬ìš© ê°€ëŠ¥í•œ PDF ëª©ë¡ ë³´ê¸°")
            print("0. ì¢…ë£Œ")
            print("-"*70)
            
            choice = input("ì„ íƒí•˜ì„¸ìš”: ").strip()
            
            if choice == "1":
                # ì „ì²´ 25ë¬¸ì œ ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)
                difficulty = input("ë‚œì´ë„ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰, ê¸°ë³¸ê°’: ì¤‘ê¸‰): ").strip()
                if difficulty not in ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"]:
                    difficulty = "ì¤‘ê¸‰"
                
                save_option = input("JSON íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                save_to_file = save_option == 'y'
                
                filename = None
                if save_to_file:
                    filename_input = input("íŒŒì¼ëª… (ì—”í„°: ìë™ìƒì„±): ").strip()
                    if filename_input:
                        filename = filename_input
                
                input_data = {
                    "mode": "full_exam",
                    "difficulty": difficulty,
                    "save_to_file": save_to_file,
                    "filename": filename
                }
                
                print("\nì „ì²´ 25ë¬¸ì œ ìƒì„± ì¤‘...")
                result = agent.execute(input_data)
                
                if result["success"]:
                    exam_data = result["result"]
                    summary = exam_data.get("generation_summary", {})
                    
                    print(f"\nâœ… ìƒì„± ì™„ë£Œ!")
                    print(f"ì „ì²´ ë¬¸ì œ ìˆ˜: {summary.get('actual_total', 0)}/25ë¬¸ì œ")
                    print(f"ì„±ê³µë¥ : {summary.get('success_rate', '0%')}")
                    print(f"ì†Œìš” ì‹œê°„: {summary.get('generation_time', 'N/A')}")
                    
                    if "file_path" in result:
                        print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {result['file_path']}")
                else:
                    print(f"âŒ ì‹¤íŒ¨: {result['error']}")
            
            elif choice == "2":
                # íŠ¹ì • ê³¼ëª© ë¬¸ì œ ìƒì„± (ê¸°ì¡´ê³¼ ë™ì¼)
                print("\n[ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ê³¼ëª© ì„ íƒ]")
                subjects = list(agent.SUBJECT_AREAS.keys())
                for i, subject in enumerate(subjects, 1):
                    count = agent.SUBJECT_AREAS[subject]["count"]
                    print(f"{i}. {subject} ({count}ë¬¸ì œ)")
                
                try:
                    subject_choice = int(input("ê³¼ëª© ë²ˆí˜¸ ì„ íƒ: "))
                    if 1 <= subject_choice <= len(subjects):
                        selected_subject = subjects[subject_choice - 1]
                        default_count = agent.SUBJECT_AREAS[selected_subject]["count"]
                        
                        count_input = input(f"ìƒì„±í•  ë¬¸ì œ ìˆ˜ (ê¸°ë³¸ê°’: {default_count}): ").strip()
                        target_count = int(count_input) if count_input.isdigit() else default_count
                        
                        difficulty = input("ë‚œì´ë„ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰, ê¸°ë³¸ê°’: ì¤‘ê¸‰): ").strip()
                        if difficulty not in ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"]:
                            difficulty = "ì¤‘ê¸‰"
                        
                        save_option = input("JSON íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                        save_to_file = save_option == 'y'
                        
                        filename = None
                        if save_to_file:
                            filename_input = input("íŒŒì¼ëª… (ì—”í„°: ìë™ìƒì„±): ").strip()
                            if filename_input:
                                filename = filename_input
                        
                        input_data = {
                            "mode": "subject_quiz",
                            "subject_area": selected_subject,
                            "target_count": target_count,
                            "difficulty": difficulty,
                            "save_to_file": save_to_file,
                            "filename": filename
                        }
                        
                        print(f"\n{selected_subject} ê³¼ëª© {target_count}ë¬¸ì œ ìƒì„± ì¤‘...")
                        result = agent.execute(input_data)
                        
                        if result["success"]:
                            subject_data = result["result"]
                            print(f"âœ… ìƒì„± ì™„ë£Œ!")
                            print(f"{subject_data['subject_area']}: {subject_data['quiz_count']}/{subject_data['requested_count']}ë¬¸ì œ")
                            print(f"ìƒíƒœ: {subject_data.get('status', 'UNKNOWN')}")
                            
                            if "file_path" in result:
                                print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {result['file_path']}")
                        else:
                            print(f"âŒ ì‹¤íŒ¨: {result['error']}")
                    else:
                        print("ìœ íš¨í•˜ì§€ ì•Šì€ ê³¼ëª© ë²ˆí˜¸ì…ë‹ˆë‹¤.")
                except ValueError:
                    print("ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            elif choice == "3":
                # LLM ê¸°ë°˜ ì·¨ì•½ì  ë¶„ì„ + ë§ì¶¤ ë¬¸ì œ ìƒì„± (íŒŒì¼)
                print("\nğŸ§  [LLM ê¸°ë°˜ ì·¨ì•½ì  ë¶„ì„ + ë§ì¶¤ ë¬¸ì œ ìƒì„± - íŒŒì¼]")
                
                analysis_file_path = input("ë¶„ì„ ê²°ê³¼ JSON íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
                
                if not os.path.exists(analysis_file_path):
                    print("âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    continue
                
                try:
                    # ë¶„ì„ íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°
                    with open(analysis_file_path, 'r', encoding='utf-8') as f:
                        analysis_data = json.load(f)
                    
                    print(f"\nğŸ“‹ ë¶„ì„ íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
                    
                    count_input = input("ìƒì„±í•  ë¬¸ì œ ìˆ˜ (ê¸°ë³¸ê°’: 10): ").strip()
                    target_count = int(count_input) if count_input.isdigit() else 10
                    
                    difficulty = input("ë‚œì´ë„ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰, ê¸°ë³¸ê°’: ì¤‘ê¸‰): ").strip()
                    if difficulty not in ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"]:
                        difficulty = "ì¤‘ê¸‰"
                    
                    save_option = input("JSON íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                    save_to_file = save_option == 'y'
                    
                    filename = None
                    if save_to_file:
                        filename_input = input("íŒŒì¼ëª… (ì—”í„°: ìë™ìƒì„±): ").strip()
                        if filename_input:
                            filename = filename_input
                    
                    print(f"\nğŸ§  LLMì´ ì·¨ì•½ì ì„ ë¶„ì„í•˜ê³  ë§ì¶¤ ë¬¸ì œ {target_count}ê°œë¥¼ ìƒì„± ì¤‘...")
                    
                    result = generate_weakness_quiz_from_analysis_llm(
                        agent=agent,
                        analysis_file_path=analysis_file_path,
                        target_count=target_count,
                        difficulty=difficulty,
                        save_to_file=save_to_file,
                        filename=filename
                    )
                    
                    if result["success"]:
                        weakness_data = result["result"]
                        print(f"\nâœ… LLM ì·¨ì•½ì  ë¶„ì„ ë° ë§ì¶¤ ë¬¸ì œ ìƒì„± ì™„ë£Œ!")
                        print(f"ğŸ§  LLMì´ ë¶„ì„í•œ ì·¨ì•½ì  ê°œë…: {weakness_data.get('weakness_concepts', [])}")
                        print(f"ğŸ“š ì§‘ì¤‘ ì¶”ì²œ ê³¼ëª©: {weakness_data.get('weakness_analysis', {}).get('subject_focus', [])}")
                        print(f"ğŸ¯ ì¶”ì²œ ë‚œì´ë„: {weakness_data.get('weakness_analysis', {}).get('difficulty_level', 'ì¤‘ê¸‰')}")
                        print(f"ğŸ“Š ìƒì„±ëœ ë¬¸ì œ ìˆ˜: {weakness_data.get('quiz_count', 0)}/{weakness_data.get('requested_count', 0)}")
                        print(f"ğŸ“ˆ ì„±ê³µë¥ : {weakness_data.get('generation_summary', {}).get('success_rate', '0%')}")
                        
                        # í•™ìŠµ ìš°ì„ ìˆœìœ„ í‘œì‹œ
                        learning_priorities = weakness_data.get('weakness_analysis', {}).get('learning_priorities', [])
                        if learning_priorities:
                            print(f"ğŸ“ ì¶”ì²œ í•™ìŠµ ìˆœì„œ:")
                            for i, priority in enumerate(learning_priorities[:5], 1):
                                print(f"  {i}. {priority}")
                        
                        # ë¬¸ì œ ë¯¸ë¦¬ë³´ê¸°
                        questions = weakness_data.get("questions", [])
                        if questions and input("\nìƒì„±ëœ ë¬¸ì œë¥¼ ë¯¸ë¦¬ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower() == 'y':
                            for i, q in enumerate(questions[:2], 1):
                                weakness_concept = q.get('weakness_concept', 'ì¼ë°˜')
                                weakness_focus = q.get('weakness_focus', weakness_concept)
                                print(f"\n[ğŸ¯ ì·¨ì•½ì  ì§‘ì¤‘: {weakness_focus}] [ë¬¸ì œ {i}]")
                                print(f"â“ {q.get('question', '')}")
                                for option in q.get('options', []):
                                    print(f"{option}")
                                print(f"âœ… ì •ë‹µ: {q.get('answer', '')}")
                                print(f"ğŸ’¡ í•´ì„¤: {q.get('explanation', '')}")
                                if i < 2 and i < len(questions):
                                    input("ë‹¤ìŒ ë¬¸ì œë¥¼ ë³´ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
                            
                            if len(questions) > 2:
                                print(f"\n... ì™¸ {len(questions)-2}ê°œ ë¬¸ì œê°€ ë” ìˆìŠµë‹ˆë‹¤.")
                        
                        if "file_path" in result:
                            print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {result['file_path']}")
                    else:
                        print(f"âŒ ì‹¤íŒ¨: {result['error']}")
                        
                except Exception as e:
                    print(f"âŒ ë¶„ì„ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            
            elif choice == "4":
                # LLM ê¸°ë°˜ ì·¨ì•½ì  ë¶„ì„ + ë§ì¶¤ ë¬¸ì œ ìƒì„± (í…ìŠ¤íŠ¸)
                print("\nğŸ§  [LLM ê¸°ë°˜ ì·¨ì•½ì  ë¶„ì„ + ë§ì¶¤ ë¬¸ì œ ìƒì„± - í…ìŠ¤íŠ¸ ì…ë ¥]")
                
                print("í•™ìŠµìì˜ ì·¨ì•½ì ì´ë‚˜ ë¶„ì„ ë‚´ìš©ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ì„¸ìš”.")
                print("ì˜ˆ: 'ìë£Œíë¦„ë„ êµ¬ì„±ìš”ì†Œ ì´í•´ ë¶€ì¡±, SQL ì¡°ì¸ ì—°ì‚° ì‹¤ìˆ˜ ë§ìŒ, UML ë‹¤ì´ì–´ê·¸ë¨ í•´ì„ ì–´ë ¤ì›€'")
                print("(ì—¬ëŸ¬ ì¤„ ì…ë ¥ ê°€ëŠ¥, ì™„ë£Œ í›„ ë¹ˆ ì¤„ì—ì„œ Enter)")
                
                analysis_lines = []
                while True:
                    line = input()
                    if line.strip() == "":
                        break
                    analysis_lines.append(line)
                
                analysis_text = "\n".join(analysis_lines)
                
                if not analysis_text.strip():
                    print("âŒ ë¶„ì„ ë‚´ìš©ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    continue
                
                print(f"\nğŸ“ ì…ë ¥ëœ ë¶„ì„ ë‚´ìš©:")
                print(f"{analysis_text[:200]}...")
                
                count_input = input("\nìƒì„±í•  ë¬¸ì œ ìˆ˜ (ê¸°ë³¸ê°’: 8): ").strip()
                target_count = int(count_input) if count_input.isdigit() else 8
                
                difficulty = input("ë‚œì´ë„ (ì´ˆê¸‰/ì¤‘ê¸‰/ê³ ê¸‰, ê¸°ë³¸ê°’: ì¤‘ê¸‰): ").strip()
                if difficulty not in ["ì´ˆê¸‰", "ì¤‘ê¸‰", "ê³ ê¸‰"]:
                    difficulty = "ì¤‘ê¸‰"
                
                save_option = input("JSON íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
                save_to_file = save_option == 'y'
                
                filename = None
                if save_to_file:
                    filename_input = input("íŒŒì¼ëª… (ì—”í„°: ìë™ìƒì„±): ").strip()
                    if filename_input:
                        filename = filename_input
                
                print(f"\nğŸ§  LLMì´ ì…ë ¥ ë‚´ìš©ì„ ë¶„ì„í•˜ê³  ë§ì¶¤ ë¬¸ì œ {target_count}ê°œë¥¼ ìƒì„± ì¤‘...")
                
                result = generate_weakness_quiz_from_text_llm(
                    agent=agent,
                    analysis_text=analysis_text,
                    target_count=target_count,
                    difficulty=difficulty,
                    save_to_file=save_to_file,
                    filename=filename
                )
                
                if result["success"]:
                    weakness_data = result["result"]
                    print(f"\nâœ… LLM í…ìŠ¤íŠ¸ ë¶„ì„ ë° ë§ì¶¤ ë¬¸ì œ ìƒì„± ì™„ë£Œ!")
                    print(f"ğŸ§  LLMì´ ì¶”ì¶œí•œ ì·¨ì•½ì : {weakness_data.get('weakness_concepts', [])}")
                    print(f"ğŸ“š ì§‘ì¤‘ ì¶”ì²œ ê³¼ëª©: {weakness_data.get('weakness_analysis', {}).get('subject_focus', [])}")
                    print(f"ğŸ¯ LLM ì¶”ì²œ ë‚œì´ë„: {weakness_data.get('weakness_analysis', {}).get('difficulty_level', 'ì¤‘ê¸‰')}")
                    print(f"ğŸ“Š ìƒì„±ëœ ë¬¸ì œ ìˆ˜: {weakness_data.get('quiz_count', 0)}/{weakness_data.get('requested_count', 0)}")
                    print(f"ğŸ“ˆ ì„±ê³µë¥ : {weakness_data.get('generation_summary', {}).get('success_rate', '0%')}")
                    
                    # ì¶”ì²œ ë¬¸ì œ ìœ í˜• í‘œì‹œ
                    question_types = weakness_data.get('weakness_analysis', {}).get('question_types', [])
                    if question_types:
                        print(f"ğŸ“‹ ì¶”ì²œ ë¬¸ì œ ìœ í˜•: {', '.join(question_types)}")
                    
                    # ë¬¸ì œ ë¯¸ë¦¬ë³´ê¸°
                    questions = weakness_data.get("questions", [])
                    if questions and input("\nìƒì„±ëœ ë¬¸ì œë¥¼ ë¯¸ë¦¬ë³´ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower() == 'y':
                        for i, q in enumerate(questions[:2], 1):
                            weakness_concept = q.get('weakness_concept', 'ì¼ë°˜')
                            weakness_focus = q.get('weakness_focus', weakness_concept)
                            print(f"\n[ğŸ¯ ì·¨ì•½ì  ì§‘ì¤‘: {weakness_focus}] [ë¬¸ì œ {i}]")
                            print(f"â“ {q.get('question', '')}")
                            for option in q.get('options', []):
                                print(f"{option}")
                            print(f"âœ… ì •ë‹µ: {q.get('answer', '')}")
                            print(f"ğŸ’¡ í•´ì„¤: {q.get('explanation', '')}")
                            if i < 2 and i < len(questions):
                                input("ë‹¤ìŒ ë¬¸ì œë¥¼ ë³´ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")
                        
                        if len(questions) > 2:
                            print(f"\n... ì™¸ {len(questions)-2}ê°œ ë¬¸ì œê°€ ë” ìˆìŠµë‹ˆë‹¤.")
                    
                    if "file_path" in result:
                        print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {result['file_path']}")
                else:
                    print(f"âŒ ì‹¤íŒ¨: {result['error']}")
            
            elif choice == "5":
                # PDF íŒŒì¼ ëª©ë¡ ë³´ê¸° (RAG ì—”ì§„ ì‚¬ìš©)
                pdf_files = agent.rag_engine.get_pdf_files()
                if pdf_files:
                    print(f"\n=== '{agent.rag_engine.data_folder}' í´ë”ì˜ PDF íŒŒì¼ ëª©ë¡ ===")
                    for i, file_path in enumerate(pdf_files, 1):
                        filename = os.path.basename(file_path)
                        file_size = os.path.getsize(file_path) / 1024
                        print(f"{i}. {filename} ({file_size:.1f} KB)")
                else:
                    print(f"'{agent.rag_engine.data_folder}' í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            elif choice == "0":
                print("ğŸ§  LLM ê¸°ë°˜ ì—ì´ì „íŠ¸ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            
            else:
                print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 0~5 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")
    
    except Exception as e:
        print(f"ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # Groq API í‚¤ í™•ì¸
    if not os.getenv("GROQ_API_KEY"):
        print("GROQ_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # ì‚¬ìš© ë°©ë²• ì„ íƒ
    print("ğŸ§  LLM ê¸°ë°˜ ì •ë³´ì²˜ë¦¬ê¸°ì‚¬ ë§ì¶¤í˜• ë¬¸ì œ ìƒì„± ì—ì´ì „íŠ¸")
    print("1. ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤ ì‚¬ìš©")
    print("2. LLM ì·¨ì•½ì  ë¶„ì„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    
    choice = input("ì„ íƒí•˜ì„¸ìš” (1 ë˜ëŠ” 2): ").strip()
    
    if choice == "1":
        interactive_menu_llm()
    elif choice == "2":
        # JSON íŒŒì¼ì—ì„œ ì·¨ì•½ì  ë¶„ì„ í…ŒìŠ¤íŠ¸
        try:
            agent = InfoProcessingExamAgent()
            
            # test_sample í´ë”ì—ì„œ ë¶„ì„ íŒŒì¼ ì„ íƒ
            test_sample_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "test_sample")
            
            if not os.path.exists(test_sample_dir):
                print(f"âŒ test_sample í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_sample_dir}")
                return
            
            # í´ë” ë‚´ JSON íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            json_files = [f for f in os.listdir(test_sample_dir) if f.endswith('.json')]
            
            if not json_files:
                print(f"âŒ {test_sample_dir} í´ë”ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            print(f"\nğŸ“ {test_sample_dir} í´ë”ì˜ ë¶„ì„ íŒŒì¼ ëª©ë¡:")
            for i, filename in enumerate(json_files, 1):
                file_path = os.path.join(test_sample_dir, filename)
                file_size = os.path.getsize(file_path) / 1024
                print(f"{i}. {filename} ({file_size:.1f} KB)")
            
            # ì‚¬ìš©ìê°€ íŒŒì¼ ì„ íƒ
            while True:
                try:
                    file_choice = input(f"\në¶„ì„í•  íŒŒì¼ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš” (1-{len(json_files)}): ").strip()
                    file_index = int(file_choice) - 1
                    
                    if 0 <= file_index < len(json_files):
                        selected_filename = json_files[file_index]
                        analysis_file_path = os.path.join(test_sample_dir, selected_filename)
                        break
                    else:
                        print(f"1-{len(json_files)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                except ValueError:
                    print("ìœ íš¨í•œ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            print(f"\nğŸ“ ì„ íƒëœ ë¶„ì„ íŒŒì¼: {selected_filename}")
            print(f"ğŸ“ íŒŒì¼ ê²½ë¡œ: {analysis_file_path}")
            
            analysis_data = agent.load_analysis_from_file(analysis_file_path)
            
            print("ğŸ§  JSON íŒŒì¼ì—ì„œ ì·¨ì•½ì  ê°œë… ì¶”ì¶œ ì¤‘...")
            weakness_concepts = agent._extract_weakness_concepts_from_analysis(analysis_data)
            
            if weakness_concepts:
                print(f"âœ… ì·¨ì•½ì  ê°œë… ì¶”ì¶œ ì™„ë£Œ!")
                print(f"ğŸ§  ì¶”ì¶œëœ ì·¨ì•½ì  ê°œë…: {weakness_concepts}")
                
                print("\nğŸ”§ ì¶”ì¶œëœ ì·¨ì•½ì  ê¸°ë°˜ ë§ì¶¤ ë¬¸ì œ ìƒì„± ì¤‘...")
                result = agent._generate_weakness_quiz(
                    input_data={
                        "analysis_file_path": analysis_file_path,
                        "target_count": 5
                    },
                    difficulty="ì¤‘ê¸‰"
                )
                
                if "error" not in result:
                    print(f"âœ… ë¬¸ì œ ìƒì„± ì™„ë£Œ!")
                    print(f"ğŸ“ ìƒì„±ëœ ë¬¸ì œ ìˆ˜: {result.get('quiz_count', 0)}")
                    print(f"ğŸ¯ ì·¨ì•½ì  ê°œë… ìˆ˜: {result.get('generation_summary', {}).get('analyzed_concepts', 0)}")
                    
                    # ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (ìë™ ë²ˆí˜¸ ì¦ê°€)
                    base_filename = "weakness_based_quiz"
                    counter = 1
                    
                    # ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë‹¤ìŒ ë²ˆí˜¸ ì°¾ê¸°
                    while os.path.exists(f"{base_filename}{counter}_result.json"):
                        counter += 1
                    
                    output_file = f"{base_filename}{counter}_result.json"
                    with open(output_file, 'w', encoding='utf-8') as f:
                        json.dump(result, f, ensure_ascii=False, indent=2)
                    print(f"ğŸ’¾ ê²°ê³¼ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    print(f"âŒ ë¬¸ì œ ìƒì„± ì‹¤íŒ¨: {result['error']}")
            else:
                print("âŒ ì·¨ì•½ì  ê°œë…ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âŒ ì·¨ì•½ì  ë¶„ì„ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            import traceback
            traceback.print_exc()
    else:
        print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤.")


if __name__ == "__main__":
    main()

