import os
import glob
from typing import List, Dict, Any
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from langchain_huggingface import HuggingFaceEmbeddings
from collections import Counter


class RAGEngine:
    """
    RAG(Retrieval-Augmented Generation) ì—”ì§„
    PDF íŒŒì¼ ë¡œë”©, ì„ë² ë”©, ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬, ë¬¸ì„œ ê²€ìƒ‰ì„ ë‹´ë‹¹
    """
    
    def __init__(self, data_folder: str = os.path.join(os.path.dirname(__file__),"data")):
        """
        RAG ì—”ì§„ ì´ˆê¸°í™”
        
        Args:
            data_folder: PDF íŒŒì¼ì´ ì €ì¥ëœ í´ë” ê²½ë¡œ
        """
        self.data_folder = data_folder
        os.makedirs(self.data_folder, exist_ok=True)
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        self.embeddings_model = None
        self.vectorstore = None
        self.retriever = None
        
        # ë²¡í„° ìŠ¤í† ì–´ì— í¬í•¨ëœ íŒŒì¼ ëª©ë¡ ì¶”ì 
        self.files_in_vectorstore = []
        
        self._initialize_embeddings()
    
    def _initialize_embeddings(self):
        """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            self.embeddings_model = HuggingFaceEmbeddings(
                model_name="jhgan/ko-sroberta-multitask",
                model_kwargs={'device': 'cpu'},
                encode_kwargs={'normalize_embeddings': True}
            )
        except Exception as e:
            raise ValueError(f"ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def get_pdf_files(self) -> List[str]:
        """
        data í´ë”ì—ì„œ PDF íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        
        Returns:
            PDF íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        return glob.glob(os.path.join(self.data_folder, "*.pdf"))
    
    def build_vectorstore_from_all_pdfs(self) -> bool:
        """
        ëª¨ë“  PDFë¥¼ ë¡œë“œí•˜ì—¬ ë²¡í„° ìŠ¤í† ì–´ë¥¼ ìƒì„±/ì—…ë°ì´íŠ¸ (ì¦ë¶„ ë°©ì‹)
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        pdf_files = self.get_pdf_files()
        if not pdf_files:
            return False

        # ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ê°€ ìˆê³  íŒŒì¼ ëª©ë¡ì´ ê°™ìœ¼ë©´ ì¬ì‚¬ìš©
        if self.vectorstore and set(self.files_in_vectorstore) == set(pdf_files):
            return True

        # ìƒˆë¡œìš´ íŒŒì¼ë§Œ ì°¾ê¸° (ì²« ë²ˆì§¸ ì‹¤í–‰ ì‹œì—ëŠ” ëª¨ë“  íŒŒì¼)
        new_files = []
        if self.vectorstore:
            new_files = [f for f in pdf_files if f not in self.files_in_vectorstore]
            print(f"ğŸ“ ìƒˆë¡œìš´ íŒŒì¼ {len(new_files)}ê°œ ë°œê²¬")
        else:
            # ì²« ë²ˆì§¸ ì‹¤í–‰ ì‹œì—ëŠ” ëª¨ë“  íŒŒì¼ì„ ì²˜ë¦¬
            new_files = pdf_files
            print(f"ğŸ“ ì²« ë²ˆì§¸ ì‹¤í–‰: {len(new_files)}ê°œ PDF íŒŒì¼ ì²˜ë¦¬")
        
        if not new_files and self.vectorstore:
            return True  # ë³€ê²½ì‚¬í•­ ì—†ìŒ

        # ìƒˆë¡œìš´ íŒŒì¼ë“¤ë§Œ ì²˜ë¦¬
        new_documents = []
        for pdf_path in new_files:
            try:
                loader = PyPDFLoader(pdf_path)
                documents = loader.load()
                for doc in documents:
                    doc.metadata['source_file'] = os.path.basename(pdf_path)
                new_documents.extend(documents)
            except Exception as e:
                print(f"PDF ë¡œë“œ ì‹¤íŒ¨: {pdf_path}, ì˜¤ë¥˜: {e}")
                continue

        if new_documents:
            # í…ìŠ¤íŠ¸ ë¶„í• 
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000, 
                chunk_overlap=200
            )
            new_splits = text_splitter.split_documents(new_documents)

            if self.vectorstore:
                # ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
                self.vectorstore.add_documents(new_splits)
                print(f"âœ… ê¸°ì¡´ ë²¡í„°ìŠ¤í† ì–´ì— {len(new_splits)}ê°œ ì²­í¬ ì¶”ê°€")
            else:
                # ìƒˆë¡œ ìƒì„±
                self.vectorstore = FAISS.from_documents(new_splits, self.embeddings_model)
                print(f"âœ… ìƒˆ ë²¡í„°ìŠ¤í† ì–´ ìƒì„±: {len(new_splits)}ê°œ ì²­í¬")

            # retriever ì—…ë°ì´íŠ¸
            self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": 15})
            
            # íŒŒì¼ ëª©ë¡ ì—…ë°ì´íŠ¸
            self.files_in_vectorstore = pdf_files
            
            return True
        
        return False
    
    def retrieve_documents(self, query: str, subject_area: str = "", weakness_concepts: List[str] = None) -> Dict[str, Any]:
        """
        ì¿¼ë¦¬ì— ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            subject_area: ê³¼ëª© ì˜ì—­
            weakness_concepts: ì·¨ì•½ì  ê°œë… ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ì™€ ì‚¬ìš©ëœ ì†ŒìŠ¤ ì •ë³´
        """
        try:
            if not self.retriever:
                return {"error": "ë²¡í„° ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
            
            # ì·¨ì•½ì  ê°œë…ì´ ìˆëŠ” ê²½ìš° ì¿¼ë¦¬ ê°•í™”
            if weakness_concepts:
                enhanced_query = f"{subject_area} {' '.join(weakness_concepts)} {query}"
            else:
                enhanced_query = f"{subject_area} {query}"
            
            # ë¬¸ì„œ ê²€ìƒ‰
            documents = self.retriever.invoke(enhanced_query)
            
            # ì‚¬ìš©ëœ ì†ŒìŠ¤ íŒŒì¼ ë¶„ì„
            source_files = [doc.metadata.get('source_file', 'Unknown') for doc in documents]
            used_sources = list(Counter(source_files).keys())
            
            return {
                "documents": documents,
                "used_sources": used_sources,
                "query": enhanced_query
            }
            
        except Exception as e:
            return {"error": f"ë¬¸ì„œ ê²€ìƒ‰ ì˜¤ë¥˜: {e}"}
    
    def prepare_context(self, documents: List[Document], weakness_concepts: List[str] = None) -> str:
        """
        ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„
        
        Args:
            documents: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
            weakness_concepts: ì·¨ì•½ì  ê°œë… ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ì¤€ë¹„ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
        """
        if not documents:
            return ""
        
        # ì·¨ì•½ì  ê°œë…ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì„ ìš°ì„ ì ìœ¼ë¡œ ì„ ë³„
        key_sents = []
        weakness_related_sents = []
        
        for doc in documents:
            lines = doc.page_content.split("\n")
            for line in lines:
                line = line.strip()
                if len(line) > 50:  # ìµœì†Œ ê¸¸ì´ í™•ë³´
                    # ì·¨ì•½ì  ê°œë…ê³¼ ê´€ë ¨ëœ ë‚´ìš© ìš°ì„  ì„ ë³„
                    is_weakness_related = False
                    if weakness_concepts:
                        is_weakness_related = any(
                            concept.lower() in line.lower() 
                            for concept in weakness_concepts
                        )
                    
                    # ì¤‘ìš”í•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥
                    is_important = any(k in line for k in [
                        "ì •ì˜", "íŠ¹ì§•", "ì¢…ë¥˜", "ì˜ˆì‹œ", "ì›ë¦¬", 
                        "êµ¬ì„±", "ì ˆì°¨", "ì¥ì ", "ë‹¨ì ", "ë°©ë²•", "ê¸°ëŠ¥"
                    ])
                    
                    if is_weakness_related:
                        weakness_related_sents.append(line)
                    elif is_important or len(line) > 100:
                        key_sents.append(line)
        
        # ì·¨ì•½ì  ê´€ë ¨ ë‚´ìš©ì„ ì•ìª½ì—, ì¼ë°˜ ë‚´ìš©ì„ ë’¤ìª½ì— ë°°ì¹˜
        all_sents = weakness_related_sents + key_sents
        context = "\n".join(all_sents[:20])  # ìµœëŒ€ 20ê°œ ë¬¸ì¥ìœ¼ë¡œ ì œí•œ
        
        return context
    
    def get_vectorstore_info(self) -> Dict[str, Any]:
        """
        ë²¡í„° ìŠ¤í† ì–´ ì •ë³´ ë°˜í™˜
        
        Returns:
            ë²¡í„° ìŠ¤í† ì–´ ìƒíƒœ ì •ë³´
        """
        return {
            "is_initialized": self.vectorstore is not None,
            "total_files": len(self.files_in_vectorstore),
            "files": self.files_in_vectorstore.copy(),
            "embeddings_model": "jhgan/ko-sroberta-multitask" if self.embeddings_model else None
        }
    
    def clear_vectorstore(self):
        """ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        self.vectorstore = None
        self.retriever = None
        self.files_in_vectorstore = []
    
    def update_data_folder(self, new_data_folder: str):
        """
        ë°ì´í„° í´ë” ê²½ë¡œ ë³€ê²½
        
        Args:
            new_data_folder: ìƒˆë¡œìš´ ë°ì´í„° í´ë” ê²½ë¡œ
        """
        self.data_folder = new_data_folder
        os.makedirs(self.data_folder, exist_ok=True)
        self.clear_vectorstore()  # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
