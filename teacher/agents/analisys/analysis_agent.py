import json
import os
from typing import Dict, List, TypedDict, Annotated, Any  # ìˆ˜ì •: Any ì¶”ê°€
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
from groq import Groq
from langchain_teddynote import logging
from ..base_agent import BaseAgent

class AnalysisState(TypedDict):
    """ë¶„ì„ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤"""
    messages: Annotated[List[BaseMessage], "ë©”ì‹œì§€ ëª©ë¡"]
    problem: List[str]
    # ë³€ê²½: problem_type ì´ êµ¬ì¡°í™”ëœ ê°ì²´ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ ì§€ì›
    problem_type: List[Dict[str, Any]]  # ì˜ˆ: {"ê³¼ëª©ëª…": "...", "ì£¼ìš”í•­ëª©": "...", "ì„¸ë¶€í•­ëª©": "...", "ì„¸ì„¸í•­ëª©": "..."
    user_answer: List[int]
    solution_answer: List[int]
    solution: List[str]
    grade_result: List[int]
    mistake_summary: str
    final_feedback: str

class AnalysisAgent(BaseAgent):
    """LangGraph ê¸°ë°˜ ë¶„ì„ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.client = Groq(api_key=os.getenv("GROQ_API_KEY"))
        self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # ë˜ëŠ” "meta-llama/llama-3.1-8b-instant"
        self.graph = self._create_graph()
    
    @property
    def name(self) -> str:
        """ì—ì´ì „íŠ¸ ê³ ìœ  ì´ë¦„"""
        return "analysis"

    @property
    def description(self) -> str:
        """ì—ì´ì „íŠ¸ ì„¤ëª…"""
        return "ì‚¬ìš©ì ë‹µì•ˆì„ ë¶„ì„í•˜ê³  ë§ì¶¤í˜• í•™ìŠµ í”¼ë“œë°±ì„ ìƒì„±í•˜ëŠ” ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤."

    def _create_graph(self) -> StateGraph:
        """ë¶„ì„ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„± (ì±„ì  ë‹¨ê³„ ì œê±°)"""
        workflow = StateGraph(AnalysisState)
        
        # ë…¸ë“œ ì¶”ê°€ - analyze_mistakes ì œê±°í•˜ê³  ì§ì ‘ generate_feedbackìœ¼ë¡œ ì—°ê²°
        workflow.add_node("generate_feedback", self._generate_feedback)
        
        # ì—£ì§€ ìˆ˜ì • - grade_answersì—ì„œ ë°”ë¡œ generate_feedbackìœ¼ë¡œ ì—°ê²°
        workflow.set_entry_point("generate_feedback")
        workflow.add_edge("generate_feedback", END)
        
        return workflow.compile()
    
    def _generate_feedback(self, state: AnalysisState) -> AnalysisState:
        """ì‚¬ìš©ì ë‹µì•ˆ ë¶„ì„ ë° í”¼ë“œë°± ìƒì„± (ìƒˆ problem_type êµ¬ì¡° ë°˜ì˜)"""
        problems = state["problem"]
        problem_types = state["problem_type"]  # ì´ì œ dict ë¦¬ìŠ¤íŠ¸
        user_answers = state["user_answer"]
        solution_answers = state["solution_answer"]
        solutions = state["solution"]

        # ìƒˆ helper: problem_type í‰íƒ„í™”
        def flatten_problem_type(pt: Any) -> str:
            if isinstance(pt, dict):
                keys = ["ê³¼ëª©ëª…", "ì£¼ìš”í•­ëª©", "ì„¸ë¶€í•­ëª©", "ì„¸ì„¸í•­ëª©"]
                parts = [str(pt.get(k)) for k in keys if pt.get(k)]
                return " > ".join(parts) if parts else json.dumps(pt, ensure_ascii=False)
            return str(pt)

        flattened_types: List[str] = [flatten_problem_type(pt) for pt in problem_types]

        grade_result = [1 if ua == sa else 0 for ua, sa in zip(user_answers, solution_answers)]
        state["grade_result"] = grade_result

        mistakes = []
        for i, (is_correct, problem, p_type, p_type_flat, user_ans, correct_ans, solution) in enumerate(
            zip(grade_result, problems, problem_types, flattened_types, user_answers, solution_answers, solutions)
        ):
            if not is_correct:
                mistakes.append({
                    "problem_number": i + 1,
                    "problem": problem,
                    "problem_type": p_type,          # ì›ë³¸ êµ¬ì¡°
                    "problem_type_path": p_type_flat, # í‰íƒ„ ê²½ë¡œ
                    "user_answer": user_ans,
                    "correct_answer": correct_ans,
                    "solution": solution
                })

        analysis_data = {
            "all_problems": {
                "problem": problems,
                "problem_type": problem_types,          # ì›ë³¸
                "problem_type_flat": flattened_types,   # í‰íƒ„í™”
                "user_answer": user_answers,
                "solution_answer": solution_answers,
                "solution": solutions,
                "result": grade_result
            },
            "mistakes": mistakes,
            "correct_count": sum(grade_result),
            "total_count": len(grade_result)
        }

        # í”„ë¡¬í”„íŠ¸ ìˆ˜ì •: problem_type êµ¬ì¡° ì„¤ëª… ë° í™œìš© ì§€ì‹œ
        if len(mistakes) > 0:
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ í•™ìƒì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì „ë¬¸ í•™ìŠµ ì½”ì¹˜ì…ë‹ˆë‹¤.
problem_type ì€ ê° ë¬¸í•­ì˜ ê°œë…ì  ê³„ì¸µ ì •ë³´ë¥¼ ë‹´ëŠ” ê°ì²´ì…ë‹ˆë‹¤.
ì˜ˆì‹œ: {"ê³¼ëª©ëª…":"ì†Œí”„íŠ¸ì›¨ì–´ ì„¤ê³„","ì£¼ìš”í•­ëª©":"ìš”êµ¬ì‚¬í•­ í™•ì¸","ì„¸ë¶€í•­ëª©":"ìš”êµ¬ì‚¬í•­ í™•ì¸","ì„¸ì„¸í•­ëª©":"ìš”êµ¬ë¶„ì„ê¸°ë²•"}
í•„ìš” ì‹œ 'ê³¼ëª©ëª… > ì£¼ìš”í•­ëª© > ì„¸ë¶€í•­ëª© > ì„¸ì„¸í•­ëª©' í˜•íƒœë¡œ ê°œë… ê²½ë¡œë¥¼ êµ¬ì„±í•˜ì—¬ í™œìš©í•˜ì‹­ì‹œì˜¤.
ì‘ë‹µì€ ì§€ì •ëœ JSON ìŠ¤í‚¤ë§ˆë§Œì„ ì¶œë ¥í•˜ê³ , ë¶ˆí•„ìš”í•œ ìì—°ì–´ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤."""
                    },
                    {
                        "role": "user",
                        "content": f"""ë‹¤ìŒ í•™ìƒì˜ ë¬¸ì œ í’€ì´ ê²°ê³¼ë¥¼ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë§ì¶¤í˜• í”¼ë“œë°±ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

{json.dumps(analysis_data, ensure_ascii=False, indent=2)}

ë¶„ì„ ì‹œ:
- mistakes.problem_type_path ë¥¼ ì‚¬ìš©í•´ ê°œë… ê²½ë¡œ ê¸°ë°˜ìœ¼ë¡œ íŒ¨í„´ì„ ë„ì¶œ
- ë™ì¼/ìœ ì‚¬ ê²½ë¡œ ë°˜ë³µ ì˜¤ë‹µì€ ë¬¶ì–´ì„œ íŒ¨í„´ ì„¤ëª…
- ì‹¤ìˆ˜ ìœ í˜•ì€ ê°€ëŠ¥í•œ í•œ êµ¬ì²´í™”

ì•„ë˜ JSON í˜•ì‹ì„ ê·¸ëŒ€ë¡œ ë”°ë¥´ì„¸ìš”.
```json
{{
  "detailed_analysis": [
    {{
      "problem_number": "í‹€ë¦° ë¬¸ì œ ë²ˆí˜¸",
      "concept_path": "ë¬¸ì œì˜ ê°œë… ê²½ë¡œ (problem_type_path í™œìš©)",
      "mistake_type": "ì‹¤ìˆ˜ ìœ í˜• (ì˜ˆ: ê°œë… ì´í•´ ë¶€ì¡±, ê³„ì‚° ì‹¤ìˆ˜, ì¡°ê±´ ëˆ„ë½)",
      "analysis": "ì™œ í‹€ë ¸ëŠ”ì§€ì— ëŒ€í•œ êµ¬ì²´ì  ì›ì¸ ë¶„ì„ (í•™ìƒì˜ ì‚¬ê³  ê³¼ì • ì¶”ì •)",
      "recommendation": "ì‹¤ìˆ˜ë¥¼ êµì •í•˜ê¸° ìœ„í•œ êµ¬ì²´ì  í•™ìŠµ/ì—°ìŠµ ì œì•ˆ"
    }}
  ],
  "overall_assessment": {{
    "strengths": "í•™ìƒì´ ì˜í•œ ì ",
    "weaknesses": "ì·¨ì•½ì ê³¼ ë°˜ë³µ íŒ¨í„´",
    "action_plan": {{
      "title": "ë§ì¶¤ í•™ìŠµ ê³„íš",
      "short_term_goal": "1~2ì£¼ ë‚´ ì‹¤í–‰ ëª©í‘œ",
      "long_term_goal": "ì¥ê¸°ì  ì„±ì¥ ëª©í‘œ",
      "recommended_strategies": ["êµ¬ì²´ì  ì „ëµ 1", "êµ¬ì²´ì  ì „ëµ 2"],
      "recommended_resources": ["ìë£Œ/ê°•ì˜ (ì„ íƒ)"]
    }},
    "final_message": "ê²©ë ¤ ë©”ì‹œì§€"
  }}
}}
```
ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±."""
                    }
                ],
                temperature=0,
                max_completion_tokens=4096,
                top_p=1,
                stream=False,
                response_format={"type": "json_object"},
                stop=None
            )
            feedback_content = completion.choices[0].message.content
            parsed_feedback = json.loads(feedback_content)
            state["mistake_summary"] = json.dumps(parsed_feedback.get("detailed_analysis", {}), ensure_ascii=False, indent=2)
            state["final_feedback"] = json.dumps(parsed_feedback, ensure_ascii=False, indent=2)
        else:
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ í•™ìƒì˜ ì ì¬ë ¥ì„ íŒŒì•…í•˜ê³  ë” ë†’ì€ ë‹¨ê³„ë¡œ ì´ëŒì–´ì£¼ëŠ” ì „ë¬¸ í•™ìŠµ ì½”ì¹˜ì…ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": f"""í•™ìƒì€ ëª¨ë“  ë¬¸ì œ({len(grade_result)}ë¬¸ì œ)ë¥¼ ì •ë‹µ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.
problem_type ì€ ê³„ì¸µí˜• ê°ì²´ì´ë©° flat ê²½ë¡œëŠ” all_problems.problem_type_flat ì— ìˆìŠµë‹ˆë‹¤.
ì´ë¥¼ í™œìš©í•˜ì—¬ ê°œë…ì  ê°•ì ì„ êµ¬ì¡°ì ìœ¼ë¡œ ì„¤ëª…í•˜ê³  ë‹¤ìŒ í•™ìŠµ ë‹¨ê³„ë¥¼ ì œì•ˆí•˜ì„¸ìš”.

{json.dumps(analysis_data["all_problems"], ensure_ascii=False, indent=2)}

JSON í˜•ì‹:
{{
  "overall_assessment": {{
    "title": "ì™„ë²½í•œ ê²°ê³¼! ë‹¤ìŒ ë„ì „ì„ ìœ„í•œ ì œì•ˆ",
    "strengths_analysis": "ê°œë… ê³„ì¸µ ê¸°ë°˜ ê°•ì  ë¶„ì„",
    "deepen_learning_plan": {{
      "title": "ì‹¬í™” í•™ìŠµ ê³„íš",
      "recommendations": ["ì¶”ì²œ 1", "ì¶”ì²œ 2"],
      "recommended_resources": ["ìë£Œ 1", "ìë£Œ 2"]
    }},
    "final_message": "ê²©ë ¤ ë©”ì‹œì§€"
  }}
}}
í•œêµ­ì–´ë¡œ ì‘ì„±."""
                    }
                ],
                temperature=0,
                max_completion_tokens=1024,
                top_p=1,
                stream=False,
                response_format={"type": "json_object"},
                stop=None
            )
            feedback_content = completion.choices[0].message.content
            state["mistake_summary"] = "ëª¨ë“  ë¬¸ì œë¥¼ ì •ë‹µìœ¼ë¡œ í•´ê²°í–ˆìŠµë‹ˆë‹¤."
            state["final_feedback"] = feedback_content

        state["messages"].append(AIMessage(content="ë¶„ì„ ë° í”¼ë“œë°± ìƒì„± ì™„ë£Œ"))
        return state
    
    def execute(self, input_data: Dict) -> Dict:
        """ë©”ì¸ ë¶„ì„ ë©”ì„œë“œ"""
        try:
            # ì…ë ¥ ë°ì´í„° ê²€ì¦
            required_fields = ["problem", "problem_type", "user_answer", "solution_answer", "solution"]
            missing_fields = [field for field in required_fields if field not in input_data]
            
            if missing_fields:
                return {
                    "status": "error",
                    "error_message": f"í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_fields}",
                    "metadata": {"total_problems": 0, "correct_count": 0, "score": 0, "has_mistakes": False},
                    "grading": {"results": [], "details": []},
                    "analysis": {},
                    "raw_data": {"missing_fields": missing_fields}
                }
            
            # ë°ì´í„° ê¸¸ì´ ì¼ì¹˜ í™•ì¸
            lengths = [len(input_data[field]) for field in required_fields]
            if len(set(lengths)) > 1:
                return {
                    "status": "error", 
                    "error_message": f"ëª¨ë“  í•„ë“œì˜ ë°ì´í„° ê¸¸ì´ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {dict(zip(required_fields, lengths))}",
                    "metadata": {"total_problems": 0, "correct_count": 0, "score": 0, "has_mistakes": False},
                    "grading": {"results": [], "details": []},
                    "analysis": {},
                    "raw_data": {"field_lengths": dict(zip(required_fields, lengths))}
                }
                
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = AnalysisState(
                messages=[HumanMessage(content="ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")],
                problem=input_data.get("problem", []),
                problem_type=input_data.get("problem_type", []),
                user_answer=input_data.get("user_answer", []),
                solution_answer=input_data.get("solution_answer", []),
                solution=input_data.get("solution", []),
                grade_result=[],
                mistake_summary="",
                final_feedback=""
            )
            
            # ê·¸ë˜í”„ ì‹¤í–‰
            result = self.graph.invoke(initial_state)
            
            # ê²°ê³¼ ì •ë¦¬ - êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë°˜í™˜
            try:
                feedback_data = json.loads(result["final_feedback"]) if result["final_feedback"] else {}
                analysis_result = {
                    "status": "success",
                    "metadata": {
                        "total_problems": len(result["grade_result"]),
                        "correct_count": sum(result["grade_result"]),
                        "incorrect_count": len(result["grade_result"]) - sum(result["grade_result"]),
                        "score": round((sum(result["grade_result"]) / len(result["grade_result"])) * 100, 1) if result["grade_result"] else 0,
                        "analysis_timestamp": "generated",
                        "has_mistakes": sum(result["grade_result"]) < len(result["grade_result"])
                    },
                    "grading": {
                        "results": result["grade_result"],
                        "details": [
                            {
                                "problem_number": i + 1,
                                "is_correct": bool(grade),
                                "user_answer": input_data.get("user_answer", [])[i],
                                "correct_answer": input_data.get("solution_answer", [])[i],
                                # ì¶”ê°€: problem_type ê²½ë¡œ í¬í•¨ (ìƒˆ êµ¬ì¡° ì¶”ì )
                                "problem_type": input_data.get("problem_type", [])[i],
                            }
                            for i, grade in enumerate(result["grade_result"])
                        ]
                    },
                    "analysis": feedback_data,
                    "raw_data": {
                        "mistake_summary": result["mistake_summary"],
                        "messages": [msg.content for msg in result["messages"]]
                    }
                }
                return analysis_result
                
            except (json.JSONDecodeError, KeyError) as e:
                # JSON íŒŒì‹± ì˜¤ë¥˜ ì²˜ë¦¬
                return {
                    "status": "error",
                    "error_message": f"ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                    "metadata": {
                        "total_problems": len(result.get("grade_result", [])),
                        "correct_count": sum(result.get("grade_result", [])),
                        "score": round((sum(result.get("grade_result", [])) / len(result.get("grade_result", []))) * 100, 1) if result.get("grade_result") else 0,
                        "has_mistakes": True if result.get("grade_result") else False
                    },
                    "grading": {
                        "results": result.get("grade_result", []),
                        "details": []
                    },
                    "analysis": {},
                    "raw_data": {
                        "mistake_summary": result.get("mistake_summary", ""),
                        "final_feedback": result.get("final_feedback", ""),
                        "messages": [msg.content for msg in result.get("messages", [])],
                        "parsing_error": str(e)
                    }
                }
                
        except Exception as e:
            # ê¸°íƒ€ ì˜ˆì™¸ ì²˜ë¦¬
            return {
                "status": "error",
                "error_message": f"ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "metadata": {
                    "total_problems": 0,
                    "correct_count": 0,
                    "score": 0,
                    "has_mistakes": False
                },
                "grading": {
                    "results": [],
                    "details": []
                },
                "analysis": {},
                "raw_data": {
                    "error_details": str(e),
                    "input_data_keys": list(input_data.keys()) if isinstance(input_data, dict) else "invalid_input",
                    "error_type": type(e).__name__
                }
            }

# ì‚¬ìš© ì˜ˆì œ
def print_analysis_result(result):
    """ì±„ì /ë¶„ì„ ê²°ê³¼ ì¶œë ¥ (score ì—”ì§„ ë‹¨ìˆœ ê²°ê³¼ + analysis ì—ì´ì „íŠ¸ ê²°ê³¼ ëª¨ë‘ ì§€ì›)
    ì§€ì› í˜•ì‹ 1 (ë‹¨ìˆœ ì±„ì ):
      {
        "problem": [...],
        "problem_type": [ { "ê³¼ëª©ëª…": "...", ... }, ... ],
        "user_answer": [...],
        "solution_answer": [...],
        "solution": [...],
        "status": "success",
        "total": 4,
        "correct": 2,
        "incorrect": 2,
        "score": 50.0,
        "answer_results": [
          {"index":0,"user":3,"solution":3,"correct":true}, ...
        ]
      }
    ì§€ì› í˜•ì‹ 2 (ê¸°ì¡´ ë¶„ì„):
      {
        "status":"success",
        "metadata": {...},
        "grading": {"results":[...],"details":[...]},
        "analysis": {...}
      }
    """
    def flatten_problem_type(pt):
        if isinstance(pt, dict):
            keys = ["ê³¼ëª©ëª…", "ì£¼ìš”í•­ëª©", "ì„¸ë¶€í•­ëª©", "ì„¸ì„¸í•­ëª©"]
            parts = [str(pt.get(k)) for k in keys if pt.get(k)]
            return " > ".join(parts) if parts else json.dumps(pt, ensure_ascii=False)
        return str(pt)

    print("\n" + "="*20 + " ê²°ê³¼ ì¶œë ¥ " + "="*20)

    # ê³µí†µ ì—ëŸ¬ ì²˜ë¦¬
    if result.get("status") == "error":
        print(f"âŒ ì˜¤ë¥˜: {result.get('error_message') or result.get('message') or 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}")
        return

    # 1) ìƒˆ ë‹¨ìˆœ ì±„ì  êµ¬ì¡°
    if "answer_results" in result and "total" in result:
        total = result.get("total", 0)
        correct = result.get("correct", 0)
        score = result.get("score", 0)
        incorrect = result.get("incorrect", total - correct)
        print(f"\n[ ğŸ“Š ì±„ì  ìš”ì•½ ]")
        print(f"  - ì´ ë¬¸í•­: {total}")
        print(f"  - ì •ë‹µ: {correct}")
        print(f"  - ì˜¤ë‹µ: {incorrect}")
        print(f"  - ì ìˆ˜: {score}ì ")

        problems = result.get("problem", [])
        problem_types = result.get("problem_type", [])
        solutions = result.get("solution", [])
        answer_results = result.get("answer_results", [])

        # ì˜¤ë‹µ ìˆ˜ì§‘
        wrong = [ar for ar in answer_results if not ar.get("correct")]
        if not wrong:
            print("\nğŸ‰ ëª¨ë“  ë¬¸í•­ì„ ë§ì·„ìŠµë‹ˆë‹¤! í›Œë¥­í•©ë‹ˆë‹¤.")
        else:
            print("\n[ â— ì˜¤ë‹µ ìƒì„¸ ]")
            for ar in wrong:
                idx = ar["index"]
                prob_text = problems[idx] if idx < len(problems) else "(ë¬¸í•­ ì—†ìŒ)"
                user = ar.get("user")
                sol = ar.get("solution")
                concept_path = flatten_problem_type(problem_types[idx]) if idx < len(problem_types) else "-"
                explanation = solutions[idx] if idx < len(solutions) else ""
                # --- ìˆ˜ì •: f-string ë‚´ë¶€ì—ì„œ replace('\n    ') ì‚¬ìš© ëŒ€ì‹  ì‚¬ì „ ê³„ì‚° ---
                formatted_problem = prob_text.replace("\n", "\n    ")
                formatted_explanation = explanation.replace("\n", "\n    ") if explanation else ""
                print(f"\nâ— ë¬¸í•­ #{idx+1}")
                print(f"  - ê°œë… ê²½ë¡œ: {concept_path}")
                print(f"  - ì‚¬ìš©ì ë‹µ: {user}")
                print(f"  - ì •ë‹µ: {sol}")
                print("  - ë¬¸ì œ:\n    " + formatted_problem)
                if explanation:
                    print("  - í•´ì„¤:\n    " + formatted_explanation)

        # ì •ë‹µë„ ê°„ë‹¨ í‘œ
        print("\n[ âœ… ì „ì²´ ë¬¸í•­ ê²°ê³¼ ]")
        for ar in answer_results:
            idx = ar["index"]
            mark = "O" if ar["correct"] else "X"
            concept_path = flatten_problem_type(problem_types[idx]) if idx < len(problem_types) else "-"
            print(f"  #{idx+1:02d} {mark}  ({ar['user']} / {ar['solution']})  {concept_path}")

        print("\n" + "="*50)
        return

    # 2) ê¸°ì¡´ ë¶„ì„ + grading êµ¬ì¡° (í˜¸í™˜)
    metadata = result.get("metadata", {})
    grading = result.get("grading", {})
    analysis = result.get("analysis", {})

    if metadata:
        print(f"\n[ ğŸ“Š ì¢…í•© ì„±ì·¨ë„ ]")
        print(f"  - ì ìˆ˜: {metadata.get('score', 0)}ì ")
        print(f"  - ì •ë‹µìˆ˜: {metadata.get('correct_count', 0)} / {metadata.get('total_problems', 0)}")
        if "incorrect_count" in metadata:
            print(f"  - ì˜¤ë‹µìˆ˜: {metadata.get('incorrect_count')}")

    details = grading.get("details", [])
    if details:
        print("\n[ ğŸ” ë¬¸í•­ ê²°ê³¼ ]")
        for d in details:
            mark = "O" if d.get("is_correct") else "X"
            print(f"  #{d.get('problem_number')} {mark} (user={d.get('user_answer')}, correct={d.get('correct_answer')})")

    if analysis:
        print("\n[ ğŸ§  ë¶„ì„ ìš”ì•½ ]")
        if "overall_assessment" in analysis:
            oa = analysis["overall_assessment"]
            for k, v in oa.items():
                if isinstance(v, (str, int, float)):
                    print(f"  - {k}: {v}")
        if "detailed_analysis" in analysis:
            print("\n[ â— ì˜¤ë‹µ ë¶„ì„ ]")
            for item in analysis.get("detailed_analysis", []):
                print(f"  Â· ë¬¸ì œ {item.get('problem_number')}: {item.get('mistake_type')} / {item.get('recommendation')}")
    print("\n" + "="*50)


# if __name__ == "__main__":
#     # .env íŒŒì¼ì— OPENAI_API_KEY ì„¤ì • í•„ìš”
#     agent = AnalysisAgent()
    
#     # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
#     import json
#     import sys
#     from pathlib import Path
    
#     # ê¸°ë³¸ input.json ê²½ë¡œ (í˜„ì¬ ë””ë ‰í† ë¦¬)
#     input_file = Path("input.json")
    
#     # ëª…ë ¹ì¤„ ì¸ìë¡œ íŒŒì¼ ê²½ë¡œê°€ ì œê³µëœ ê²½ìš° ì‚¬ìš©
#     if len(sys.argv) > 1:
#         input_file = Path(sys.argv[1])
    
#     # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
#     if not input_file.exists():
#         print(f"ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({input_file})")
#         sys.exit(1)
    
#     # ë°ì´í„° ë¡œë“œ
#     try:
#         with open(input_file, 'r', encoding='utf-8') as f:
#             input_data = json.load(f)
        
#         print(f"íŒŒì¼ '{input_file}' ë¡œë“œ ì„±ê³µ")
        
#         # í•„ìˆ˜ í•„ë“œ í™•ì¸
#         required_fields = ["problem", "problem_type", "user_answer", "solution_answer", "solution"]
#         for field in required_fields:
#             if field not in input_data:
#                 print(f"ì˜¤ë¥˜: í•„ìˆ˜ í•„ë“œ '{field}'ê°€ ì…ë ¥ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
#                 sys.exit(1)
    
#         # ë¶„ì„ ì‹¤í–‰
#         print("ë¶„ì„ ì‹œì‘...")
#         result = agent.execute(input_data)
        
#         # ê²°ê³¼ ì¶œë ¥
#         print_analysis_result(result)
        
#         # ê²°ê³¼ ì €ì¥
#         output_file = input_file.with_name(f"{input_file.stem}_result.json")
#         with open(output_file, 'w', encoding='utf-8') as f:
#             json.dump(result, f, ensure_ascii=False, indent=2)
        
#         print(f"\nê²°ê³¼ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
#     except json.JSONDecodeError:
#         print(f"ì˜¤ë¥˜: '{input_file}'ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
#         sys.exit(1)
#     except Exception as e:
#         print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
#         sys.exit(1)
#         print_analysis_result(result)
        
#         # ê²°ê³¼ ì €ì¥
#         output_file = input_file.with_name(f"{input_file.stem}_result.json")
#         with open(output_file, 'w', encoding='utf-8') as f:
#             json.dump(result, f, ensure_ascii=False, indent=2)
        
#         print(f"\nê²°ê³¼ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
#     except json.JSONDecodeError:
#         print(f"ì˜¤ë¥˜: '{input_file}'ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
#         sys.exit(1)
#     except Exception as e:
#         print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
#         sys.exit(1)
