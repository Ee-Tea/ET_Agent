import json
import os
from typing import Dict, List, TypedDict, Annotated
from langgraph.graph import StateGraph, END
from langgraph.prebuilt import ToolNode
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
from groq import Groq
from langchain_teddynote import logging
logging.langsmith("analysis-agent")
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from ..base_agent import BaseAgent

class AnalysisState(TypedDict):
    """ë¶„ì„ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤"""
    messages: Annotated[List[BaseMessage], "ë©”ì‹œì§€ ëª©ë¡"]
    problem: List[str]
    problem_type: List[str]
    user_answer: List[int]
    solution_answer: List[int]
    solution: List[str]
    grade_result: List[int]
    mistake_summary: str
    final_feedback: str

class AnalysisAgent(BaseAgent):
    """LangGraph ê¸°ë°˜ ë¶„ì„ ì—ì´ì „íŠ¸"""
    
    def __init__(self):
        self.client = Groq(api_key=os.getenv("GROQ_API_KEY"))
        self.model = "meta-llama/llama-4-scout-17b-16e-instruct"  # ë˜ëŠ” "meta-llama/llama-3.1-8b-instant"
        self.graph = self._create_graph()
    
    def _create_graph(self) -> StateGraph:
        """ë¶„ì„ ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±"""
        workflow = StateGraph(AnalysisState)
        
        # ë…¸ë“œ ì¶”ê°€ - analyze_mistakes ì œê±°í•˜ê³  ì§ì ‘ generate_feedbackìœ¼ë¡œ ì—°ê²°
        workflow.add_node("grade_answers", self._grade_answers)
        workflow.add_node("generate_feedback", self._generate_feedback)
        
        # ì—£ì§€ ìˆ˜ì • - grade_answersì—ì„œ ë°”ë¡œ generate_feedbackìœ¼ë¡œ ì—°ê²°
        workflow.set_entry_point("grade_answers")
        workflow.add_edge("grade_answers", "generate_feedback")
        workflow.add_edge("generate_feedback", END)
        
        return workflow.compile()
    
    def _grade_answers(self, state: AnalysisState) -> AnalysisState:
        """ì‚¬ìš©ì ë‹µì•ˆê³¼ ì •ë‹µì„ ë¹„êµí•˜ì—¬ ì±„ì """
        user_answers = state["user_answer"]
        solution_answers = state["solution_answer"]
        
        # ì •ë‹µê³¼ ì‚¬ìš©ì ë‹µì•ˆì„ ë¹„êµí•˜ì—¬ ì±„ì  (ì •ë‹µ: 1, ì˜¤ë‹µ: 0)
        grade_result = [1 if ua == sa else 0 for ua, sa in zip(user_answers, solution_answers)]
        state["grade_result"] = grade_result
        
        # ë©”ì‹œì§€ ê¸°ë¡ ì¶”ê°€
        state["messages"].append(
            AIMessage(content="ì±„ì ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        )
        return state
    
    
    def _generate_feedback(self, state: AnalysisState) -> AnalysisState:
        """ì˜¤ë‹µ ë¶„ì„ê³¼ ê°œì¸í™”ëœ í”¼ë“œë°±ì„ í•¨ê»˜ ìƒì„±"""
        problems = state["problem"]
        problem_types = state["problem_type"]
        user_answers = state["user_answer"]
        solution_answers = state["solution_answer"]
        solutions = state["solution"]
        grade_result = state["grade_result"]
        
        # ì˜¤ë‹µ ë¬¸ì œë“¤ ì¶”ì¶œ (_analyze_mistakes ê¸°ëŠ¥ í†µí•©)
        mistakes = []
        for i, (is_correct, problem, p_type, user_ans, correct_ans, solution) in enumerate(
            zip(grade_result, problems, problem_types, user_answers, solution_answers, solutions)
        ):
            if not is_correct:
                mistakes.append({
                    "problem_number": i + 1,
                    "problem": problem,
                    "problem_type": p_type,
                    "user_answer": user_ans,
                    "correct_answer": correct_ans,
                    "solution": solution
                })
        
        # ë¶„ì„ìš© ë°ì´í„° êµ¬ì¡°í™” (ì „ì²´ ë¬¸ì œì™€ ì˜¤ë‹µ ì •ë³´ ëª¨ë‘ í¬í•¨)
        analysis_data = {
            "all_problems": {
                "problem": problems,
                "problem_type": problem_types,
                "user_answer": user_answers,
                "solution_answer": solution_answers,
                "solution": solutions,
                "result": grade_result
            },
            "mistakes": mistakes,
            "correct_count": sum(grade_result),
            "total_count": len(grade_result)
        }
        
        # í†µí•©ëœ ë¶„ì„ ìš”ì²­: ì˜¤ë‹µ ë¶„ì„ê³¼ ì¢…í•© í”¼ë“œë°±ì„ í•œ ë²ˆì— ìš”ì²­
        if len(mistakes) > 0:  # ì˜¤ë‹µì´ ìˆëŠ” ê²½ìš°
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": """ë‹¹ì‹ ì€ í•™ìƒì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì¸í™”ëœ í”¼ë“œë°±ì„ ì œê³µí•˜ëŠ” ìµœê³ ì˜ í•™ìŠµ ì½”ì¹˜ì…ë‹ˆë‹¤. í•™ìƒì˜ ì„±ì¥ì„ ë•ê¸° ìœ„í•´, ê¸ì •ì ì´ê³  ê²©ë ¤í•˜ëŠ” ì–´ì¡°ë¥¼ ì‚¬ìš©í•˜ë˜, ë¶„ì„ì€ ë§¤ìš° êµ¬ì²´ì ì´ê³  ì „ë¬¸ì ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ì œê³µëœ JSON í˜•ì‹ì— ë§ì¶° ë‹µë³€í•´ì£¼ì„¸ìš”."""
                    },
                    {
                        "role": "user",
                        "content": f"""ë‹¤ìŒ í•™ìƒì˜ ë¬¸ì œ í’€ì´ ê²°ê³¼ë¥¼ ì‹¬ì¸µì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ ë§ì¶¤í˜• í”¼ë“œë°±ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

                {json.dumps(analysis_data, ensure_ascii=False, indent=2)}

                ë¶„ì„ ê²°ê³¼ëŠ” ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶°, ê° í•­ëª©ì„ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©ìœ¼ë¡œ ì±„ì›Œì£¼ì„¸ìš”.
                ```json
                {{
                  "performance_summary": {{
                    "total_problems": "ì „ì²´ ë¬¸í•­ ìˆ˜",
                    "correct_count": "ì •ë‹µ ê°œìˆ˜",
                    "score": "ì ìˆ˜ (100ì  ë§Œì )",
                    "correctness_by_type": {{
                      "ìœ í˜•A": "ì •ë‹µë¥  (ì˜ˆ: 50%)"
                    }}
                  }},
                  "detailed_analysis": [
                    {{
                      "problem_number": "í‹€ë¦° ë¬¸ì œ ë²ˆí˜¸",
                      "mistake_type": "ì‹¤ìˆ˜ ìœ í˜• (ì˜ˆ: ê°œë… ì´í•´ ë¶€ì¡±, ê³„ì‚° ì‹¤ìˆ˜, ì¡°ê±´ ëˆ„ë½)",
                      "analysis": "ì™œ í‹€ë ¸ëŠ”ì§€ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì›ì¸ ë¶„ì„. í•™ìƒì˜ í’€ì´ ê³¼ì •ì„ ì¶”ì¸¡í•˜ë©° ì„¤ëª…í•´ì£¼ì„¸ìš”.",
                      "recommendation": "í•´ë‹¹ ì‹¤ìˆ˜ë¥¼ ë°”ë¡œì¡ê¸° ìœ„í•œ ëª…í™•í•˜ê³  ì‹¤ì²œì ì¸ ì¡°ì–¸. (ì˜ˆ: 'X ê°œë…ì„ ë‹¤ì‹œ í•™ìŠµí•˜ê³ , ê´€ë ¨ ì˜ˆì œ 3ê°œë¥¼ í’€ì–´ë³´ì„¸ìš”.')"
                    }}
                  ],
                  "overall_assessment": {{
                    "strengths": "í•™ìƒì´ ë³´ì—¬ì¤€ ê°•ì ê³¼ ì˜í•œ ì ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì¹­ì°¬.",
                    "weaknesses": "ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íŒŒì•…ëœ ì „ë°˜ì ì¸ ì·¨ì•½ì ê³¼ ë°˜ë³µë˜ëŠ” ì‹¤ìˆ˜ íŒ¨í„´.",
                    "action_plan": {{
                      "title": "ì„±ì¥ì„ ìœ„í•œ ë§ì¶¤ í•™ìŠµ ê³„íš",
                      "short_term_goal": "1-2ì£¼ ì•ˆì— ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ë‹¨ê¸° ëª©í‘œ.",
                      "long_term_goal": "ê¶ê·¹ì ìœ¼ë¡œ ë„ë‹¬í•´ì•¼ í•  ì¥ê¸°ì ì¸ í•™ìŠµ ëª©í‘œ.",
                      "recommended_strategies": ["ì˜¤ë‹µ ë…¸íŠ¸ ì‘ì„±ë²•, ê°œë… ì •ë¦¬ë²• ë“± êµ¬ì²´ì ì¸ í•™ìŠµ ì „ëµ ì œì•ˆ"],
                      "recommended_resources": ["ë„ì›€ì´ ë  ë§Œí•œ ìë£Œë‚˜ ê°•ì˜ ë§í¬ (ìˆì„ ê²½ìš°)"]
                    }},
                    "final_message": "í•™ìƒì—ê²Œ ìš©ê¸°ë¥¼ ì£¼ëŠ” ë”°ëœ»í•œ ê²©ë ¤ì™€ ì‘ì›ì˜ ë©”ì‹œì§€."
                  }}
                }}
                ```
                ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                """
                    }
                ],
                temperature=0,
                max_completion_tokens=4096,
                top_p=1,
                stream=False,
                response_format={"type": "json_object"},
                stop=None
            )
            
            # JSON ì‘ë‹µ íŒŒì‹± ë° ì €ì¥
            feedback_content = completion.choices[0].message.content
            parsed_feedback = json.loads(feedback_content)
            
            # ì˜¤ë‹µ ë¶„ì„ ë° í”¼ë“œë°± ì €ì¥
            state["mistake_summary"] = json.dumps(parsed_feedback.get("detailed_analysis", {}), ensure_ascii=False, indent=2)
            state["final_feedback"] = json.dumps(parsed_feedback, ensure_ascii=False, indent=2)
        else:  # ëª¨ë“  ë¬¸ì œë¥¼ ë§ì¶˜ ê²½ìš°
            # ëª¨ë“  ë¬¸ì œë¥¼ ë§ì¶˜ ê²½ìš°ì˜ ë¶„ì„ ìƒì„±
            completion = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ í•™ìƒì˜ ì ì¬ë ¥ì„ íŒŒì•…í•˜ê³  ë” ë†’ì€ ë‹¨ê³„ë¡œ ì´ëŒì–´ì£¼ëŠ” ì „ë¬¸ í•™ìŠµ ì½”ì¹˜ì…ë‹ˆë‹¤. í•™ìƒì´ ëª¨ë“  ë¬¸ì œë¥¼ ë§í˜”ì„ ë•Œ, ì¹­ì°¬ê³¼ í•¨ê»˜ ì‹¬í™” í•™ìŠµ ë°©í–¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": f"""ì´ í•™ìƒì€ ëª¨ë“  ë¬¸ì œ({len(grade_result)}ë¬¸ì œ)ë¥¼ ì™„ë²½í•˜ê²Œ í’€ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìƒì˜ ê°•ì ì„ ë¶„ì„í•˜ê³ , ë‹¤ìŒ ë‹¨ê³„ë¡œ ë‚˜ì•„ê°ˆ ìˆ˜ ìˆëŠ” ì‹¬í™” í•™ìŠµ ê³„íšì„ ì œì•ˆí•´ì£¼ì„¸ìš”.

                {json.dumps(analysis_data["all_problems"], ensure_ascii=False, indent=2)}

                í”¼ë“œë°±ì€ ì•„ë˜ JSON í˜•ì‹ì— ë§ì¶°, í•™ìƒì˜ ìì‹ ê°ì„ ë†’ì´ê³  ë„ì „ ì˜ì‹ì„ ìê·¹í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                ```json
                {{
                  "overall_assessment": {{
                    "title": "ì™„ë²½í•œ ê²°ê³¼! ë‹¤ìŒ ë„ì „ì„ ìœ„í•œ ì œì•ˆ",
                    "strengths_analysis": "ë¬¸ì œ ìœ í˜•ë³„ ì •ë‹µë¥  100%ë¥¼ ë‹¬ì„±í•œ ê²ƒì„ ë°”íƒ•ìœ¼ë¡œ, í•™ìƒì´ ì–´ë–¤ ê°œë…ê³¼ ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì´ ë›°ì–´ë‚œì§€ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  ì¹­ì°¬í•´ì£¼ì„¸ìš”.",
                    "deepen_learning_plan": {{
                      "title": "ì‹¤ë ¥ ìœ ì§€ë¥¼ ìœ„í•œ ì‹¬í™” í•™ìŠµ ê³„íš",
                      "recommendations": [
                        "í˜„ì¬ ì§€ì‹ì„ ë” ê¹Šê²Œ ë§Œë“¤ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ í•™ìŠµ í™œë™ ì œì•ˆ (ì˜ˆ: 'ê´€ë ¨ ì‹¬í™” ë¬¸ì œì§‘ í’€ì´', 'ìœ ì‚¬í•œ ê°œë…ì„ ë‹¤ë¥¸ ê³¼ëª©ê³¼ ì—°ê²°í•´ë³´ê¸°')",
                        "ìƒˆë¡œìš´ ë„ì „ ê³¼ì œ ì œì•ˆ (ì˜ˆ: 'ê²½ì‹œëŒ€íšŒ ë¬¸ì œ ë§›ë³´ê¸°', 'ê´€ë ¨ ì£¼ì œì— ëŒ€í•œ í”„ë¡œì íŠ¸ í•™ìŠµ')"
                      ],
                      "recommended_resources": ["ì‹¬í™” í•™ìŠµì— ë„ì›€ì´ ë  ë§Œí•œ ìë£Œë‚˜ ì±…, ê°•ì˜ ë§í¬ (ìˆì„ ê²½ìš°)"]
                    }},
                    "final_message": "í•™ìƒì˜ ì„±ì·¨ë¥¼ ì¶•í•˜í•˜ê³ , ì•ìœ¼ë¡œì˜ ì„±ì¥ì„ ì‘ì›í•˜ëŠ” ê²©ë ¤ì˜ ë©”ì‹œì§€."
                  }}
                }}
                ```
                ëª¨ë“  ë‚´ìš©ì€ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
                """
                    }
                ],
                temperature=0,
                max_completion_tokens=1024,
                top_p=1,
                stream=False,
                response_format={"type": "json_object"},
                stop=None
            )
            
            feedback_content = completion.choices[0].message.content
            state["mistake_summary"] = "ëª¨ë“  ë¬¸ì œë¥¼ ì •ë‹µìœ¼ë¡œ í•´ê²°í–ˆìŠµë‹ˆë‹¤."
            state["final_feedback"] = feedback_content
        
        # ë©”ì‹œì§€ ê¸°ë¡ ì¶”ê°€
        state["messages"].append(
            AIMessage(content="ì˜¤ë‹µ ë¶„ì„ ë° ê°œì¸í™”ëœ í”¼ë“œë°± ìƒì„± ì™„ë£Œ")
        )
        
        return state
    
    def execute(self, input_data: Dict) -> Dict:
        """ë©”ì¸ ë¶„ì„ ë©”ì„œë“œ"""
        try:
            # ì…ë ¥ ë°ì´í„° ê²€ì¦
            required_fields = ["problem", "problem_type", "user_answer", "solution_answer", "solution"]
            missing_fields = [field for field in required_fields if field not in input_data]
            
            if missing_fields:
                return {
                    "status": "error",
                    "error_message": f"í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_fields}",
                    "metadata": {"total_problems": 0, "correct_count": 0, "score": 0, "has_mistakes": False},
                    "grading": {"results": [], "details": []},
                    "analysis": {},
                    "raw_data": {"missing_fields": missing_fields}
                }
            
            # ë°ì´í„° ê¸¸ì´ ì¼ì¹˜ í™•ì¸
            lengths = [len(input_data[field]) for field in required_fields]
            if len(set(lengths)) > 1:
                return {
                    "status": "error", 
                    "error_message": f"ëª¨ë“  í•„ë“œì˜ ë°ì´í„° ê¸¸ì´ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {dict(zip(required_fields, lengths))}",
                    "metadata": {"total_problems": 0, "correct_count": 0, "score": 0, "has_mistakes": False},
                    "grading": {"results": [], "details": []},
                    "analysis": {},
                    "raw_data": {"field_lengths": dict(zip(required_fields, lengths))}
                }
                
            # ì´ˆê¸° ìƒíƒœ ì„¤ì •
            initial_state = AnalysisState(
                messages=[HumanMessage(content="ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")],
                problem=input_data.get("problem", []),
                problem_type=input_data.get("problem_type", []),
                user_answer=input_data.get("user_answer", []),
                solution_answer=input_data.get("solution_answer", []),
                solution=input_data.get("solution", []),
                grade_result=[],
                mistake_summary="",
                final_feedback=""
            )
            
            # ê·¸ë˜í”„ ì‹¤í–‰
            result = self.graph.invoke(initial_state)
            
            # ê²°ê³¼ ì •ë¦¬ - êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë°˜í™˜
            try:
                # final_feedback JSON íŒŒì‹±
                feedback_data = json.loads(result["final_feedback"]) if result["final_feedback"] else {}
                
                # í‘œì¤€í™”ëœ ì‘ë‹µ êµ¬ì¡° ìƒì„±
                analysis_result = {
                    "status": "success",
                    "metadata": {
                        "total_problems": len(result["grade_result"]),
                        "correct_count": sum(result["grade_result"]),
                        "incorrect_count": len(result["grade_result"]) - sum(result["grade_result"]),
                        "score": round((sum(result["grade_result"]) / len(result["grade_result"])) * 100, 1) if result["grade_result"] else 0,
                        "analysis_timestamp": "generated",
                        "has_mistakes": sum(result["grade_result"]) < len(result["grade_result"])
                    },
                    "grading": {
                        "results": result["grade_result"],
                        "details": [
                            {
                                "problem_number": i + 1,
                                "is_correct": bool(grade),
                                "user_answer": input_data.get("user_answer", [])[i] if i < len(input_data.get("user_answer", [])) else None,
                                "correct_answer": input_data.get("solution_answer", [])[i] if i < len(input_data.get("solution_answer", [])) else None
                            }
                            for i, grade in enumerate(result["grade_result"])
                        ]
                    },
                    "analysis": feedback_data,
                    "raw_data": {
                        "mistake_summary": result["mistake_summary"],
                        "messages": [msg.content for msg in result["messages"]]
                    }
                }
                
                return analysis_result
                
            except (json.JSONDecodeError, KeyError) as e:
                # JSON íŒŒì‹± ì˜¤ë¥˜ ì²˜ë¦¬
                return {
                    "status": "error",
                    "error_message": f"ê²°ê³¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                    "metadata": {
                        "total_problems": len(result.get("grade_result", [])),
                        "correct_count": sum(result.get("grade_result", [])),
                        "score": round((sum(result.get("grade_result", [])) / len(result.get("grade_result", []))) * 100, 1) if result.get("grade_result") else 0,
                        "has_mistakes": True if result.get("grade_result") else False
                    },
                    "grading": {
                        "results": result.get("grade_result", []),
                        "details": []
                    },
                    "analysis": {},
                    "raw_data": {
                        "mistake_summary": result.get("mistake_summary", ""),
                        "final_feedback": result.get("final_feedback", ""),
                        "messages": [msg.content for msg in result.get("messages", [])],
                        "parsing_error": str(e)
                    }
                }
                
        except Exception as e:
            # ê¸°íƒ€ ì˜ˆì™¸ ì²˜ë¦¬
            return {
                "status": "error",
                "error_message": f"ë¶„ì„ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                "metadata": {
                    "total_problems": 0,
                    "correct_count": 0,
                    "score": 0,
                    "has_mistakes": False
                },
                "grading": {
                    "results": [],
                    "details": []
                },
                "analysis": {},
                "raw_data": {
                    "error_details": str(e),
                    "input_data_keys": list(input_data.keys()) if isinstance(input_data, dict) else "invalid_input",
                    "error_type": type(e).__name__
                }
            }

# ì‚¬ìš© ì˜ˆì œ
def print_analysis_result(result):
    """ê°œì„ ëœ ë¶„ì„ ê²°ê³¼ ì¶œë ¥ í•¨ìˆ˜"""
    print("\n" + "="*20 + " ë¶„ì„ ê²°ê³¼ " + "="*20)
    
    # ìƒíƒœ í™•ì¸
    if result.get("status") == "error":
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {result.get('error_message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
        return
    
    # ë©”íƒ€ë°ì´í„° ì¶œë ¥
    metadata = result.get("metadata", {})
    print(f"\n[ ğŸ“Š ì¢…í•© ì„±ì·¨ë„ ]")
    print(f"  - ì ìˆ˜: {metadata.get('score', 0)}ì  / 100ì ")
    print(f"  - ì •ë‹µë¥ : {metadata.get('correct_count', 0)} / {metadata.get('total_problems', 0)}")
    print(f"  - ì˜¤ë‹µ ê°œìˆ˜: {metadata.get('incorrect_count', 0)}ê°œ")
    
    # ë¶„ì„ ë°ì´í„° ì¶œë ¥
    analysis_data = result.get("analysis", {})
    
    if not metadata.get("has_mistakes", False):
        # ëª¨ë“  ë¬¸ì œë¥¼ ë§ì¶˜ ê²½ìš°
        if "overall_assessment" in analysis_data:
            assessment = analysis_data.get("overall_assessment", {})
            print(f"\nğŸ‰ {assessment.get('title', 'ì™„ë²½í•œ ê²°ê³¼!')}")
            print(f"\n[ ğŸ’ª ê°•ì  ë¶„ì„ ]")
            print(f"  {assessment.get('strengths_analysis', 'N/A')}")

            deepen_plan = assessment.get("deepen_learning_plan", {})
            if deepen_plan:
                print(f"\n[ ğŸ“š {deepen_plan.get('title', 'ì‹¬í™” í•™ìŠµ ê³„íš')} ]")
                if deepen_plan.get("recommendations"):
                    print("  - ì¶”ì²œ í™œë™:")
                    for rec in deepen_plan["recommendations"]:
                        print(f"    â€¢ {rec}")
            
            print(f"\n[ ğŸ’Œ ìµœì¢… ë©”ì‹œì§€ ]")
            print(f"  {assessment.get('final_message', 'N/A')}")
    else:
        # ì˜¤ë‹µì´ ìˆëŠ” ê²½ìš°
        if "performance_summary" in analysis_data:
            summary = analysis_data.get("performance_summary", {})
            if summary.get("correctness_by_type"):
                print("  - ìœ í˜•ë³„ ì •ë‹µë¥ :")
                for p_type, rate in summary["correctness_by_type"].items():
                    print(f"    - {p_type}: {rate}")

            print("\n" + "-"*15 + " ğŸ” ì˜¤ë‹µ ìƒì„¸ ë¶„ì„ " + "-"*15)
            detailed_analysis = analysis_data.get("detailed_analysis", [])
            if not detailed_analysis:
                print("  ë¶„ì„í•  ì˜¤ë‹µì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for analysis in detailed_analysis:
                    print(f"\nâ–¶ ë¬¸ì œ ë²ˆí˜¸: {analysis.get('problem_number', 'N/A')}")
                    print(f"  - ì‹¤ìˆ˜ ìœ í˜•: {analysis.get('mistake_type', 'N/A')}")
                    print(f"  - ì›ì¸ ë¶„ì„: {analysis.get('analysis', 'N/A')}")
                    print(f"  - ê°œì„  ì œì•ˆ: {analysis.get('recommendation', 'N/A')}")

            assessment = analysis_data.get("overall_assessment", {})
            print("\n" + "-"*15 + " ğŸ“‹ ì¢…í•© í‰ê°€ ë° í•™ìŠµ ê³„íš " + "-"*15)
            print(f"\n[ ğŸ’ª ê°•ì  ]")
            print(f"  {assessment.get('strengths', 'N/A')}")
            print(f"\n[ ğŸ”§ ë³´ì™„ì  ]")
            print(f"  {assessment.get('weaknesses', 'N/A')}")

            action_plan = assessment.get("action_plan", {})
            if action_plan:
                print(f"\n[ ğŸ“ˆ {action_plan.get('title', 'í•™ìŠµ ê³„íš')} ]")
                print(f"  - ë‹¨ê¸° ëª©í‘œ: {action_plan.get('short_term_goal', 'N/A')}")
                print(f"  - ì¥ê¸° ëª©í‘œ: {action_plan.get('long_term_goal', 'N/A')}")
                if action_plan.get("recommended_strategies"):
                    print("  - ì¶”ì²œ ì „ëµ:")
                    for strategy in action_plan["recommended_strategies"]:
                        print(f"    â€¢ {strategy}")
            
            print(f"\n[ ğŸ’Œ ìµœì¢… ë©”ì‹œì§€ ]")
            print(f"  {assessment.get('final_message', 'N/A')}")

    print("\n" + "="*50)


# if __name__ == "__main__":
#     # .env íŒŒì¼ì— OPENAI_API_KEY ì„¤ì • í•„ìš”
#     agent = AnalysisAgent()
    
#     # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
#     import json
#     import sys
#     from pathlib import Path
    
#     # ê¸°ë³¸ input.json ê²½ë¡œ (í˜„ì¬ ë””ë ‰í† ë¦¬)
#     input_file = Path("input.json")
    
#     # ëª…ë ¹ì¤„ ì¸ìë¡œ íŒŒì¼ ê²½ë¡œê°€ ì œê³µëœ ê²½ìš° ì‚¬ìš©
#     if len(sys.argv) > 1:
#         input_file = Path(sys.argv[1])
    
#     # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
#     if not input_file.exists():
#         print(f"ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({input_file})")
#         sys.exit(1)
    
#     # ë°ì´í„° ë¡œë“œ
#     try:
#         with open(input_file, 'r', encoding='utf-8') as f:
#             input_data = json.load(f)
        
#         print(f"íŒŒì¼ '{input_file}' ë¡œë“œ ì„±ê³µ")
        
#         # í•„ìˆ˜ í•„ë“œ í™•ì¸
#         required_fields = ["problem", "problem_type", "user_answer", "solution_answer", "solution"]
#         for field in required_fields:
#             if field not in input_data:
#                 print(f"ì˜¤ë¥˜: í•„ìˆ˜ í•„ë“œ '{field}'ê°€ ì…ë ¥ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
#                 sys.exit(1)
    
#         # ë¶„ì„ ì‹¤í–‰
#         print("ë¶„ì„ ì‹œì‘...")
#         result = agent.execute(input_data)
        
#         # ê²°ê³¼ ì¶œë ¥
#         print_analysis_result(result)
        
#         # ê²°ê³¼ ì €ì¥
#         output_file = input_file.with_name(f"{input_file.stem}_result.json")
#         with open(output_file, 'w', encoding='utf-8') as f:
#             json.dump(result, f, ensure_ascii=False, indent=2)
        
#         print(f"\nê²°ê³¼ê°€ '{output_file}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
#     except json.JSONDecodeError:
#         print(f"ì˜¤ë¥˜: '{input_file}'ì´ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
#         sys.exit(1)
#     except Exception as e:
#         print(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
#         sys.exit(1)
