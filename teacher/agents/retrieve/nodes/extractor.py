import os
import json
import re
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv
load_dotenv()

from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

# LLM ëª¨ë¸ ì„¤ì •ì„ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
OPENAI_LLM_MODEL = os.getenv("OPENAI_LLM_MODEL", "moonshotai/kimi-k2-instruct")
LLM_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.2"))
LLM_MAX_TOKENS = int(os.getenv("LLM_MAX_TOKENS", "2048"))

openai_api_key = os.getenv("OPENAI_API_KEY")
# print(openai_api_key,OPENAI_LLM_MODEL,LLM_TEMPERATURE,LLM_MAX_TOKENS)
if not openai_api_key:
  raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

def parse_llama_json(result: str) -> dict:
  """
  LLaMA ì‘ë‹µì—ì„œ JSONì„ ì¶”ì¶œí•˜ì—¬ dictë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
  ì½”ë“œ ë¸”ë¡(```json â€¦ ```) ê°ì‹¸ì§ê³¼ ì„¤ëª… í…ìŠ¤íŠ¸ë¥¼ ì œê±°í•©ë‹ˆë‹¤.
  """
  cleaned = result.strip()

  # ì½”ë“œ ë¸”ë¡ ì œê±°
  if cleaned.startswith("```"):
      cleaned = re.sub(r"^```(?:json)?", "", cleaned, flags=re.IGNORECASE).strip()
      cleaned = re.sub(r"```$", "", cleaned, flags=re.IGNORECASE).strip()

  # BOM ì œê±°
  cleaned = cleaned.encode("utf-8").decode("utf-8-sig")

  # JSON ë³¸ë¬¸ë§Œ ì¶”ì¶œ (ì¤‘ê´„í˜¸ë¡œ ì‹œì‘í•˜ê³  ëë‚˜ëŠ” ê°€ì¥ í° JSON)
  json_match = re.search(r"\{.*\}", cleaned, flags=re.DOTALL)
  if not json_match:
      print("âŒ JSON ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
      print("â†’ ì›ë³¸:", repr(cleaned))
      return {}

  try:
      return json.loads(json_match.group())
  except json.JSONDecodeError as e:
      print("âŒ JSON íŒŒì‹± ì‹¤íŒ¨")
      print("â†’ ì˜¤ë¥˜:", e)
      print("â†’ ì›ë³¸:", repr(json_match.group()))
      return {}

def extract_query_elements(user_question: str) -> dict:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    system_prompt = """ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì•„ë˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì„¸ìš”:
    - keyword: ì§ˆë¬¸ì— ì–¸ê¸‰ëœ ì‚¬ìš©ìê°€ ì •ë³´ë¥¼ í•„ìš”ë¡œ í•˜ëŠ” ìš©ì–´

    JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆì‹œ:
    {
    "keyword": "LLM"
    }"""

    llm = ChatOpenAI(
        api_key=openai_api_key,
        base_url=os.getenv("OPENAI_BASE_URL", "https://api.groq.com/openai/v1"),
        model=OPENAI_LLM_MODEL,
        temperature=LLM_TEMPERATURE,
        max_tokens=LLM_MAX_TOKENS
    )
    
    response = llm.invoke([
        HumanMessage(content=system_prompt),
        HumanMessage(content=user_question)
    ])
    
    result = response.content
    result_dict = parse_llama_json(result)
    keyword = result_dict.get("keyword", "")
    if isinstance(keyword, str):
        return [keyword]
    elif isinstance(keyword, list):
        return keyword
    else:
        return []

def query_rewrite(question: str, keywords: list[str]) -> str:
    """
    ì§ˆë¬¸ì„ LLMì— ë§ê²Œ ì¬ì‘ì„±í•©ë‹ˆë‹¤.
    """
    keyword_text = ", ".join(keywords)
    original_question = question
    rewrite_prompt = f"""
    ì‚¬ìš©ìì˜ ì›ë˜ ì§ˆë¬¸ê³¼ ì¶”ì¶œëœ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ, ê²€ìƒ‰ì— ì í•©í•œ í˜•íƒœì˜ ëª…í™•í•œ ì§ˆë¬¸ìœ¼ë¡œ ë°”ê¿”ì£¼ì„¸ìš”.

    - ì‚¬ìš©ì ì§ˆë¬¸: {original_question}
    - ì¶”ì¶œ í‚¤ì›Œë“œ: {keyword_text}

    ==> ì¬ì‘ì„±ëœ ê²€ìƒ‰ ì§ˆë¬¸:
    """
    
    llm = ChatOpenAI(
        api_key=openai_api_key,
        base_url=os.getenv("OPENAI_BASE_URL", "https://api.groq.com/openai/v1"),
        model=OPENAI_LLM_MODEL,
        temperature=0.5,
        max_tokens=LLM_MAX_TOKENS
    )
    
    response = llm.invoke([HumanMessage(content=rewrite_prompt)])
    return response.content.strip()

def query_reinforce(state: dict) -> str:
    """
    ê²€ì¦ì— ì‹¤íŒ¨í•œ ê²½ìš° ì› ì§ˆë¬¸ì„ ë³´ì™„í•˜ì—¬ ì¬ì‘ì„±í•˜ëŠ” í•¨ìˆ˜.
    """
    original_question = state["retrieval_question"]
    verdict = state.get("fact_check_result", {}).get("verdict", "NOT ENOUGH INFO")
    answer = state.get("answer", "")
    context = state.get("merged_context", "")

    prompt = f"""
    ì´ì „ ì§ˆë¬¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

    "{original_question}"

    í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ LLM ì‘ë‹µì€ ë‹¤ìŒê³¼ ê°™ì•˜ìŠµë‹ˆë‹¤:

    "{answer}"

    í•˜ì§€ë§Œ ë‹¤ìŒ ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ê²€í† í•œ ê²°ê³¼, ì´ ì‘ë‹µì€ "{verdict}" íŒì •ì„ ë°›ì•˜ìŠµë‹ˆë‹¤:

    "{context}"

    ë”°ë¼ì„œ, ì´ ì§ˆë¬¸ì„ ë” ëª…í™•í•˜ê³  ì‚¬ì‹¤ ê²€ì¦ì´ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì¬ì‘ì„±í•´ì£¼ì„¸ìš”.
    """

    llm = ChatOpenAI(
        api_key=openai_api_key,
        base_url=os.getenv("OPENAI_BASE_URL", "https://api.groq.com/openai/v1"),
        model=OPENAI_LLM_MODEL,
        temperature=0.3,
        max_tokens=LLM_MAX_TOKENS
    )
    
    response = llm.invoke([HumanMessage(content=prompt)])
    rewritten_question = response.content.strip()
    print(f"ğŸ” ì¬ì‘ì„±ëœ ì§ˆë¬¸ (ë³´ê°•): {rewritten_question}")
    return rewritten_question