import streamlit as st
from retrieve import graph  # ê¸°ì¡´ LangGraph ê·¸ë˜í”„ import

# 1ï¸âƒ£ ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
st.title("ğŸ“š LLM ê¸°ë°˜ ê²€ì¦í˜• ê²€ìƒ‰ ë´‡")
user_question = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ì†Œí”„íŠ¸ì›¨ì–´ ìƒëª… ì£¼ê¸°ì˜ ì •ì˜ì™€ ì¢…ë¥˜ëŠ”?")

# 2ï¸âƒ£ ì§ˆë¬¸ì´ ì…ë ¥ë˜ë©´ LangGraph ì‹¤í–‰
if user_question:
    with st.spinner("ê²€ìƒ‰ ë° ê²€ì¦ ì¤‘ì…ë‹ˆë‹¤... â³"):
        initial_state = {"retrieval_question": user_question}

        # LangGraph ì‹¤í–‰
        result = graph.invoke(initial_state)

        # ìƒíƒœ í‘œì‹œìš© ì •ë³´ë“¤ ì¶œë ¥
        st.subheader("ğŸ“Œ ì „ì²´ ê³¼ì • ìš”ì•½")
        st.markdown(f"**ì´ˆê¸° ì§ˆë¬¸**: `{result.get('retrieval_question', '')}`")
        st.markdown(f"**ì¶”ì¶œëœ í‚¤ì›Œë“œ**: `{result.get('keywords', [])}`")
        st.markdown(f"**ì¬ì‘ì„±ëœ ì§ˆë¬¸**: `{result.get('rewritten_question', '')}`")

        with st.expander("ğŸ” ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ì»¨í…ìŠ¤íŠ¸ ë³´ê¸°"):
            st.code(result.get("merged_context", "(ì—†ìŒ)"))

        st.subheader("ğŸ“¥ LLM ì‘ë‹µ")
        st.success(result.get("answer", "ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤."))

        if "fact_check_result" in result:
            st.subheader("ğŸ§ª ì‘ë‹µ ê²€ì¦ ê²°ê³¼")
            verdict = result['fact_check_result'].get("verdict", "UNKNOWN")
            confidence = result['fact_check_result'].get("confidence", 0.0)
            evidence = result['fact_check_result'].get("evidence", [])

            verdict_display = f"âœ… ê²€ì¦ í†µê³¼ ({verdict})" if verdict == "SUPPORTED" else f"âŒ ê²€ì¦ ì‹¤íŒ¨ ({verdict})"
            st.markdown(f"**ê²€ì¦ ê²°ê³¼**: {verdict_display}")
            st.markdown(f"**ì‹ ë¢°ë„(confidence)**: `{confidence}`")

            if evidence:
                st.markdown("**ê²€ì¦ ê·¼ê±°:**")
                for i, ev in enumerate(evidence, 1):
                    st.markdown(f"- {i}. {ev}")
