# teacher/agents/solution/app.py
import os, sys, json
from typing import List, Dict, Any, Optional

import streamlit as st
from dotenv import load_dotenv

# --- íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì•ˆì „í™” ---
try:
    from teacher.agents.solution.solution_agent import SolutionAgent
except Exception:
    THIS_DIR = os.path.dirname(os.path.abspath(__file__))
    ROOT = os.path.dirname(os.path.dirname(os.path.dirname(THIS_DIR)))  # .../llm-T
    if ROOT not in sys.path:
        sys.path.insert(0, ROOT)
    from teacher.agents.solution.solution_agent import SolutionAgent

# (MilvusëŠ” ì˜µì…˜)
try:
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_milvus import Milvus
    from pymilvus import connections
    from langchain_core.documents import Document
except Exception:
    Milvus = None  # ë¯¸ì„¤ì¹˜ì—¬ë„ ë™ì‘

load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

st.set_page_config(page_title="ğŸ§  ë¬¸ì œ í•´ë‹µ ìƒì„±ê¸° (JSON)", layout="wide")
st.title("ğŸ§  ë¬¸ì œ í•´ë‹µ ìƒì„±ê¸° (JSON Batch)")

# -------- ì‚¬ì´ë“œë°”: JSON ì—…ë¡œë“œ / ì‹¤í–‰ì˜µì…˜ --------
with st.sidebar:
    st.subheader("ğŸ—‚ï¸ ë¬¸ì œ JSON ì—…ë¡œë“œ")
    up = st.file_uploader("íŒŒì¼ ì„ íƒ (.json)", type=["json"])
    st.caption("í˜•ì‹: [{ 'question': str, 'options': [str, ...] }, ...]")

    st.divider()
    st.subheader("âš™ï¸ ì‹¤í–‰ ì˜µì…˜")
    save_to_vector = st.checkbox("Milvusì— ì €ì¥", value=False)
    if save_to_vector:
        milvus_host = st.text_input("Milvus Host", value="localhost")
        milvus_port = st.text_input("Milvus Port", value="19530")
        collection_name = st.text_input("Collection", value="problems")

# -------- ë¦¬ì†ŒìŠ¤: Milvus(ì˜µì…˜) / Agent --------
@st.cache_resource
def init_vectorstore(host: str, port: str, coll: str) -> Optional["Milvus"]:
    if not save_to_vector or Milvus is None:
        return None
    try:
        from langchain_huggingface import HuggingFaceEmbeddings
        from langchain_milvus import Milvus
        from pymilvus import connections
        emb = HuggingFaceEmbeddings(model_name="jhgan/ko-sroberta-multitask",
                                    model_kwargs={"device": "cpu"})
        if "default" in connections.list_connections():
            connections.disconnect("default")
        connections.connect(alias="default", host=host, port=port)
        vs = Milvus(embedding_function=emb,
                    collection_name=coll,
                    connection_args={"host": host, "port": port})
        return vs
    except Exception as e:
        st.sidebar.warning(f"Milvus ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def build_agent(use_store: bool) -> SolutionAgent:
    """
    use_store=Falseì´ë©´ store ë…¸ë“œë¥¼ ê²°ê³¼ë§Œ ì ì¬í•˜ëŠ” ì•ˆì „ ìŠ¤í…ìœ¼ë¡œ êµì²´ í›„ ê·¸ë˜í”„ ì¬ì»´íŒŒì¼
    """
    ag = SolutionAgent()

    if not use_store:
        def _store_stub(self, state: Dict[str, Any]) -> Dict[str, Any]:
            item = {
                "user_problem": state.get("user_problem", ""),
                "user_problem_options": state.get("user_problem_options", []),
                "generated_answer": state.get("generated_answer", ""),
                "generated_explanation": state.get("generated_explanation", ""),
                "generated_subject": state.get("generated_subject", ""),
                "validated": state.get("validated", False),
                "chat_history": state.get("chat_history", []),
            }
            state.setdefault("results", []).append(item)
            return state

        # ë©”ì„œë“œ ë°”ì¸ë”© í›„ ê·¸ë˜í”„ ì¬ìƒì„±
        ag._store_to_vector_db = _store_stub.__get__(ag, SolutionAgent)
        ag.graph = ag._create_graph()
    return ag

if save_to_vector:
    vectorstore = init_vectorstore(milvus_host, milvus_port, collection_name)
else:
    vectorstore = None

agent = build_agent(use_store=save_to_vector and vectorstore is not None)

# -------- ì…ë ¥: ì§€ì‹œë¬¸ --------
user_instr = st.text_input("âœï¸ ìš”êµ¬ì‚¬í•­/ì§€ì‹œë¬¸ (ëª¨ë“  ë¬¸ì œì— ê³µí†µ ì ìš©)", value="ì •ë‹µ ë²ˆí˜¸ì™€ í’€ì´, ê³¼ëª©ì„ ì•Œë ¤ì¤˜.")

# -------- JSON íŒŒì‹± / ë¯¸ë¦¬ë³´ê¸° --------
problems: List[Dict[str, Any]] = []
if up:
    try:
        problems = json.loads(up.read().decode("utf-8"))
        assert isinstance(problems, list)
    except Exception as e:
        st.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        problems = []

if problems:
    st.success(f"ì´ {len(problems)}ë¬¸ì œ ë¡œë“œë¨.")
    # ì„ íƒ ì‹¤í–‰
    idx = st.number_input("ğŸ”¢ ì„ íƒ ì‹¤í–‰ (1~N)", min_value=1, max_value=len(problems), value=1, step=1)
    sel = problems[idx - 1]
    st.markdown("**ë¯¸ë¦¬ë³´ê¸°**")
    st.write(sel.get("question", ""))
    for i, o in enumerate(sel.get("options", []), 1):
        st.write(f"{i}. {o}")

    col1, col2 = st.columns(2)
    with col1:
        if st.button("â–¶ï¸ ì„ íƒ ë¬¸ì œ í’€ì´"):
            with st.spinner("ì‹¤í–‰ ì¤‘..."):
                init_state = {
                    "user_input_txt": user_instr,
                    "user_problem": sel.get("question", ""),
                    "user_problem_options": sel.get("options", []),
                    "vectorstore": vectorstore,
                    "retrieved_docs": [],
                    "similar_questions_text": "",
                    "generated_answer": "",
                    "generated_explanation": "",
                    "generated_subject": "",
                    "validated": False,
                    "retry_count": 0,
                    "results": [],
                    "chat_history": [],
                    "source_type": "external" if (save_to_vector and vectorstore) else "internal",
                }
                final_state = agent.graph.invoke(init_state, config={"recursion_limit": 200})
                results = final_state.get("results", [])
                if results:
                    last = results[-1]
                    st.markdown(f"**ì •ë‹µ(ë²ˆí˜¸)**: {last.get('generated_answer','-')}")
                    st.markdown(f"**ê³¼ëª©**: {last.get('generated_subject','-')}")
                    st.markdown("**í’€ì´**")
                    st.write(last.get("generated_explanation","-"))
                else:
                    st.error("ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    with col2:
        if st.button("â© ì „ì²´ ë¬¸ì œ ì¼ê´„ í’€ì´"):
            outs = []
            prog = st.progress(0)
            for i, p in enumerate(problems, 1):
                init_state = {
                    "user_input_txt": user_instr,
                    "user_problem": p.get("question", ""),
                    "user_problem_options": p.get("options", []),
                    "vectorstore": vectorstore,
                    "retrieved_docs": [],
                    "similar_questions_text": "",
                    "generated_answer": "",
                    "generated_explanation": "",
                    "generated_subject": "",
                    "validated": False,
                    "retry_count": 0,
                    "results": [],
                    "chat_history": [],
                    "source_type": "external" if (save_to_vector and vectorstore) else "internal",
                }
                final_state = agent.graph.invoke(init_state, config={"recursion_limit": 200})
                res = (final_state.get("results") or [{}])[-1]
                outs.append(res)
                prog.progress(i / len(problems))
            st.success(f"ì´ {len(outs)}ê±´ ì™„ë£Œ")
            for i, r in enumerate(outs, 1):
                st.markdown(f"### ê²°ê³¼ #{i}")
                st.markdown(f"- **ì •ë‹µ(ë²ˆí˜¸)**: {r.get('generated_answer','-')}")
                st.markdown(f"- **ê³¼ëª©**: {r.get('generated_subject','-')}")
                st.markdown("**í’€ì´**")
                st.write(r.get("generated_explanation","-"))
else:
    st.info("ì¢Œì¸¡ì—ì„œ JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

# -------- í‚¤ ì•ˆë‚´ --------
if not GROQ_API_KEY:
    st.caption("â„¹ï¸ `.env`ì˜ GROQ_API_KEYê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. LLM í˜¸ì¶œ ì‹¤íŒ¨ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
