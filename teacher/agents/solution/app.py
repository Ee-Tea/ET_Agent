# teacher/agents/solution/app.py
import os, sys, json
from typing import List, Dict, Any

import streamlit as st
from dotenv import load_dotenv

# --- íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì•ˆì „í™” ---
try:
    from teacher.agents.solution.solution_agent import SolutionAgent
except Exception:
    THIS_DIR = os.path.dirname(os.path.abspath(__file__))
    ROOT = os.path.dirname(os.path.dirname(os.path.dirname(THIS_DIR)))  # .../llm-T
    if ROOT not in sys.path:
        sys.path.insert(0, ROOT)
    from teacher.agents.solution.solution_agent import SolutionAgent

# --- Milvus í•„ìˆ˜ ---
try:
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_milvus import Milvus
    from pymilvus import connections
except Exception as e:
    st.error(f"Milvus ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤: {e}\n\npip/uvë¡œ ë‹¤ìŒì„ ì„¤ì¹˜í•˜ì„¸ìš”: langchain-milvus, pymilvus, langchain-huggingface")
    st.stop()

load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

st.set_page_config(page_title="ğŸ§  ë¬¸ì œ í•´ë‹µ ìƒì„±ê¸° (JSON+Milvus)", layout="wide")
st.title("ğŸ§  ë¬¸ì œ í•´ë‹µ ìƒì„±ê¸° (JSON + Milvus í•„ìˆ˜)")
st.caption("JSON ì—…ë¡œë“œ í›„ ì„ íƒ ì‹¤í–‰/ì¼ê´„ ì‹¤í–‰. ê²°ê³¼ëŠ” í•­ìƒ Milvusì— ì €ì¥ë©ë‹ˆë‹¤.")

# -------- ì‚¬ì´ë“œë°”: JSON ì—…ë¡œë“œ / Milvus ì„¤ì • --------
with st.sidebar:
    st.subheader("ğŸ—‚ï¸ ë¬¸ì œ JSON ì—…ë¡œë“œ")
    up = st.file_uploader("íŒŒì¼ ì„ íƒ (.json)", type=["json"])
    st.caption("í˜•ì‹: [{ 'question': str, 'options': [str, ...] }, ...]")

    st.divider()
    st.subheader("ğŸ—„ï¸ Milvus ì—°ê²°(í•„ìˆ˜)")
    milvus_host = st.text_input("Host", value="localhost")
    milvus_port = st.text_input("Port", value="19530")
    collection_name = st.text_input("Collection", value="problems")

# -------- ë¦¬ì†ŒìŠ¤: Milvus / Agent --------
@st.cache_resource
def init_vectorstore(host: str, port: str, coll: str) -> Milvus:
    try:
        emb = HuggingFaceEmbeddings(
            model_name="jhgan/ko-sroberta-multitask",
            model_kwargs={"device": "cpu"},
        )
        if "default" in connections.list_connections():
            connections.disconnect("default")
        connections.connect(alias="default", host=host, port=port)
        vs = Milvus(
            embedding_function=emb,
            collection_name=coll,
            connection_args={"host": host, "port": port},
        )
        return vs
    except Exception as e:
        st.error(f"Milvus ì—°ê²° ì‹¤íŒ¨: {e}")
        st.stop()

@st.cache_resource
def get_agent() -> SolutionAgent:
    return SolutionAgent()

vectorstore = init_vectorstore(milvus_host, milvus_port, collection_name)
agent = get_agent()

# -------- ì…ë ¥: ê³µí†µ ì§€ì‹œë¬¸ --------
user_instr = st.text_input("âœï¸ ê³µí†µ ì§€ì‹œë¬¸", value="ì •ë‹µ ë²ˆí˜¸ì™€ í’€ì´, ê³¼ëª©ì„ ì•Œë ¤ì¤˜.")

# -------- JSON íŒŒì‹± / ë¯¸ë¦¬ë³´ê¸° --------
problems: List[Dict[str, Any]] = []
if up:
    try:
        problems = json.loads(up.read().decode("utf-8"))
        assert isinstance(problems, list)
    except Exception as e:
        st.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        problems = []

if problems:
    st.success(f"ì´ {len(problems)}ë¬¸ì œ ë¡œë“œë¨.")
    idx = st.number_input("ğŸ”¢ ì„ íƒ ì‹¤í–‰ (1~N)", min_value=1, max_value=len(problems), value=1, step=1)
    sel = problems[idx - 1]
    st.markdown("**ë¯¸ë¦¬ë³´ê¸°**")
    st.write(sel.get("question", ""))
    for i, o in enumerate(sel.get("options", []), 1):
        st.write(f"{o}")

    col1, col2 = st.columns(2)

    def run_one(p: Dict[str, Any]):
        init_state = {
            "user_input_txt": user_instr,
            "user_problem": p.get("question", ""),
            "user_problem_options": p.get("options", []),
            "vectorstore": vectorstore,                 # âœ… í•­ìƒ ì—°ê²°
            "retrieved_docs": [],
            "similar_questions_text": "",
            "generated_answer": "",
            "generated_explanation": "",
            "generated_subject": "",
            "validated": False,
            "retry_count": 0,
            "results": [],
            "chat_history": [],
            "source_type": "external",                  # âœ… í•­ìƒ ì™¸ë¶€ ì €ì¥
        }
        return agent.graph.invoke(init_state, config={"recursion_limit": 200})

    with col1:
        if st.button("â–¶ï¸ ì„ íƒ ë¬¸ì œ í’€ì´"):
            with st.spinner("ì‹¤í–‰ ì¤‘..."):
                final_state = run_one(sel)
                results = final_state.get("results", [])
                if results:
                    last = results[-1]
                    st.markdown(f"**ì •ë‹µ(ë²ˆí˜¸)**: {last.get('generated_answer','-')}")
                    st.markdown(f"**ê³¼ëª©**: {last.get('generated_subject','-')}")
                    st.markdown(f"**í’€ì´**: {last.get('generated_explanation','-')}")
                    st.write(last.get("generated_explanation","-"))
                else:
                    st.error("ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    with col2:
        if st.button("â© ì „ì²´ ë¬¸ì œ ì¼ê´„ í’€ì´"):
            outs = []
            prog = st.progress(0)
            for i, p in enumerate(problems, 1):
                final_state = run_one(p)
                res = (final_state.get("results") or [{}])[-1]
                outs.append(res)
                prog.progress(i / len(problems))
            st.success(f"ì´ {len(outs)}ê±´ ì™„ë£Œ")
            for i, r in enumerate(outs, 1):
                st.markdown(f"### ê²°ê³¼ #{i}")
                st.markdown(f"- **ì •ë‹µ(ë²ˆí˜¸)**: {r.get('generated_answer','-')}")
                st.markdown(f"- **ê³¼ëª©**: {r.get('generated_subject','-')}")
                st.markdown("**í’€ì´**")
                st.write(r.get("generated_explanation","-"))
else:
    st.info("ì¢Œì¸¡ì—ì„œ JSON íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")

# -------- í‚¤ ì•ˆë‚´ --------
if not GROQ_API_KEY:
    st.caption("â„¹ï¸ `.env`ì˜ GROQ_API_KEYê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. LLM í˜¸ì¶œ ì‹¤íŒ¨ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤.")
