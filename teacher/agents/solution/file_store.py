import json
from langchain.schema import Document
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_milvus import Milvus
from pymilvus import connections
from pathlib import Path


def load_questions_from_json(inputs):

    # ë¬¸ì œ ê²½ë¡œì—ì„œ JSON íŒŒì¼ ë¡œë“œ
    with open(inputs["question_path"], "r", encoding="utf-8") as f:
        questions = json.load(f)["all_questions"]
    
    docs = []
    for q in questions:
        question_text = q.get("question", "").strip()
        options = q.get("options", [])
        answer = q.get("answer", None)
        explanation = q.get("explanation", "")
        subject = q.get("subject", "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬")  # ê¸°ë³¸ ê³¼ëª© ì„¤ì •



        # ë¬¸ì¥ì€ ë³¸ë¬¸ë§Œ ì €ì¥, ì˜µì…˜ì€ metadataì— ë”°ë¡œ
        doc = Document(
            page_content=question_text,
            metadata={
                "options": json.dumps(options),
                "answer": str(answer) if answer is not None else "",
                "explanation": explanation.strip(),
                "subject": subject,
            }
        )
        docs.append(doc)

    # ğŸ§  ì„ë² ë”© ëª¨ë¸ ë° ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •
    collection_name = "problems"
    embedding_model = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={"device": "cpu"}
    )

    if "default" in connections.list_connections():
        connections.disconnect(alias="default")

    # Milvus ì—°ê²° ì„¤ì •
    connections.connect(
        alias="default",
        host="localhost",
        port="19530"
    )

    # if not utility.has_collection(collection_name):
    print("ğŸ†• ë¬¸ì œ ë²¡í„°ìŠ¤í† ì–´ ìƒì„± ì¤‘...")
    inputs["vectorstore"] = Milvus.from_documents(
        documents=docs,
        embedding=embedding_model,
        collection_name=collection_name,
        connection_args={"host": "localhost", "port": "19530"}
    )
    # else:
    #     print("âœ… ë¬¸ì œ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì¤‘...")
    #     inputs["vectorstore"] = Milvus(
    #         embedding_function=embedding_model,
    #         collection_name=collection_name,
    #         connection_args={"host": "localhost", "port": "19530"}
    #     )

if __name__ == "__main__":

    base_dir = Path(__file__).parent.parent.parent  # llm-T í´ë” ê¸°ì¤€
    inputs = {
            "question_path": str(base_dir / "teacher/agents/TestGenerator/test/ê°œë°œ ê´€ë ¨ 3ê°œ_3ê³¼ëª©_24ë¬¸ì œ.json"),
            "docs": []
        }
    load_questions_from_json(inputs)
    print("ê¸°ì¶œë¬¸ì œ ë¡œë“œ ë° ë²¡í„°ìŠ¤í† ì–´ ì„¤ì • ì™„ë£Œ")