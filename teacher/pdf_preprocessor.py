"""
PDF ì „ì²˜ë¦¬ ê´€ë ¨ í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†“ì€ ëª¨ë“ˆ
teacher_graph.pyì—ì„œ PDF ê´€ë ¨ ë¡œì§ì„ ë¶„ë¦¬í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì„
"""

import os
import re
import json
from typing import List, Dict, Optional, Tuple
from docling.document_converter import DocumentConverter
from langchain_openai import ChatOpenAI


class PDFPreprocessor:
    """PDF íŒŒì¼ ì „ì²˜ë¦¬ ë° ë¬¸ì œ ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # í™˜ê²½ë³€ìˆ˜ ì„¤ì •ìœ¼ë¡œ ê¶Œí•œ ë¬¸ì œ í•´ê²°
        os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'
        os.environ['HF_HOME'] = 'C:\\temp\\huggingface_cache'
        
        # cv2 setNumThreads ë¬¸ì œ í•´ê²°
        try:
            import cv2
            if not hasattr(cv2, 'setNumThreads'):
                # setNumThreadsê°€ ì—†ìœ¼ë©´ ë”ë¯¸ í•¨ìˆ˜ ì¶”ê°€
                cv2.setNumThreads = lambda x: None
        except ImportError:
            pass
    
    def extract_pdf_paths(self, text: str) -> List[str]:
        """PDF íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ"""
        # PDF íŒŒì¼ ê²½ë¡œ íŒ¨í„´ ë§¤ì¹­
        pdf_patterns = [
            r'([^\s]+\.pdf)',  # ê¸°ë³¸ .pdf íŒŒì¼ ê²½ë¡œ
            r'([C-Z]:[\\\/][^\\\/\s]*\.pdf)',  # Windows ì ˆëŒ€ ê²½ë¡œ
            r'([\.\/][^\\\/\s]*\.pdf)',  # ìƒëŒ€ ê²½ë¡œ
        ]
        
        pdf_paths = []
        for pattern in pdf_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            pdf_paths.extend(matches)
        
        return list(set(pdf_paths))  # ì¤‘ë³µ ì œê±°
    
    def extract_problem_range(self, text: str) -> Optional[Dict]:
        """ë¬¸ì œ ë²ˆí˜¸ ë²”ìœ„ ì¶”ì¶œ"""
        # íŒ¨í„´ë“¤: "5ë²ˆ", "1-10ë²ˆ", "3ë²ˆë¶€í„° 7ë²ˆê¹Œì§€", "1,3,5ë²ˆ"
        patterns = [
            r'(\d+)ë²ˆë§Œ',  # "5ë²ˆë§Œ"
            r'(\d+)ë²ˆ\s*í’€',  # "5ë²ˆ í’€ì–´ì¤˜"
            r'(\d+)\s*[-~]\s*(\d+)ë²ˆ',  # "1-10ë²ˆ", "1~10ë²ˆ"
            r'(\d+)ë²ˆë¶€í„°\s*(\d+)ë²ˆ',  # "3ë²ˆë¶€í„° 7ë²ˆê¹Œì§€"
            r'(\d+(?:\s*,\s*\d+)*)ë²ˆ',  # "1,3,5ë²ˆ"
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                groups = match.groups()
                if len(groups) == 1:
                    if ',' in groups[0]:
                        # ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë²ˆí˜¸ë“¤
                        numbers = [int(x.strip()) for x in groups[0].split(',')]
                        return {"type": "specific", "numbers": numbers}
                    else:
                        # ë‹¨ì¼ ë²ˆí˜¸
                        return {"type": "single", "number": int(groups[0])}
                elif len(groups) == 2:
                    # ë²”ìœ„
                    start, end = int(groups[0]), int(groups[1])
                    return {"type": "range", "start": start, "end": end}
        return None
    
    def determine_problem_source(self, text: str) -> Optional[str]:
        """ë¬¸ì œ ì†ŒìŠ¤ ê²°ì •"""
        text_lower = text.lower()
        
        # ëª…ì‹œì  ì†ŒìŠ¤ ì§€ì •
        if any(keyword in text_lower for keyword in ['pdf', 'íŒŒì¼', 'ë¬¸ì„œ']):
            return "pdf_extracted"
        elif any(keyword in text_lower for keyword in ['ê¸°ì¡´', 'shared', 'ì €ì¥ëœ', 'ì´ì „']):
            return "shared"
        
        # PDF íŒŒì¼ì´ ëª…ì‹œë˜ì—ˆìœ¼ë©´ pdf_extracted ìš°ì„ 
        if self.extract_pdf_paths(text):
            return "pdf_extracted"
        
        # ì•„ë¬´ê²ƒë„ ëª…ì‹œë˜ì§€ ì•Šìœ¼ë©´ None (ìë™ ê²°ì •)
        return None
    
    def extract_problems_from_pdf(self, file_paths: List[str]) -> List[Dict]:
        """PDF íŒŒì¼ì—ì„œ ë¬¸ì œ ì¶”ì¶œ (Docling ì‚¬ìš©)"""
        # Docling ë³€í™˜ê¸° ì´ˆê¸°í™”
        converter = DocumentConverter()
        
        # LLM ì„¤ì •
        llm = ChatOpenAI(
            api_key=os.getenv("GROQ_API_KEY"),
            base_url="https://api.groq.com/openai/v1", 
            model="moonshotai/kimi-k2-instruct",
            temperature=0
        )
        
        all_problems = []
        
        for path in file_paths:
            try:
                print(f"ğŸ“– íŒŒì¼ ì²˜ë¦¬ ì¤‘: {path}")
                
                # Doclingìœ¼ë¡œ PDF ë³€í™˜
                doc_result = converter.convert(path)
                raw_text = doc_result.document.export_to_markdown()
                
                if not raw_text.strip():
                    print(f"âš ï¸ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŒ: {path}")
                    continue
                
                # ë””ë²„ê¹…: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ì¼ë¶€ ì¶œë ¥
                print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):")
                print(f"'{raw_text[:500]}...'")
                print(f"ğŸ“Š ì´ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(raw_text)} ë¬¸ì")
                
                # í…ìŠ¤íŠ¸ë¥¼ ë¸”ë¡ìœ¼ë¡œ ë¶„í• 
                blocks = self._split_problem_blocks(raw_text)
                print(f"ğŸ“ {len(blocks)}ê°œ ë¸”ë¡ìœ¼ë¡œ ë¶„í• ")
                
                # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ë¸”ë¡ ë¯¸ë¦¬ë³´ê¸°
                if blocks:
                    print(f"ğŸ” ì²« ë²ˆì§¸ ë¸”ë¡ ë¯¸ë¦¬ë³´ê¸°:")
                    print(f"'{blocks[0][:300]}...'")
                    if len(blocks) > 1:
                        print(f"ğŸ” ë‘ ë²ˆì§¸ ë¸”ë¡ ë¯¸ë¦¬ë³´ê¸°:")
                        print(f"'{blocks[1][:300]}...'")
                        print(f"ğŸ” ë§ˆì§€ë§‰ ë¸”ë¡ ë¯¸ë¦¬ë³´ê¸°:")
                        print(f"'{blocks[-1][:300]}...')")
                
                # ê° ë¸”ë¡ì„ LLMìœ¼ë¡œ íŒŒì‹±
                successful_parses = 0
                for i, block in enumerate(blocks):
                    block_len = len(block.strip())
                    if block_len < 20:  # í•„í„°ë§ ì¡°ê±´ì„ ì™„í™” (50 â†’ 20)
                        print(f"âš ï¸ ë¸”ë¡ {i+1} ìŠ¤í‚µ (ë„ˆë¬´ ì§§ìŒ: {block_len}ì): '{block[:50]}...'")
                        continue
                    
                    print(f"ğŸ”„ ë¸”ë¡ {i+1}/{len(blocks)} íŒŒì‹± ì¤‘ ({block_len}ì)...")
                    print(f"   ë¯¸ë¦¬ë³´ê¸°: '{block[:100]}...'")
                        
                    try:
                        problem = self._parse_block_with_llm(block, llm)
                        if problem:
                            all_problems.append(problem)
                            successful_parses += 1
                            print(f"âœ… ë¸”ë¡ {i+1} íŒŒì‹± ì„±ê³µ! (ì´ {successful_parses}ê°œ)")
                        else:
                            print(f"âŒ ë¸”ë¡ {i+1} íŒŒì‹± ì‹¤íŒ¨: LLMì´ ìœ íš¨í•œ ë¬¸ì œë¡œ ì¸ì‹í•˜ì§€ ëª»í•¨")
                    except Exception as e:
                        print(f"âš ï¸ ë¸”ë¡ {i+1} íŒŒì‹± ì‹¤íŒ¨: {e}")
                        continue
                        
                print(f"ğŸ“Š íŒŒì‹± ê²°ê³¼: {successful_parses}/{len(blocks)} ë¸”ë¡ ì„±ê³µ")
                        
            except Exception as e:
                print(f"âŒ íŒŒì¼ {path} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue
        
        print(f"ğŸ¯ ì´ {len(all_problems)}ê°œ ë¬¸ì œ ì¶”ì¶œ ì™„ë£Œ")
        return all_problems
    
    def _split_problem_blocks(self, raw_text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì œ ë¸”ë¡ìœ¼ë¡œ ë¶„í•  (ì‹¤ì œ ë¬¸ì œ í—¤ë” ê¸°ë°˜)"""
        print("ğŸ” [êµ¬ì¡° ë¶„ì„] ì‹¤ì œ ë¬¸ì œ í—¤ë” ê¸°ë°˜ìœ¼ë¡œ íŒŒì‹± ë°©ì‹ ê²°ì •")
        
        lines = raw_text.split('\n')
        
        # ì‹¤ì œ ë¬¸ì œ í—¤ë” íŒ¨í„´ë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
        problem_header_patterns = [
            r'^\s*##\s*ë¬¸ì œ\s*(\d+)\s*[.)]\s*',  # "## ë¬¸ì œ 1." (ë§ˆí¬ë‹¤ìš´ í—¤ë”)
            r'^\s*#+\s*ë¬¸ì œ\s*(\d+)\s*[.)]\s*',  # "# ë¬¸ì œ 1.", "### ë¬¸ì œ 1." ë“±
            r'^\s*ë¬¸ì œ\s*(\d+)\s*[.)]\s*',       # "ë¬¸ì œ 1." ë˜ëŠ” "ë¬¸ì œ 1)"
            r'^\s*Q\s*(\d+)\s*[.)]\s*',          # "Q1." ë˜ëŠ” "Q1)"
            r'^\s*\[(\d+)\]\s*',                 # "[1]"
        ]
        
        # ë³´ê¸° ë²ˆí˜¸ íŒ¨í„´ë“¤ (ë¬¸ì œ í—¤ë”ê°€ ì•„ë‹˜)
        option_patterns = [
            r'^\s*(\d+)\.\s*\1\.\s*',           # "4. 4." (ì¤‘ë³µ ë²ˆí˜¸)
            r'^\s*(\d+)\s*[.)]\s*',              # "1)", "2." (ë³´ê¸° ë²ˆí˜¸)
            r'^\s*[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*',      # ì›ë¬¸ì ë³´ê¸°
            r'^\s*[ê°€-í•˜]\s*[)]\s*',            # "ê°€)", "ë‚˜)" (ë³´ê¸°)
            r'^\s*[A-E]\s*[)]\s*',              # "A)", "B)" (ë³´ê¸°)
        ]
        
        # ë¬¸ì œ í—¤ë” ìœ„ì¹˜ ì°¾ê¸°
        problem_headers = []
        
        for i, line in enumerate(lines):
            line_stripped = line.strip()
            if not line_stripped:
                continue
                
            # ë³´ê¸° ë²ˆí˜¸ì¸ì§€ ë¨¼ì € í™•ì¸
            is_option = False
            for pattern in option_patterns:
                if re.match(pattern, line_stripped):
                    is_option = True
                    break
            
            if is_option:
                continue  # ë³´ê¸° ë²ˆí˜¸ëŠ” ìŠ¤í‚µ
            
            # ë¬¸ì œ í—¤ë”ì¸ì§€ í™•ì¸
            for pattern in problem_header_patterns:
                match = re.match(pattern, line_stripped)
                if match:
                    problem_num = int(match.group(1))
                    problem_headers.append((i, problem_num, line_stripped))
                    print(f"âœ… [ë¬¸ì œ í—¤ë” ë°œê²¬] ë¼ì¸ {i+1}: '{line_stripped}' (ë¬¸ì œ {problem_num}ë²ˆ)")
                    break
        
        if not problem_headers:
            print("âš ï¸ ë¬¸ì œ í—¤ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ - ì „ì²´ë¥¼ 1ê°œ ë¸”ë¡ìœ¼ë¡œ ì²˜ë¦¬")
            return [raw_text] if raw_text.strip() else []
        
        print(f"ğŸ” ì´ {len(problem_headers)}ê°œ ë¬¸ì œ í—¤ë” ë°œê²¬")
        
        # ë¬¸ì œ í—¤ë”ë¥¼ ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬
        problem_headers.sort(key=lambda x: x[1])
        
        # ë¬¸ì œ ë¸”ë¡ ìƒì„±
        problem_blocks = []
        
        for i, (header_idx, problem_num, header_text) in enumerate(problem_headers):
            # í˜„ì¬ ë¬¸ì œì˜ ì‹œì‘
            start_line = header_idx
            
            # ë‹¤ìŒ ë¬¸ì œì˜ ì‹œì‘ (ë˜ëŠ” ë§ˆì§€ë§‰)
            if i + 1 < len(problem_headers):
                end_line = problem_headers[i + 1][0]
            else:
                end_line = len(lines)
            
            # ë¬¸ì œ ë¸”ë¡ í…ìŠ¤íŠ¸ ìƒì„±
            problem_text = '\n'.join(lines[start_line:end_line]).strip()
            
            if problem_text:
                problem_blocks.append(problem_text)
                print(f"ğŸ“¦ ë¬¸ì œ {problem_num}ë²ˆ: ë¼ì¸ {start_line+1}-{end_line} ({len(problem_text)}ì)")
                print(f"   í—¤ë”: '{header_text}'")
        
        print(f"âœ… ì´ {len(problem_blocks)}ê°œ ë¬¸ì œ ë¸”ë¡ ìƒì„± ì™„ë£Œ")
        return problem_blocks
    
    def _merge_blocks_by_question(self, micro_blocks: List[str]) -> List[str]:
        """ë¯¸ì„¸ ë¶„í• ëœ ë¸”ë¡ë“¤ì„ ë¬¸ì œë³„ë¡œ ì¬ë¬¶ê¸°"""
        if not micro_blocks:
            return []
        
        print(f"ğŸ”„ [ì¬ë¬¶ê¸°] {len(micro_blocks)}ê°œ ë¯¸ì„¸ ë¸”ë¡ì„ ë¬¸ì œë³„ë¡œ ë¬¶ëŠ” ì¤‘...")
        
        # ë¬¸ì œ í—¤ë” íŒ¨í„´ë“¤ (ë§ˆí¬ë‹¤ìš´ í—¤ë” ìš°ì„ , ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›)
        question_patterns = [
            r'^\s*##\s*ë¬¸ì œ\s*(\d+)\s*[.)]\s*',  # "## ë¬¸ì œ 1." (ë§ˆí¬ë‹¤ìš´ í—¤ë” ìš°ì„ )
            r'^\s*#+\s*ë¬¸ì œ\s*(\d+)\s*[.)]\s*',  # "# ë¬¸ì œ 1.", "### ë¬¸ì œ 1." ë“±
            r'^\s*ë¬¸ì œ\s*(\d+)\s*[.)]\s*',       # "ë¬¸ì œ 1." ë˜ëŠ” "ë¬¸ì œ 1)"
            r'^\s*(\d+)\s*[.)]\s*(?![â‘ â‘¡â‘¢â‘£â‘¤])', # "1." (ë³´ê¸°ê°€ ì•„ë‹Œ ê²½ìš°)
            r'^\s*Q\s*(\d+)\s*[.)]\s*',          # "Q1." ë˜ëŠ” "Q1)"
            r'^\s*\[(\d+)\]\s*',                 # "[1]"
        ]
        
        # ë³´ê¸° íŒ¨í„´ë“¤ (ë¬¸ì œì™€ êµ¬ë¶„í•˜ê¸° ìœ„í•´)
        option_patterns = [
            r'^\s*[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]',      # ì›ë¬¸ì ë³´ê¸°
            r'^\s*[1-5]\s*[)]\s*\S',        # "1) ë‚´ìš©" (ì§§ì€ ìˆ«ì + ë‚´ìš©)
            r'^\s*[ê°€-í•˜]\s*[)]\s*',        # "ê°€) ë‚´ìš©"
            r'^\s*[A-E]\s*[)]\s*',          # "A) ë‚´ìš©"
        ]
        
        merged_blocks = []
        current_block = ""
        current_question_num = 0
        
        for i, block in enumerate(micro_blocks):
            block = block.strip()
            if not block:
                continue
            
            # ë¬¸ì œ í—¤ë”ì¸ì§€ í™•ì¸
            is_question_header = False
            question_num = 0
            
            for pattern in question_patterns:
                match = re.match(pattern, block, re.IGNORECASE)
                if match:
                    # ë³´ê¸°ê°€ ì•„ë‹Œì§€ ì¶”ê°€ í™•ì¸
                    is_option = any(re.match(opt_pattern, block) for opt_pattern in option_patterns)
                    if not is_option:
                        is_question_header = True
                        question_num = int(match.group(1))
                        print(f"âœ… [ë¬¸ì œ í—¤ë” ë°œê²¬] ë¸”ë¡ {i+1}: '{block[:50]}...' (ë¬¸ì œ {question_num}ë²ˆ)")
                        break
            
            if is_question_header and current_block:
                # ìƒˆë¡œìš´ ë¬¸ì œ ì‹œì‘ - ì´ì „ ë¸”ë¡ ì €ì¥
                merged_blocks.append(current_block.strip())
                current_block = block
                current_question_num = question_num
                print(f"ğŸ“¦ [ë¸”ë¡ ì™„ì„±] {len(merged_blocks)}ë²ˆì§¸ ë¬¸ì œ ë¸”ë¡ ìƒì„± ({len(current_block)}ì)")
            else:
                # í˜„ì¬ ë¬¸ì œì— ì¶”ê°€
                if current_block:
                    current_block += "\n\n" + block
                else:
                    current_block = block
                    if is_question_header:
                        current_question_num = question_num
        
        # ë§ˆì§€ë§‰ ë¸”ë¡ ì¶”ê°€
        if current_block:
            merged_blocks.append(current_block.strip())
            print(f"ğŸ“¦ [ë¸”ë¡ ì™„ì„±] {len(merged_blocks)}ë²ˆì§¸ ë¬¸ì œ ë¸”ë¡ ìƒì„± ({len(current_block)}ì)")
        
        print(f"ğŸ¯ [ì¬ë¬¶ê¸° ì™„ë£Œ] {len(micro_blocks)}ê°œ â†’ {len(merged_blocks)}ê°œ ë¬¸ì œ ë¸”ë¡")
        
        # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ë¸”ë¡ ë¯¸ë¦¬ë³´ê¸°
        if merged_blocks:
            print(f"ğŸ” [ì¬ë¬¶ê¸° ê²°ê³¼] ì²« ë²ˆì§¸ ë¬¸ì œ ë¸”ë¡:")
            print(f"'{merged_blocks[0][:200]}...'")
        
        return merged_blocks
    
    def normalize_docling_markdown(self, md: str) -> str:
        """Docling ë§ˆí¬ë‹¤ìš´ ì •ê·œí™”"""
        s = md
        s = re.sub(r'(?m)^\s*(\d+)\.\s*\1\.\s*', r'\1. ', s)  # '1. 1.' -> '1.'
        s = re.sub(r'(?m)^\s*(\d+)\s*\.\s*', r'\1. ', s)      # '1 . ' -> '1. '
        s = re.sub(r'[ \t]+', ' ', s).replace('\r', '')
        return s.strip()
    
    def _find_option_clusters(self, lines: List[str], start: int, end: int) -> List[Tuple[int, int]]:
        """
        [start, end) ë¼ì¸ êµ¬ê°„ì—ì„œ ì˜µì…˜ ë¼ì¸ì´ 3ê°œ ì´ìƒ ì—°ì†ë˜ëŠ” êµ¬ê°„ë“¤ì„ ë°˜í™˜.
        (ë³´ê¸° ì˜ì—­ ì‹ë³„ìš©)
        """
        _OPT_LINE = re.compile(
            r'(?m)^\s*(?:\(?([1-5])\)?\.?|[â‘ -â‘¤]|[ê°€-í•˜]\)|[A-Z]\))\s+\S'
        )
        
        clusters = []
        i = start
        while i < end:
            if _OPT_LINE.match(lines[i] or ''):
                j = i
                cnt = 0
                while j < end and _OPT_LINE.match(lines[j] or ''):
                    cnt += 1
                    j += 1
                if cnt >= 3:
                    clusters.append((i, j))  # [i, j) ì˜µì…˜ ë¸”ë¡
                i = j
            else:
                i += 1
        return clusters
    
    def split_problem_blocks_without_keyword(self, text: str) -> List[str]:
        """
        'ë¬¸ì œ' í‚¤ì›Œë“œê°€ ì—†ëŠ” ì‹œí—˜ì§€ì—ì„œ ë²ˆí˜¸(1., 2., â€¦)ë§Œìœ¼ë¡œ ë¬¸í•­ ë‹¨ìœ„ë¥¼ ë¶„í• .
        - ì „ì—­ ì¦ê°€ ì‹œí€€ìŠ¤(prev+1) íœ´ë¦¬ìŠ¤í‹±
        - ì„¹ì…˜ ë¦¬ì…‹(ë²ˆí˜¸=1) ì œí•œì  í—ˆìš©
        - ì˜µì…˜ í´ëŸ¬ìŠ¤í„°(ì—°ì† 3+)ëŠ” ë¬¸í•­ í—¤ë”ë¡œ ì·¨ê¸‰í•˜ì§€ ì•ŠìŒ
        """
        text = self.normalize_docling_markdown(text)
        lines = text.split('\n')
        n = len(lines)

        # ë¯¸ë¦¬ ì˜µì…˜ í´ëŸ¬ìŠ¤í„°ë¥¼ ê³„ì‚°í•´ë†“ê³ , ê·¸ ë‚´ë¶€ ë²ˆí˜¸ëŠ” ë¬¸í•­ í—¤ë”ë¡œ ì•ˆ ë´„
        clusters = self._find_option_clusters(lines, 0, n)

        def in_option_cluster(idx: int) -> bool:
            for a, b in clusters:
                if a <= idx < b:
                    return True
            return False

        # ë¬¸í•­ í—¤ë” í›„ë³´ ì¸ë±ìŠ¤ ìˆ˜ì§‘
        _QHEAD_CAND = re.compile(r'(?m)^\s*(\d{1,3})[.)]\s+\S')
        candidates = []
        for i, ln in enumerate(lines):
            m = _QHEAD_CAND.match(ln or '')
            if not m:
                continue
            if in_option_cluster(i):
                # ë³´ê¸° ë¸”ë¡ ì•ˆì˜ ë²ˆí˜¸ëŠ” ë¬¸í•­ í—¤ë”ê°€ ì•„ë‹˜
                print(f"ğŸ” [ë””ë²„ê·¸] ë¼ì¸ {i}: '{ln[:50]}...' (ì˜µì…˜ í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ - ìŠ¤í‚µ)")
                continue
            num = int(m.group(1))
            candidates.append((i, num))
            print(f"ğŸ” [ë””ë²„ê·¸] ë¼ì¸ {i}: '{ln[:50]}...' â†’ í›„ë³´ ë²ˆí˜¸ {num}")
        
        print(f"ğŸ” [ë””ë²„ê·¸] ì´ í›„ë³´ ìˆ˜: {len(candidates)}")
        print(f"ğŸ” [ë””ë²„ê·¸] ì˜µì…˜ í´ëŸ¬ìŠ¤í„° ìˆ˜: {len(clusters)}")

        # ì „ì—­ ì¦ê°€ ì‹œí€€ìŠ¤ + ì„¹ì…˜ ë¦¬ì…‹ í—ˆìš©ìœ¼ë¡œ ì‹¤ì œ í—¤ë” ì„ ë³„
        headers = []
        prev_num = 0
        last_header_idx = -9999
        for i, num in candidates:
            if num == prev_num + 1:
                headers.append(i)
                prev_num = num
                last_header_idx = i
                print(f"âœ… [ë””ë²„ê·¸] ë¼ì¸ {i}: ë²ˆí˜¸ {num} - ìˆœì°¨ ì¦ê°€ë¡œ í—¤ë” ì„ íƒ")
                continue
            # ì„¹ì…˜ ë¦¬ì…‹: num==1ì´ê³ , ìµœê·¼ í—¤ë”ì—ì„œ ì¶©ë¶„íˆ ë–¨ì–´ì ¸ ìˆê±°ë‚˜ ì„¹ì…˜ ëŠë‚Œì˜ ë¼ì¸ ì¡´ì¬ ì‹œ í—ˆìš©
            if num == 1:
                window = '\n'.join(lines[max(0, i-3): i+1])
                if (i - last_header_idx) >= 8 or re.search(r'(â… |â…¡|III|ê³¼ëª©|íŒŒíŠ¸|SECTION)', window):
                    headers.append(i)
                    prev_num = 1
                    last_header_idx = i
                    print(f"âœ… [ë””ë²„ê·¸] ë¼ì¸ {i}: ë²ˆí˜¸ {num} - ì„¹ì…˜ ë¦¬ì…‹ìœ¼ë¡œ í—¤ë” ì„ íƒ")
                    continue
                else:
                    print(f"âŒ [ë””ë²„ê·¸] ë¼ì¸ {i}: ë²ˆí˜¸ {num} - ì„¹ì…˜ ë¦¬ì…‹ ì¡°ê±´ ë¶ˆì¶©ì¡± (ê±°ë¦¬: {i - last_header_idx})")
            else:
                print(f"âŒ [ë””ë²„ê·¸] ë¼ì¸ {i}: ë²ˆí˜¸ {num} - ìˆœì°¨ ì¦ê°€ ì•„ë‹˜ (ì˜ˆìƒ: {prev_num + 1})")
            # ê·¸ ì™¸ëŠ” ì˜µì…˜/ë…¸ì´ì¦ˆë¡œ ë¬´ì‹œ

        # í—¤ë”ê°€ í•˜ë‚˜ë„ ì•ˆ ì¡íˆë©´ í´ë°± ì „ëµ ì‚¬ìš©
        if not headers:
            print(f"âŒ [ë””ë²„ê·¸] í—¤ë”ê°€ í•˜ë‚˜ë„ ì„ íƒë˜ì§€ ì•ŠìŒ - í´ë°± ì „ëµ ì‚¬ìš©")
            # í´ë°± 1: ë” ëŠìŠ¨í•œ ì¡°ê±´ìœ¼ë¡œ ì¬ì‹œë„
            if candidates:
                print(f"ğŸ”„ [í´ë°±] ìˆœì°¨ ì¡°ê±´ ì—†ì´ ëª¨ë“  í›„ë³´ë¥¼ í—¤ë”ë¡œ ì‚¬ìš©")
                headers = [i for i, num in candidates]
            else:
                # í´ë°± 2: ê¸°ë³¸ ë²ˆí˜¸ íŒ¨í„´ìœ¼ë¡œ ë¶„í• 
                print(f"ğŸ”„ [í´ë°±] ê¸°ë³¸ ë²ˆí˜¸ íŒ¨í„´ìœ¼ë¡œ ë¶„í• ")
                simple_pattern = re.compile(r'(?m)^\s*(\d{1,2})\.\s+')
                for i, ln in enumerate(lines):
                    if simple_pattern.match(ln or ''):
                        headers.append(i)
                        print(f"ğŸ“Œ [í´ë°±] ë¼ì¸ {i}: '{ln[:30]}...' â†’ í—¤ë” ì¶”ê°€")
            
            if not headers:
                print(f"âŒ [í´ë°± ì‹¤íŒ¨] ì „ì²´ë¥¼ 1ê°œ ë¸”ë¡ìœ¼ë¡œ ì²˜ë¦¬")
                return [text] if text.strip() else []

        print(f"âœ… [ë””ë²„ê·¸] ìµœì¢… ì„ íƒëœ í—¤ë” ìˆ˜: {len(headers)}")
        
        # í—¤ë” ë²”ìœ„ë¡œ ë¸”ë¡ ë§Œë“¤ê¸°
        headers.append(n)  # sentinel
        blocks = []
        for a, b in zip(headers[:-1], headers[1:]):
            blk = '\n'.join(lines[a:b]).strip()
            if blk:
                blocks.append(blk)
                print(f"ğŸ“¦ [ë””ë²„ê·¸] ë¸”ë¡ {len(blocks)}: ë¼ì¸ {a}-{b-1} ({len(blk)}ì)")
        
        print(f"ğŸ¯ [ë””ë²„ê·¸] ìµœì¢… ë¸”ë¡ ìˆ˜: {len(blocks)}")
        return blocks
    
    def _parse_block_with_llm(self, block_text: str, llm) -> Optional[Dict]:
        """LLMìœ¼ë¡œ ë¸”ë¡ì„ ë¬¸ì œ í˜•íƒœë¡œ íŒŒì‹±"""
        sys_prompt = (
            "ë„ˆëŠ” ì‹œí—˜ ë¬¸ì œ PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”í•˜ëŠ” ë„ìš°ë¯¸ë‹¤. "
            "ë¬¸ì œ ì§ˆë¬¸ê³¼ ë³´ê¸°ë¥¼ êµ¬ë¶„í•´ì„œ questionê³¼ options ë°°ì—´ë¡œ ì¶œë ¥í•œë‹¤. "
            "optionsëŠ” ë³´ê¸° í•­ëª©ë§Œ í¬í•¨í•˜ê³ , ì„¤ëª…/í•´ì„¤/ì •ë‹µ ë“±ì€ í¬í•¨í•˜ì§€ ì•ŠëŠ”ë‹¤. "
            "ì‘ë‹µì€ ë°˜ë“œì‹œ JSON í˜•íƒœë¡œë§Œ ì¶œë ¥í•œë‹¤. ë‹¤ë¥¸ ë¬¸ì¥ì´ë‚˜ ì½”ë“œëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ ê²ƒ."
        )
        
        user_prompt = (
            "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ë¬¸í•­ì„ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ, ì •í™•íˆ ì¶”ì¶œí•´ JSONìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜.\n"
            "ìš”êµ¬ ìŠ¤í‚¤ë§ˆ: {\"question\":\"...\",\"options\":[\"...\",\"...\"]}\n"
            "ê·œì¹™:\n"
            "- ë¬¸ì œ ì§ˆë¬¸ì—ì„œ ë²ˆí˜¸(ì˜ˆ: 'ë¬¸ì œ 1.' ë“±)ì™€ ë¶ˆí•„ìš”í•œ ë¨¸ë¦¬ê¸€ì€ ì œê±°.\n"
            "- ì˜µì…˜ì€ 4ê°œê°€ ì¼ë°˜ì ì„.\n"
            f"í…ìŠ¤íŠ¸:\n{block_text[:1000]}"  # ë„ˆë¬´ ê¸´ í…ìŠ¤íŠ¸ëŠ” ì˜ë¼ì„œ
        )
        
        try:
            response = llm.invoke([
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": user_prompt}
            ])
            
            content = response.content.strip()
            
            # JSON ì¶”ì¶œ
            if content.startswith('```'):
                content = re.sub(r'^```(?:json)?\s*', '', content)
                content = re.sub(r'\s*```$', '', content)
            
            data = json.loads(content)
            
            # ìœ íš¨ì„± ê²€ì‚¬
            if isinstance(data, dict) and "question" in data and "options" in data:
                if data["question"].strip() and isinstance(data["options"], list) and len(data["options"]) > 0:
                    return data
                    
        except Exception as e:
            print(f"âš ï¸ LLM íŒŒì‹± ì‹¤íŒ¨: {e}")
            
        return None


# í¸ì˜ë¥¼ ìœ„í•œ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±)
def extract_pdf_paths(text: str) -> List[str]:
    """PDF íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ (í¸ì˜ í•¨ìˆ˜)"""
    preprocessor = PDFPreprocessor()
    return preprocessor.extract_pdf_paths(text)


def extract_problem_range(text: str) -> Optional[Dict]:
    """ë¬¸ì œ ë²ˆí˜¸ ë²”ìœ„ ì¶”ì¶œ (í¸ì˜ í•¨ìˆ˜)"""
    preprocessor = PDFPreprocessor()
    return preprocessor.extract_problem_range(text)


def determine_problem_source(text: str) -> Optional[str]:
    """ë¬¸ì œ ì†ŒìŠ¤ ê²°ì • (í¸ì˜ í•¨ìˆ˜)"""
    preprocessor = PDFPreprocessor()
    return preprocessor.determine_problem_source(text)
