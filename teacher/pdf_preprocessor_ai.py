# teacher/pdf_preprocessor_ai.py
# -*- coding: utf-8 -*-
"""
PDF ì „ì²˜ë¦¬ & ë¬¸ì œ ì¶”ì¶œ (ì—´ ë‹¨ìœ„ LLM íŒŒì´í”„ë¼ì¸, ì •ë¦¬íŒ)

í•µì‹¬ ì•„ì´ë””ì–´
- PDFMinerë¡œ í˜ì´ì§€ë§ˆë‹¤ ì¢Œ/ìš° ì—´ í…ìŠ¤íŠ¸ ë¶„ë¦¬
- ê° ì—´ì„ í†µìœ¼ë¡œ(ì•ˆì „ ì²­í¬) LLMì— ë„˜ê²¨ ë¬¸í•­ ë°°ì—´(JSON) ì¶”ì¶œ
- í—¤ë”/ë²ˆí˜¸ ê¸°ë°˜ ë¶„í• , ë³µì¡í•œ í—¤ë” ì¶”ì • ë¡œì§ ì œê±°
"""

import os
import re, traceback
import json
import hashlib
import html
from typing import List, Dict, Optional
from dotenv import load_dotenv

load_dotenv()

from docling.document_converter import DocumentConverter
from langchain_openai import ChatOpenAI

# â”€â”€ LLM ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_LLM_MODEL = os.getenv("OPENAI_LLM_MODEL", "moonshotai/kimi-k2-instruct")
LLM_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.0"))  # ì•ˆì •ì„±â†‘
LLM_MAX_TOKENS = int(os.getenv("LLM_MAX_TOKENS", "2048"))


class PDFPreprocessor:
    """PDF íŒŒì¼ ì „ì²˜ë¦¬ ë° ë¬¸ì œ ì¶”ì¶œ (ì—´ ë‹¨ìœ„)"""

    def __init__(self):
        # ê¶Œí•œ/ìºì‹œ ê´€ë ¨ (Windows í™˜ê²½ ëŒ€ì‘)
        os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
        os.environ["HF_HOME"] = os.getenv("HF_HOME", "C:\\temp\\huggingface_cache")

        # ì¼ë¶€ OpenCV ë¹Œë“œì—ì„œ setNumThreads ë¯¸ì¡´ì¬ ì´ìŠˆ íšŒí”¼
        try:
            import cv2  # noqa: F401
            if not hasattr(cv2, "setNumThreads"):
                cv2.setNumThreads = lambda x: None  # type: ignore[attr-defined]
        except ImportError:
            pass
        

        
    # ====== JSON íŒŒì‹± ìœ í‹¸: PDFPreprocessor ë‚´ë¶€ ë©”ì„œë“œë¡œ ì¶”ê°€ ======

    def _strip_code_fences(self, text: str) -> str:
        # ```json ... ``` ê°™ì€ ì½”ë“œíœìŠ¤ ì œê±°
        return re.sub(r"```(?:json)?\s*|\s*```", "", text).strip()

    def _repair_brackets(self, text: str) -> str:
        # ê°€ì¥ ë°”ê¹¥ì˜ ëŒ€ê´„í˜¸ êµ¬ê°„ë§Œ ë³´ì¡´
        if "[" in text and "]" in text:
            s = text.find("["); e = text.rfind("]")
            return text[s:e+1]
        return text

    def _find_largest_json_array(self, text: str) -> str:
        """ì‘ë‹µ ë³¸ë¬¸ì—ì„œ ê°€ì¥ í° JSON ë°°ì—´ êµ¬ê°„ì„ ì°¾ì•„ ë°˜í™˜(ë¬¸í•­/ë³´ê¸° í‚¤ í¬í•¨ ìš°ì„ )."""
        text = self._strip_code_fences(text)
        # ê´„í˜¸ ìŠ¤íŒ¬ ìˆ˜ì§‘
        spans, stack = [], []
        for i, ch in enumerate(text):
            if ch == "[":
                stack.append(i)
            elif ch == "]" and stack:
                start = stack.pop()
                spans.append((start, i))
        spans.sort(key=lambda t: t[1]-t[0], reverse=True)
        for s, e in spans:
            sub = text[s:e+1]
            if '"question"' in sub and '"options"' in sub:
                return sub
        return self._repair_brackets(text)

    def _parse_mcq_json_safely(self, text: str):
        """LLM ì‘ë‹µ â†’ JSON ë°°ì—´(ë¬¸í•­ ìµœì†Œ ì •í•©ì„± í•„í„° í¬í•¨). ì‹¤íŒ¨ ì‹œ []."""
        try:
            cleaned = html.unescape(text or "")
            candidate = self._find_largest_json_array(cleaned)
            if not candidate:
                return []
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                data = json.loads(candidate)
            except json.JSONDecodeError:
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìˆ˜ì • ì‹œë„
                fixed = self._fix_json_format(candidate)
                try:
                    data = json.loads(fixed)
                except json.JSONDecodeError:
                    return []
            
            # ê²°ê³¼ ê²€ì¦ ë° ì •ë¦¬
            out = []
            if isinstance(data, list):
                items = data
            elif isinstance(data, dict):
                items = [data]
            else:
                return []
                
            for item in items:
                if not isinstance(item, dict):
                    continue
                    
                q = str(item.get("question", "")).strip()
                opts = [str(o).strip() for o in (item.get("options") or []) if str(o).strip()]
                
                # ìµœì†Œ ê²€ì¦: ì§ˆë¬¸ 3ì ì´ìƒ, ë³´ê¸° 2ê°œ ì´ìƒ
                if len(q) >= 3 and len(opts) >= 2:
                    # ë³´ê¸° ì •ë¦¬ (ë²ˆí˜¸/ì›ë¬¸ì ì œê±°)
                    clean_opts = []
                    for opt in opts[:4]:  # ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ
                        clean_opt = re.sub(r"^(?:[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]|\d+\)|[A-E]\)|[ê°€-í•˜]\))\s*", "", opt)
                        if clean_opt.strip():
                            clean_opts.append(clean_opt.strip())
                    
                    if len(clean_opts) >= 2:  # ìµœì†Œ 2ê°œ ë³´ê¸° í•„ìš”
                        out.append({
                            "question": re.sub(r"\s+", " ", q), 
                            "options": clean_opts
                        })
            
            return out
            
        except Exception as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            return []


    # ========== ê³µê°œ API =======================================================
    

    def extract_problems_from_pdf(self, file_paths: List[str]) -> List[Dict]:
        """PDF íŒŒì¼ë“¤ì—ì„œ ë¬¸ì œ(question, options[]) ì¶”ì¶œ"""
        # Docling ì´ˆê¸°í™”
        try:
            print("ğŸ”§ DocumentConverter ì´ˆê¸°í™” ì¤‘...")
            converter = DocumentConverter()
            try:
                converter.config.image_processing = False
                print("âœ… ì´ë¯¸ì§€ ì²˜ë¦¬ ë¹„í™œì„±í™” ì„¤ì •")
            except Exception:
                print("âš ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì„¤ì • ë³€ê²½ ë¶ˆê°€")
            try:
                converter.config.text_extraction_priority = "text"
                print("âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ìš°ì„ ìˆœìœ„ ì„¤ì •")
            except Exception:
                print("âš ï¸ í…ìŠ¤íŠ¸ ì¶”ì¶œ ìš°ì„ ìˆœìœ„ ì„¤ì • ë¶ˆê°€")
            print("âœ… DocumentConverter ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ DocumentConverter ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return []

        # LLM í´ë¼ì´ì–¸íŠ¸
        llm = ChatOpenAI(
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url=os.getenv("OPENAI_BASE_URL", "https://api.groq.com/openai/v1"),
            model=OPENAI_LLM_MODEL,
            temperature=LLM_TEMPERATURE,
            max_tokens=LLM_MAX_TOKENS,
        )

        all_problems: List[Dict] = []

        for path in file_paths:
            try:
                print(f"ğŸ“– íŒŒì¼ ì²˜ë¦¬ ì¤‘: {path}")
                doc_result = converter.convert(path)

                # Doclingì—ì„œ ë§ˆí¬ë‹¤ìš´ ì¶”ì¶œ(ì›ë¬¸ ë³´ê´€: í´ë°±ìš©)
                raw_text = doc_result.document.export_to_markdown()
                raw_text = self.normalize_docling_markdown(raw_text)
                raw_text = self._strip_headers_for_llm(raw_text)
                raw_text = self._fix_korean_spacing_noise(raw_text)
                print(f"ğŸ“Š Docling í…ìŠ¤íŠ¸ ê¸¸ì´: {len(raw_text)}")

                # 1) ì „ì²´ í…ìŠ¤íŠ¸ ìš°ì„  íŒŒì‹± (ê°€ì¥ ì •í™•)
                print("ğŸ§­ ì „ì²´ í…ìŠ¤íŠ¸ ìš°ì„  íŒŒì‹± ì‹œì‘")
                full_text_problems = self._parse_full_text_with_fallback(raw_text, llm)
                
                local: List[Dict] = []
                if full_text_problems:
                    print(f"âœ… ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ {len(full_text_problems)}ê°œ ë¬¸ì œ ì¶”ì¶œ")
                    local = full_text_problems
                else:
                    # 2) í´ë°±: ì»¬ëŸ¼ë³„ íŒŒì‹±
                    print("ğŸ” ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹¤íŒ¨ â†’ ì»¬ëŸ¼ë³„ íŒŒì‹± ì‹œë„")
                    col_batch = self._parse_by_columns_with_llm(path, llm)
                    if col_batch:
                        local = col_batch
                        print(f"âœ… ì»¬ëŸ¼ë³„ íŒŒì‹±ì—ì„œ {len(col_batch)}ê°œ ë¬¸ì œ ì¶”ì¶œ")
                    else:
                        # 3) ìµœì¢… í´ë°±: ì›ë¬¸ ì „ì²´ë¥¼ ì•ˆì „ ì²­í¬ë¡œ ë‚˜ëˆ  ì¼ê´„ ì¶”ì¶œ
                        print("ğŸ” ìµœì¢… í´ë°±: ì›ë¬¸ ì „ì²´ ì¼ê´„ ì¶”ì¶œ")
                        for chunk in self._chunk_by_paragraph(raw_text, max_chars=16000):
                            batch = self._parse_whole_text_with_llm(chunk, llm)
                            if batch:
                                local.extend(batch)

                # ì¤‘ë³µ ì œê±°
                before = len(local)
                local = self._dedupe_problems(local)
                print(f"ğŸ§¹ dedupe: {before} â†’ {len(local)}")

                all_problems.extend(local)
                print(f"ğŸ“Š ëˆ„ì  ë¬¸ì œ ìˆ˜: {len(all_problems)}")

            except Exception as e:
                print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                continue

        print(f"ğŸ¯ ì´ {len(all_problems)}ê°œ ë¬¸ì œ ì¶”ì¶œ ì™„ë£Œ")
        return all_problems

    # ========== ì—´(ì»¬ëŸ¼) ì¶”ì¶œ & ì¼ê´„ LLM =======================================

    def _extract_columns_with_pdfminer(self, pdf_path: str):
        """ê° í˜ì´ì§€ë¥¼ (left_text, right_text)ë¡œ ë¶„ë¦¬"""
        try:
            from pdfminer.high_level import extract_pages
            from pdfminer.layout import LTTextContainer
        except Exception as e:
            print(f"âš ï¸ pdfminer import ì‹¤íŒ¨: {e}")
            return []

        pages_cols = []
        try:
            for page_layout in extract_pages(pdf_path):
                left, right = [], []
                xs = []
                for el in page_layout:
                    if isinstance(el, LTTextContainer):
                        xs.append(el.bbox[0])
                if not xs:
                    pages_cols.append({"left": "", "right": ""})
                    continue

                mid = sorted(xs)[len(xs) // 2]

                for el in page_layout:
                    if isinstance(el, LTTextContainer):
                        x0, y0, x1, y1 = el.bbox
                        txt = el.get_text().strip()
                        if not txt:
                            continue
                        (left if x0 < mid else right).append((y1, txt))

                left.sort(key=lambda t: -t[0])
                right.sort(key=lambda t: -t[0])

                left_text = "".join(t for _, t in left)
                right_text = "".join(t for _, t in right)
                pages_cols.append({"left": left_text, "right": right_text})
        except Exception as e:
            print(f"âš ï¸ ì»¬ëŸ¼ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

        print(f"âœ… [ì»¬ëŸ¼ ì¶”ì¶œ] ì´ {len(pages_cols)}í˜ì´ì§€ ì²˜ë¦¬ ì™„ë£Œ")
        return pages_cols

    def _parse_by_columns_with_llm(self, pdf_path: str, llm) -> Optional[List[Dict]]:
        """ì¢Œ/ìš° ì—´ì„ í†µìœ¼ë¡œ LLMì— ë„˜ê²¨ ë¬¸í•­ ë°°ì—´ ì¶”ì¶œ"""
        cols = self._extract_columns_with_pdfminer(pdf_path)
        if not cols:
            return None

        left_stream = "\n\n".join(p["left"] for p in cols if p.get("left"))
        right_stream = "\n\n".join(p["right"] for p in cols if p.get("right"))

        results: List[Dict] = []
        for label, stream in (("LEFT", left_stream), ("RIGHT", right_stream)):
            text = self.normalize_docling_markdown(stream)
            text = self._strip_headers_for_llm(text)
            text = self._fix_korean_spacing_noise(text)

            chunks = self._chunk_by_paragraph(text, max_chars=16000)
            print(f"ğŸ§± [{label}] ì²­í¬ {len(chunks)}ê°œ")
            for idx, chunk in enumerate(chunks, 1):
                batch = self._parse_whole_text_with_llm(chunk, llm)
                if batch:
                    print(f"âœ… [{label}] ì²­í¬ {idx} â†’ {len(batch)}ê°œ ì¶”ì¶œ")
                    results.extend(batch)
                else:
                    print(f"âš ï¸ [{label}] ì²­í¬ {idx} ì¶”ì¶œ 0ê°œ")

        return results if results else None

    # ========== ì „ì²´ í…ìŠ¤íŠ¸ ìš°ì„  íŒŒì‹± (í´ë°± ë©”ì»¤ë‹ˆì¦˜ í¬í•¨) =====================

    def _parse_full_text_with_fallback(self, full_text: str, llm) -> Optional[List[Dict]]:
        """ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ë¬¸ì œë¥¼ ì¶”ì¶œí•˜ê³ , ì§ì´ ì—†ëŠ” í•­ëª©ë“¤ì„ í´ë°±ìœ¼ë¡œ ì²˜ë¦¬"""
        print("ğŸ” ì „ì²´ í…ìŠ¤íŠ¸ íŒŒì‹± ì‹œì‘")
        
        # 1ë‹¨ê³„: ì²­í¬ ë‚´ë¶€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ íƒìƒ‰í•˜ë©´ì„œ ë¬¸ì œë¥¼ í•˜ë‚˜ì”© ì¶”ì¶œ
        problems = self._parse_text_incrementally(full_text, llm)
        if problems:
            print(f"âœ… ìˆœì°¨ íŒŒì‹±ì—ì„œ {len(problems)}ê°œ ë¬¸ì œ ì¶”ì¶œ ì„±ê³µ")
            return problems
        
        # 2ë‹¨ê³„: í´ë°± - ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë¬¸ì œ-ë³´ê¸° íŒ¨í„´ ì°¾ê¸°
        print("ğŸ”„ LLM íŒŒì‹± ì‹¤íŒ¨ â†’ ì •ê·œí‘œí˜„ì‹ í´ë°± ì‹œì‘")
        regex_problems = self._extract_problems_with_regex(full_text)
        if regex_problems:
            print(f"âœ… ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ {len(regex_problems)}ê°œ ë¬¸ì œ ì¶”ì¶œ")
            return regex_problems
        
        print("âŒ ëª¨ë“  íŒŒì‹± ë°©ë²• ì‹¤íŒ¨")
        return None

    def _parse_text_incrementally(self, full_text: str, llm) -> List[Dict]:
        """ì²­í¬ ë‚´ë¶€ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ íƒìƒ‰í•˜ë©´ì„œ ë¬¸ì œë¥¼ í•˜ë‚˜ì”© ì¶”ì¶œ"""
        all_problems = []
        
        # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì œ ë‹¨ìœ„ë¡œ ë¶„í•  (ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë¬¸ì œ ë²ˆí˜¸ ê¸°ì¤€)
        problem_segments = self._split_text_by_problems(full_text)
        print(f"ğŸ” ì´ {len(problem_segments)}ê°œ ë¬¸ì œ ì„¸ê·¸ë¨¼íŠ¸ ë°œê²¬")
        
        for i, segment in enumerate(problem_segments, 1):
            if len(segment.strip()) < 50:  # ë„ˆë¬´ ì§§ì€ ì„¸ê·¸ë¨¼íŠ¸ëŠ” ê±´ë„ˆëœ€
                continue
                
            print(f"ğŸ”„ ì„¸ê·¸ë¨¼íŠ¸ {i}/{len(problem_segments)} ì²˜ë¦¬ ì¤‘...")
            
            # ê° ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ë¬¸ì œ ì¶”ì¶œ ì‹œë„
            problem = self._extract_single_problem_with_llm(segment, llm)
            if problem:
                all_problems.append(problem)
                print(f"âœ… ì„¸ê·¸ë¨¼íŠ¸ {i}ì—ì„œ ë¬¸ì œ ì¶”ì¶œ ì„±ê³µ")
            else:
                # LLM ì‹¤íŒ¨ ì‹œ ì •ê·œí‘œí˜„ì‹ í´ë°±
                regex_problem = self._extract_single_problem_with_regex(segment)
                if regex_problem:
                    all_problems.append(regex_problem)
                    print(f"âœ… ì„¸ê·¸ë¨¼íŠ¸ {i}ì—ì„œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë¬¸ì œ ì¶”ì¶œ")
                else:
                    print(f"âš ï¸ ì„¸ê·¸ë¨¼íŠ¸ {i} ì¶”ì¶œ ì‹¤íŒ¨")
        
        return all_problems

    def _split_text_by_problems(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì œ ë²ˆí˜¸ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• """
        # ë¬¸ì œ ë²ˆí˜¸ íŒ¨í„´ìœ¼ë¡œ ë¶„í•  (1. 2. 3. ë“±)
        pattern = r'(?=\d+\s*\.\s*)'
        segments = re.split(pattern, text)
        
        # ë¹ˆ ì„¸ê·¸ë¨¼íŠ¸ ì œê±°í•˜ê³  ì •ë¦¬
        cleaned_segments = []
        for segment in segments:
            segment = segment.strip()
            if segment and len(segment) > 20:  # ìµœì†Œ ê¸¸ì´ í•„í„°
                cleaned_segments.append(segment)
        
        return cleaned_segments

    def _extract_single_problem_with_llm(self, segment: str, llm) -> Optional[Dict]:
        """ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ LLMì„ ì‚¬ìš©í•´ í•˜ë‚˜ì˜ ë¬¸ì œ ì¶”ì¶œ"""
        try:
            # ë§¤ìš° ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ë¡œ ë‹¨ì¼ ë¬¸ì œë§Œ ì¶”ì¶œ
            sys_prompt = "í•œêµ­ì–´ ê°ê´€ì‹ ë¬¸ì œë¥¼ JSONìœ¼ë¡œ ë°˜í™˜í•´ë¼."
            user_prompt = (
                f"ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ê°ê´€ì‹ ë¬¸ì œ 1ê°œë¥¼ ì°¾ì•„ JSONìœ¼ë¡œ ë°˜í™˜í•´ë¼.\n"
                f"í˜•ì‹: {{\"question\": \"ì§ˆë¬¸ë‚´ìš©\", \"options\": [\"ë³´ê¸°1\", \"ë³´ê¸°2\", \"ë³´ê¸°3\", \"ë³´ê¸°4\"]}}\n"
                f"í…ìŠ¤íŠ¸:\n{segment[:2000]}"  # ê¸¸ì´ ì œí•œ
            )
            
            resp = llm.invoke([
                {"role": "system", "content": sys_prompt},
                {"role": "user", "content": user_prompt}
            ])
            
            content = (resp.content or "").strip()
            if not content:
                return None
            
            # JSON ì¶”ì¶œ ë° íŒŒì‹±
            json_part = self._extract_json_from_response(content)
            if not json_part:
                return None
            
            try:
                data = json.loads(json_part)
                if isinstance(data, dict) and "question" in data and "options" in data:
                    question = str(data["question"]).strip()
                    options = [str(opt).strip() for opt in data.get("options", []) if str(opt).strip()]
                    
                    if len(question) > 5 and len(options) >= 2:
                        # ë³´ê¸°ì—ì„œ ë²ˆí˜¸ ì œê±°
                        clean_options = []
                        for opt in options[:4]:
                            clean_opt = re.sub(r'^[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]?\s*', '', opt)
                            clean_opt = re.sub(r'^\d+\)\s*', '', clean_opt)
                            if clean_opt.strip():
                                clean_options.append(clean_opt.strip())
                        
                        if len(clean_options) >= 2:
                            return {
                                "question": re.sub(r'\s+', ' ', question),
                                "options": clean_options
                            }
                
            except json.JSONDecodeError:
                pass
            
        except Exception as e:
            print(f"âš ï¸ LLM ë‹¨ì¼ ë¬¸ì œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return None

    def _extract_single_problem_with_regex(self, segment: str) -> Optional[Dict]:
        """ë‹¨ì¼ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ í•˜ë‚˜ì˜ ë¬¸ì œ ì¶”ì¶œ"""
        try:
            # ë¬¸ì œ í…ìŠ¤íŠ¸ ì°¾ê¸°
            question_match = re.search(r'\d+\s*\.\s*(.+?)(?=[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]|\d+\))', segment, re.DOTALL)
            if not question_match:
                return None
            
            question = question_match.group(1).strip()
            if len(question) < 10:
                return None
            
            # ë³´ê¸°ë“¤ ì°¾ê¸°
            options = []
            
            # ì›ë¬¸ì ë³´ê¸° ì°¾ê¸°
            for opt_match in re.finditer(r'[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]\s*([^â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]+?)(?=[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]|\d+\s*\.|$)', segment, re.DOTALL):
                option_text = opt_match.group(1).strip()
                if len(option_text) > 3:
                    options.append(option_text)
                    if len(options) >= 4:
                        break
            
            # ìˆ«ì ë³´ê¸° ì°¾ê¸° (ì›ë¬¸ìê°€ ë¶€ì¡±í•œ ê²½ìš°)
            if len(options) < 2:
                for opt_match in re.finditer(r'\d+\)\s*([^1-4\)]+?)(?=\d+\)|\d+\s*\.|$)', segment, re.DOTALL):
                    option_text = opt_match.group(1).strip()
                    if len(option_text) > 3 and option_text not in options:
                        options.append(option_text)
                        if len(options) >= 4:
                            break
            
            if len(options) >= 2:
                return {
                    "question": re.sub(r'\s+', ' ', question),
                    "options": options[:4]
                }
            
        except Exception as e:
            print(f"âš ï¸ ì •ê·œí‘œí˜„ì‹ ë‹¨ì¼ ë¬¸ì œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        return None

    def _extract_problems_with_regex(self, text: str) -> List[Dict]:
        """ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ë¬¸ì œ-ë³´ê¸° íŒ¨í„´ì„ ì°¾ì•„ ì¶”ì¶œ"""
        problems = []
        
        # ë¬¸ì œ ë²ˆí˜¸ íŒ¨í„´ (1. 2. 3. ë“±)
        question_pattern = r'(\d+)\s*\.\s*([^â‘ -â‘©1-4\)]+?)(?=\d+\s*\.|$)'
        
        # ë³´ê¸° íŒ¨í„´ (â‘  â‘¡ â‘¢ â‘£ ë˜ëŠ” 1) 2) 3) 4))
        option_patterns = [
            r'[â‘ -â‘©]\s*([^â‘ -â‘©]+?)(?=[â‘ -â‘©]|\d+\s*\.|$)',
            r'(\d+\))\s*([^1-4\)]+?)(?=\d+\)|\d+\s*\.|$)'
        ]
        
        # ë¬¸ì œ ì°¾ê¸°
        for match in re.finditer(question_pattern, text, re.DOTALL):
            question_num = match.group(1)
            question_text = match.group(2).strip()
            
            # í•´ë‹¹ ë¬¸ì œ ë‹¤ìŒì— ì˜¤ëŠ” ë³´ê¸°ë“¤ ì°¾ê¸°
            start_pos = match.end()
            options = []
            
            # ì›ë¬¸ì ë³´ê¸° ì°¾ê¸°
            for opt_match in re.finditer(r'[â‘ -â‘©]\s*([^â‘ -â‘©]+?)(?=[â‘ -â‘©]|\d+\s*\.|$)', text[start_pos:], re.DOTALL):
                option_text = opt_match.group(1).strip()
                if len(option_text) > 5:  # ë„ˆë¬´ ì§§ì€ ë³´ê¸°ëŠ” ì œì™¸
                    options.append(option_text)
                    if len(options) >= 4:  # ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ
                        break
            
            # ìˆ«ì ë³´ê¸° ì°¾ê¸° (ì›ë¬¸ìê°€ ë¶€ì¡±í•œ ê²½ìš°)
            if len(options) < 4:
                for opt_match in re.finditer(r'(\d+\))\s*([^1-4\)]+?)(?=\d+\)|\d+\s*\.|$)', text[start_pos:], re.DOTALL):
                    option_text = opt_match.group(2).strip()
                    if len(option_text) > 5 and option_text not in options:
                        options.append(option_text)
                        if len(options) >= 4:
                            break
            
            # ìµœì†Œ 2ê°œ ë³´ê¸°ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
            if len(question_text) > 10 and len(options) >= 2:
                problems.append({
                    "question": re.sub(r'\s+', ' ', question_text),
                    "options": options[:4]  # ìµœëŒ€ 4ê°œê¹Œì§€ë§Œ
                })
        
        return problems

    # ========== LLM ì¼ê´„ íŒŒì„œ ===================================================

    def _parse_whole_text_with_llm(self, full_text: str, llm) -> Optional[List[Dict]]:
        """ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ë¬¸í•­ ë°°ì—´ì„ ì¶”ì¶œ(JSON ë°°ì—´ë§Œ í—ˆìš©) - í”„ë¡¬í”„íŠ¸ ê°•í™”íŒ"""
        cleaned = self.normalize_docling_markdown(full_text)
        cleaned = self._strip_headers_for_llm(cleaned)
        cleaned = self._fix_korean_spacing_noise(cleaned)

        # â”€â”€ í”„ë¡¬í”„íŠ¸(í˜•ì‹ ê·œì¹™ì„ ë§¤ìš° êµ¬ì²´ì ìœ¼ë¡œ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        sys_prompt = "í•œêµ­ì–´ ê°ê´€ì‹ ì‹œí—˜ì§€ì—ì„œ ë¬¸ì œë¥¼ ì°¾ì•„ JSON ë°°ì—´ë¡œ ë°˜í™˜í•´ë¼."

        # í˜•ì‹ ê·œì¹™: ì§ˆë¬¸/ë³´ê¸°ì˜ ì‹œì‘ê³¼ ëì„ ëª…ì‹œ
        user_prompt = (
            "ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ ê°ê´€ì‹ ë¬¸ì œë“¤ì„ ì°¾ì•„ JSON ë°°ì—´ë¡œ ë°˜í™˜í•´ë¼.\n"
            "í˜•ì‹: [{\"question\": \"ì§ˆë¬¸ë‚´ìš©\", \"options\": [\"ë³´ê¸°1\", \"ë³´ê¸°2\", \"ë³´ê¸°3\", \"ë³´ê¸°4\"]}]\n"
            "ë¬¸ì œ ë²ˆí˜¸ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì„ ì°¾ê³ , ê·¸ ë‹¤ìŒì— â‘  â‘¡ â‘¢ â‘£ë¡œ ì‹œì‘í•˜ëŠ” ë³´ê¸°ë“¤ì„ ì°¾ì•„ë¼.\n"
            "ì •ë‹µì´ë‚˜ í•´ì„¤ì€ ì œì™¸í•˜ê³  ë¬¸ì œì™€ ë³´ê¸°ë§Œ ì¶”ì¶œí•´ë¼.\n\n"
            f"í…ìŠ¤íŠ¸:\n{cleaned[:40000]}"
        )

        try:
            # LLM í˜¸ì¶œ ì‹œë„ (ìµœëŒ€ 3ë²ˆ)
            max_retries = 3
            for attempt in range(max_retries):
                try:
                    print(f"ğŸ”„ LLM í˜¸ì¶œ ì‹œë„ {attempt + 1}/{max_retries}")
                    resp = llm.invoke(
                        [
                            {"role": "system", "content": sys_prompt},
                            {"role": "user", "content": user_prompt},
                        ]
                    )
                    content = (resp.content or "").strip()
                    if content:
                        print(f"âœ… LLM í˜¸ì¶œ ì„±ê³µ (ì‹œë„ {attempt + 1})")
                        break
                    else:
                        print(f"âš ï¸ LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŒ (ì‹œë„ {attempt + 1})")
                        if attempt == max_retries - 1:
                            return None
                        continue
                        
                except Exception as e:
                    error_msg = str(e)
                    print(f"âš ï¸ LLM í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {error_msg}")
                    
                    # ê´„í˜¸ ì˜¤ë¥˜ì¸ ê²½ìš° í”„ë¡¬í”„íŠ¸ë¥¼ ë” ë‹¨ìˆœí•˜ê²Œ ë§Œë“¤ì–´ ì¬ì‹œë„
                    if "unbalanced parenthesis" in error_msg.lower() or "position" in error_msg.lower():
                        if attempt < max_retries - 1:
                            print("ğŸ”„ ê´„í˜¸ ì˜¤ë¥˜ ê°ì§€, í”„ë¡¬í”„íŠ¸ ë‹¨ìˆœí™”í•˜ì—¬ ì¬ì‹œë„...")
                            # ë” ë‹¨ìˆœí•œ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„
                            simple_sys = "ë¬¸ì œë¥¼ ì°¾ì•„ JSONìœ¼ë¡œ ë°˜í™˜í•´ë¼."
                            simple_user = f"í…ìŠ¤íŠ¸ì—ì„œ ê°ê´€ì‹ ë¬¸ì œë¥¼ ì°¾ì•„ [{{\"question\": \"ì§ˆë¬¸\", \"options\": [\"ë³´ê¸°1\", \"ë³´ê¸°2\", \"ë³´ê¸°3\", \"ë³´ê¸°4\"]}}] í˜•íƒœë¡œ ë°˜í™˜í•´ë¼.\n\n{cleaned[:20000]}"
                            
                            try:
                                resp = llm.invoke([
                                    {"role": "system", "content": simple_sys},
                                    {"role": "user", "content": simple_user}
                                ])
                                content = (resp.content or "").strip()
                                if content:
                                    print(f"âœ… ë‹¨ìˆœí™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì„±ê³µ")
                                    break
                            except Exception as retry_e:
                                print(f"âš ï¸ ë‹¨ìˆœí™”ëœ í”„ë¡¬í”„íŠ¸ë„ ì‹¤íŒ¨: {retry_e}")
                                continue
                        else:
                            print("âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                            return None
                    else:
                        # ë‹¤ë¥¸ ì˜¤ë¥˜ì¸ ê²½ìš° ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                        if attempt < max_retries - 1:
                            import time
                            time.sleep(1)
                            continue
                        else:
                            print("âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                            return None
            
            if not content:
                return None

            # ë‹¨ í•˜ë‚˜ì˜ JSON ì½”ë“œë¸”ë¡/ë°°ì—´ë§Œ ì¶”ì¶œ
            print(f"ğŸ” [DEBUG] LLM ì‘ë‹µ ë‚´ìš©:")
            print(f"--- ì‘ë‹µ ì‹œì‘ ---")
            print(content[:500] + "..." if len(content) > 500 else content)
            print(f"--- ì‘ë‹µ ë ---")
            
            json_part = self._extract_json_from_response(content)
            if not json_part:
                print("âŒ [ì¼ê´„] JSON ì¶”ì¶œ ì‹¤íŒ¨")
                return None
            
            print(f"ğŸ” [DEBUG] ì¶”ì¶œëœ JSON ë¶€ë¶„:")
            print(f"--- JSON ì‹œì‘ ---")
            print(json_part[:300] + "..." if len(json_part) > 300 else json_part)
            print(f"--- JSON ë ---")

            # 1ì°¨ íŒŒì‹±
            try:
                data = json.loads(json_part)
            except json.JSONDecodeError:
                # ë‚¨ì•„ìˆëŠ” ì”ì—¬ í…ìŠ¤íŠ¸ë¡œ ì¸í•œ 'Extra data' ëŒ€ì‘: ê°€ì¥ í° ìœ íš¨ ë°°ì—´ë§Œ íŒŒì‹±
                try:
                    from json import JSONDecoder
                    dec = JSONDecoder()
                    obj, _ = dec.raw_decode(json_part.lstrip())
                    data = obj
                except Exception:
                    fixed = self._fix_json_format(json_part)
                    try:
                        data = json.loads(fixed)
                    except json.JSONDecodeError as e2:
                        print(f"âŒ [ì¼ê´„] JSON íŒŒì‹± ì‹¤íŒ¨: {e2}")
                        return None

            if isinstance(data, dict):
                data = [data]
            if not isinstance(data, list):
                print("âŒ [ì¼ê´„] JSON ìµœìƒìœ„ê°€ ë°°ì—´ì´ ì•„ë‹˜")
                return None

            cleaned_list: List[Dict] = []
            for item in data:
                if not isinstance(item, dict):
                    continue
                q = (item.get("question") or "").strip()
                opts = item.get("options") if isinstance(item.get("options"), list) else []
                if not q or len(opts) < 2:
                    continue
                q = re.sub(r"\\s+", " ", q)[:800]
                norm_opts = []
                seen = set()
                for o in opts:
                    s = re.sub(r"\\s+", " ", str(o)).strip()
                    if not s or s in seen:
                        continue
                    seen.add(s)
                    # ë³´ê¸° ì• ë²ˆí˜¸/ì›ë¬¸ì ì œê±°(í˜¹ì‹œ ë‚¨ì•„ìˆë‹¤ë©´)
                    s = re.sub(r"^(?:[â‘ â‘¡â‘¢â‘£â‘¤â‘¥â‘¦â‘§â‘¨â‘©]|\\d+\\)|[A-E]\\)|[ê°€-í•˜]\\))\\s*", "", s)
                    norm_opts.append(s)
                if 2 <= len(norm_opts) <= 6:
                    cleaned_list.append({"question": q, "options": norm_opts})
            return cleaned_list or None

        except Exception as e:
            print(f"âš ï¸ [ì¼ê´„] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return None


    # ========== í…ìŠ¤íŠ¸/ì²­í¬/ì •ê·œí™” =============================================

    def _chunk_by_paragraph(self, text: str, max_chars: int = 16000) -> List[str]:
        """ë¹ˆ ì¤„ ê¸°ì¤€ìœ¼ë¡œ ì ì ˆíˆ í•©ì³ LLM ì…ë ¥ ê¸¸ì´ ì œì–´"""
        paras = [p for p in text.split("\n\n") if p.strip()]
        if not paras:  # ë¹ˆ ì¤„ ì—†ëŠ” ë¬¸ì„œ ëŒ€ë¹„
            paras = [text]

        chunks, cur, size = [], [], 0
        for p in paras:
            if size + len(p) + 2 > max_chars and cur:
                chunks.append("\n\n".join(cur))
                cur, size = [p], len(p)
            else:
                cur.append(p)
                size += len(p) + 2
        if cur:
            chunks.append("\n\n".join(cur))
        return chunks

    def normalize_docling_markdown(self, md: str) -> str:
        """Docling ë§ˆí¬ë‹¤ìš´ ì •ê·œí™”(ì‚¬ì†Œí•œ ë²ˆí˜¸/ê³µë°± ë³´ì •)"""
        s = md
        s = re.sub(r"(?m)^\s*(\d+)\.\s*\1\.\s*", r"\1. ", s)  # '1. 1.' â†’ '1.'
        s = re.sub(r"(?m)^\s*(\d+)\s*\.\s*", r"\1. ", s)      # '1 . ' â†’ '1. '
        s = re.sub(r"[ \t]+", " ", s).replace("\r", "")
        return s.strip()

    def _strip_headers_for_llm(self, s: str) -> str:
        """í—¤ë”/ë©”íƒ€ ë¼ì¸ ì œê±° ë° ì‰ì—¬ ê³µë°± ì •ë¦¬(LLM ì „ì²˜ë¦¬)"""
        s = re.sub(r"<!--.*?-->", "", s, flags=re.DOTALL)
        s = re.sub(r"(?m)^\s*<!--\s*image\s*-->\s*$", "", s)
        # ë§ˆí¬ë‹¤ìš´ í—¤ë” í”„ë¦¬í”½ìŠ¤ ì œê±°(ë‚´ìš© ë³´ì¡´)
        s = re.sub(r"(?m)^\s*#{1,6}\s*", "", s)
        # ê³¼ë„í•œ ë¹ˆ ì¤„ ì¶•ì†Œ
        s = re.sub(r"\n{3,}", "\n\n", s)
        s = re.sub(r"[ \t]+", " ", s)
        return s.strip()

    def _fix_korean_spacing_noise(self, s: str) -> str:
        """í•œê¸€-í•œê¸€ ì‚¬ì´ì— ìƒê¸´ ë¶ˆí•„ìš” ê³µë°± ì œê±°(ì˜ˆ: 'ìµìŠ¤íŠ¸ ë¦¼')"""
        for _ in range(2):  # ë‘ ë²ˆ ì •ë„ ë°˜ë³µ
            s = re.sub(r"([\uAC00-\uD7A3])\s+(?=[\uAC00-\uD7A3])", r"\1", s)
        return s

    # ========== JSON ì¶”ì¶œ ìœ í‹¸ ================================================

    def _extract_json_from_response(self, content: str) -> Optional[str]:
        """
        ì‘ë‹µì—ì„œ 'ë‹¨ í•˜ë‚˜ì˜' JSON ë°°ì—´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        1) ```json ì½”ë“œë¸”ë¡``` ì•ˆì˜ ë°°ì—´ ìš°ì„ 
        2) ë³¸ë¬¸ ì „ì²´ì—ì„œ ê°€ì¥ í° ìœ íš¨ JSON ë°°ì—´(ëŒ€ê´„í˜¸ ê· í˜• ìŠ¤ìº”)
        3) ë§ˆì§€ë§‰ í´ë°±: ë‹¨ì¼ ê°ì²´ê°€ ìˆìœ¼ë©´ ë°˜í™˜(ìƒìœ„ì—ì„œ dictâ†’listë¡œ ê°ìŒˆ)
        """
        try:
            # 1) ì½”ë“œë¸”ë¡ ìš°ì„ 
            m = re.search(r"```(?:json)?\s*(\[[\s\S]*?\])\s*```", content, re.DOTALL)
            if m:
                return m.group(1).strip()

            # 2) ë³¸ë¬¸ì—ì„œ ê°€ì¥ í° ìœ íš¨ ë°°ì—´
            arr = self._find_largest_json_array(content)
            if arr:
                return arr

            # 3) ê°ì²´ í´ë°±(ì§ˆë¬¸/ë³´ê¸° í‚¤ë¥¼ ê°€ì§„ ê°ì²´ë§Œ í—ˆìš©)
            obj = self._find_first_question_object(content)
            if obj:
                return obj

            return None
            
        except Exception as e:
            print(f"âš ï¸ JSON ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return None

    def _find_first_question_object(self, content: str) -> Optional[str]:
        """ì§ˆë¬¸/ë³´ê¸° í‚¤ë¥¼ ê°€ì§„ ì²« ë²ˆì§¸ JSON ê°ì²´ë¥¼ ì°¾ì•„ ë°˜í™˜"""
        try:
            # questionê³¼ options í‚¤ë¥¼ ëª¨ë‘ í¬í•¨í•˜ëŠ” ê°ì²´ ì°¾ê¸°
            pattern = r'\{[^{}]*"question"\s*:\s*"[^"]*"[^{}]*"options"\s*:\s*\[[^{}]*\][^{}]*\}'
            match = re.search(pattern, content, re.DOTALL)
            if match:
                return match.group(0)
            
            # ë” ìœ ì—°í•œ íŒ¨í„´ìœ¼ë¡œ ì‹œë„
            pattern2 = r'\{[^{}]*"question"[^{}]*"options"[^{}]*\}'
            match2 = re.search(pattern2, content, re.DOTALL)
            if match2:
                return match2.group(0)
                
            return None
            
        except Exception as e:
            print(f"âš ï¸ ê°ì²´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None

    def _is_valid_json_structure(self, text: str) -> bool:
        """ì¤‘ê´„í˜¸/ëŒ€ê´„í˜¸ ì§ ê°„ë‹¨ ê²€ì‚¬ + ì‹œì‘/ë ë¬¸ì ê²€ì‚¬"""
        if text.count("{") != text.count("}"):
            return False
        if text.count("[") != text.count("]"):
            return False
        if not (text.startswith("{") and text.endswith("}")) and not (
            text.startswith("[") and text.endswith("]")
        ):
            return False
        return True

    def _construct_json_from_parts(self, content: str) -> Optional[str]:
        """í©ì–´ì§„ question/optionsë¥¼ ì°¾ì•„ ìµœì†Œ JSON êµ¬ì„±"""
        try:
            q = re.search(r'"question"\s*:\s*"([^"]*)"', content)
            o = re.search(r'"options"\s*:\s*\[(.*?)\]', content, re.DOTALL)
            if not (q and o):
                return None
            question = q.group(1)
            options = [x for x in re.findall(r'"([^"]*)"', o.group(1)) if x.strip()]
            if not options:
                return None
            return json.dumps({"question": question, "options": options}, ensure_ascii=False)
        except Exception:
            return None

    def _fix_json_format(self, content: str) -> str:
        """ê°€ë²¼ìš´ JSON í¬ë§· ë³´ì •"""
        try:
            # ê¸°ë³¸ ì •ë¦¬
            content = re.sub(r",\s*}", "}", content)
            content = re.sub(r",\s*]", "]", content)
            content = re.sub(r"\n|\r", " ", content)
            content = re.sub(r"\s+", " ", content)
            
            # ì¤‘ê´„í˜¸/ëŒ€ê´„í˜¸ ë²”ìœ„ ì°¾ê¸°
            if content.count("{") > 0 and content.count("}") > 0:
                start = content.find("{")
                end = content.rfind("}")
                if start < end:
                    content = content[start:end + 1]
                    
            if content.count("[") > 0 and content.count("]") > 0:
                start = content.find("[")
                end = content.rfind("]")
                if start < end:
                    content = content[start:end + 1]
            
            # ë”°ì˜´í‘œ ë¬¸ì œ ìˆ˜ì •
            content = re.sub(r'([^\\])"([^"]*?)([^\\])"', r'\1"\2\3"', content)
            
            return content.strip()
            
        except Exception as e:
            print(f"âš ï¸ JSON í¬ë§· ìˆ˜ì • ì˜¤ë¥˜: {e}")
            return content

    # ========== dedupe =========================================================

    def _fingerprint(self, q: str) -> str:
        s = q.lower()
        s = re.sub(r"\s+", "", s)
        s = re.sub(r"[^a-z0-9\uAC00-\uD7A3]", "", s)
        return hashlib.md5(s.encode("utf-8")).hexdigest()

    def _dedupe_problems(self, items: List[Dict]) -> List[Dict]:
        seen = set()
        out: List[Dict] = []
        for it in items:
            q = (it.get("question") or "").strip()
            opts = it.get("options") or []
            if not q or not isinstance(opts, list) or len(opts) == 0:
                continue
            fp = self._fingerprint(q)
            if fp in seen:
                continue
            seen.add(fp)

            clean_opts = []
            oseen = set()
            for o in opts:
                o2 = re.sub(r"\s+", " ", str(o)).strip()
                if o2 and o2 not in oseen:
                    oseen.add(o2)
                    clean_opts.append(o2)
            it["options"] = clean_opts[:6]
            out.append(it)
        return out


# â”€â”€ ëª¨ë“ˆ ë ˆë²¨ í¸ì˜ í•¨ìˆ˜ë“¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def extract_pdf_paths(text: str) -> List[str]:
    pre = PDFPreprocessor()
    return pre.extract_pdf_paths(text)

def extract_problem_range(text: str) -> Optional[Dict]:
    pre = PDFPreprocessor()
    return pre.extract_problem_range(text)

def determine_problem_source(text: str) -> Optional[str]:
    pre = PDFPreprocessor()
    return pre.determine_problem_source(text)

# â†‘ ìœ„ 3ê°œ í¸ì˜ í•¨ìˆ˜ëŠ” ì•„ë˜ ê°„ë‹¨ êµ¬í˜„ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
# í•„ìš” ì—†ìœ¼ë©´ ì‚­ì œí•´ë„ ë˜ì§€ë§Œ ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„ ìœ„í•´ ìœ ì§€.

PDF_PATH_PATTERNS = [
    r"([^\s]+\.pdf)",  # ê¸°ë³¸ .pdf
    r"([C-Z]:[\\\/][^\\\/\s]*\.pdf)",  # Windows ì ˆëŒ€ ê²½ë¡œ
    r"([\.\/][^\\\/\s]*\.pdf)",  # ìƒëŒ€ ê²½ë¡œ
]

def _findall(pattern, text):
    return re.findall(pattern, text, re.IGNORECASE)

def _extract_pdf_paths_impl(self, text: str) -> List[str]:
    paths = []
    for p in PDF_PATH_PATTERNS:
        paths.extend(_findall(p, text))
    return list(set(paths))

def _extract_problem_range_impl(self, text: str) -> Optional[Dict]:
    # ë‹¨ì¼ ë²ˆí˜¸: "5ë²ˆë§Œ", "5ë²ˆ í’€ì–´ì¤˜"
    m = re.search(r'(\d+)ë²ˆë§Œ', text)
    if m:
        return {"type": "single", "number": int(m.group(1))}
    m = re.search(r'(\d+)ë²ˆ\s*í’€', text)
    if m:
        return {"type": "single", "number": int(m.group(1))}

    # ë²”ìœ„: "1-10ë²ˆ", "3ë²ˆë¶€í„° 7ë²ˆ"
    m = re.search(r'(\d+)\s*[-~]\s*(\d+)ë²ˆ', text)
    if m:
        return {"type": "range", "start": int(m.group(1)), "end": int(m.group(2))}
    m = re.search(r'(\d+)ë²ˆë¶€í„°\s*(\d+)ë²ˆ', text)
    if m:
        return {"type": "range", "start": int(m.group(1)), "end": int(m.group(2))}

    # ë¬¶ìŒ: "1,3,5ë²ˆ"
    m = re.search(r'(\d+(?:\s*,\s*\d+)*)ë²ˆ', text)
    if m:
        numbers = [int(x.strip()) for x in m.group(1).split(',')]
        return {"type": "specific", "numbers": numbers}

    return None

def _determine_problem_source_impl(self, text: str) -> Optional[str]:
    tl = text.lower()
    if any(k in tl for k in ['pdf', 'íŒŒì¼', 'ë¬¸ì„œ']):
        return "pdf_extracted"
    if any(k in tl for k in ['ê¸°ì¡´', 'shared', 'ì €ì¥ëœ', 'ì´ì „']):
        return "shared"
    if _extract_pdf_paths_impl(self, text):
        return "pdf_extracted"
    return None

# í´ë˜ìŠ¤ ë©”ì†Œë“œë¡œ ë°”ì¸ë”©
PDFPreprocessor.extract_pdf_paths = _extract_pdf_paths_impl
PDFPreprocessor.extract_problem_range = _extract_problem_range_impl
PDFPreprocessor.determine_problem_source = _determine_problem_source_impl
