from openai import OpenAI
from typing import List, Dict, Any, Optional
import os 
import json
import re
from dotenv import load_dotenv
load_dotenv()

openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
  raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. .env ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì— í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

# LLM ëª¨ë¸ ì„¤ì •ì„ í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
OPENAI_LLM_MODEL = os.getenv("OPENAI_LLM_MODEL", "moonshotai/kimi-k2-instruct")
LLM_TEMPERATURE = float(os.getenv("LLM_TEMPERATURE", "0.2"))

client = OpenAI(base_url=os.getenv("OPENAI_BASE_URL", "https://api.groq.com/openai/v1"), api_key=openai_api_key)


def user_intent(user_question: str) -> dict:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    system_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì„ í†µí•´ ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì„¸ìš”:
    ì‚¬ìš©ì ì§ˆë¬¸ : {user_question}
    ì§ˆë¬¸ì˜ ì˜ë„ ì¢…ë¥˜ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.
     - generate: ì‹œí—˜ ë¬¸ì œ ìƒì„± - ìƒˆë¡œìš´ ë¬¸ì œë¥¼ ë§Œë“¤ê±°ë‚˜ ìƒì„±í•˜ëŠ” ê²ƒ (ì˜ˆ: "ë¬¸ì œ ë§Œë“¤ì–´ì¤˜", "5ë¬¸ì œ ì¶œì œí•´ì¤˜")
     - retrieve: ì •ë³´ ê²€ìƒ‰ - ëª¨ë¥´ëŠ” ë‹¨ì–´ ë° ìš©ì–´ì— ëŒ€í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ëŠ” ê²ƒ
     - analyze: ì˜¤ë‹µ ë¶„ì„ - í‹€ë¦° ë¬¸ì œë¥¼ ì •ë¦¬í•˜ê³  ìœ í˜•ì„ ë¶„ì„í•˜ì—¬ ë³´ì™„ì  ë° ì „ëµ ìƒì„±ì„ ì¶”ì²œí•˜ëŠ” ê²ƒ
     - solution: ë¬¸ì œ í’€ì´ - ê¸°ì¡´ ë¬¸ì œì— ëŒ€í•œ ë‹µê³¼ í’€ì´, í•´ì„¤ì„ ì œê³µí•˜ëŠ” ê²ƒ (ì˜ˆ: "ë¬¸ì œ í’€ì–´ì¤˜", "ì´ê±° í•´ì„¤ í•´ì¤˜", "PDF í’€ì´í•´ì¤˜")
     - score: ì±„ì  - ë¬¸ì œ í’€ì´ì— ëŒ€í•œ ì±„ì  ë° í•©ê²© ì—¬ë¶€ë¥¼ íŒë‹¨ í•˜ëŠ” ê²ƒ
     
    ì¤‘ìš”í•œ êµ¬ë¶„:
    - PDF íŒŒì¼ì´ë‚˜ ê¸°ì¡´ ë¬¸ì œë¥¼ í’€ì–´ë‹¬ë¼ê³  í•˜ë©´ "solution"
    - ìƒˆë¡œìš´ ë¬¸ì œë¥¼ ë§Œë“¤ì–´ë‹¬ë¼ê³  í•˜ë©´ "generate"
    - "í’€ì–´", "í’€ì´", "í•´ì„¤" ë“±ì˜ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ëŒ€ë¶€ë¶„ "solution"
    - ì‚¬ìš©ìê°€ ë³¸ì¸ì´ ì…ë ¥í•œ ë‹µì— ëŒ€í•´ ë¬»ëŠ” ê²½ìš° "score"
     
    ìœ„ 5ê°€ì§€ ì˜ë„ ì¤‘ í•˜ë‚˜ë¡œë§Œ ë¶„ë¥˜í•˜ê³ , ê·¸ ì™¸ì— ë‹¨ì–´ë‚˜ ë¬¸ì¥ì€ í¬í•¨ë˜ì§€ ì•Šê²Œ ë‹µë³€í•˜ì„¸ìš”.
    string í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ì˜ˆì‹œ:
    "solution"
    """

    response = client.chat.completions.create(
        model=OPENAI_LLM_MODEL,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_question}
        ],
        temperature=LLM_TEMPERATURE
    )
    result = response.choices[0].message.content
    
    return result.strip().lower()

def get_user_answer(user_question: str) -> list:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ë‹µë³€ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    system_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ë‹µë³€ì„ ì¶”ì¶œí•˜ì„¸ìš”:
    ì‚¬ìš©ì ì§ˆë¬¸ : {user_question}
    
    ë‹µë³€ì€ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ëª¨ë“  ë¬¸ì œëŠ” ê°ê´€ì‹ì´ë©°, ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë³´ê¸°ì˜ ìˆ«ìë§Œì„ ë¦¬ìŠ¤íŠ¸(list[str]) í˜•íƒœë¡œ ì¶”ì¶œí•´ì•¼ í•©ë‹ˆë‹¤.
    "[4, 3, 1, 2, 4, 3, 3, 2, 1, 1, 4]"
    
    ì˜ˆì‹œ:
    ì‚¬ìš©ì ì…ë ¥: "ì •ë‹µì€ 4ë²ˆ, 3ë²ˆ, 1ë²ˆ, 2ë²ˆ, 4ë²ˆ, 3ë²ˆ, 3ë²ˆ, 2ë²ˆ, 1ë²ˆ, 1ë²ˆ, 4ë²ˆì…ë‹ˆë‹¤."
    ì¶”ì¶œí•  ë‚´ìš©: "[4, 3, 1, 2, 4, 3, 3, 2, 1, 1, 4]"
    ì¶”ì¶œí•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ì„¸ìš”. ì˜ˆì‹œ: "[]"
    """

    response = client.chat.completions.create(
        model=OPENAI_LLM_MODEL,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_question}
        ],
        temperature=LLM_TEMPERATURE
    )
    
    result = response.choices[0].message.content.strip()
    
    # LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    try:
        # JSON í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´ì„ íŒŒì‹±
        import json
        if result.startswith('[') and result.endswith(']'):
            parsed_list = json.loads(result)
            if isinstance(parsed_list, list):
                # â˜… í•­ìƒ ë¬¸ìì—´ë¡œ ì •ê·œí™”í•´ì„œ ë°˜í™˜
                return [str(x).strip() for x in parsed_list]
        
        # JSON íŒŒì‹±ì´ ì‹¤íŒ¨í•œ ê²½ìš°, ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ìˆ«ì ì¶”ì¶œ
        import re
        numbers = re.findall(r'\d+', result)
        if numbers:
            # â˜… ì—¬ê¸°ì„œë„ ë¬¸ìì—´ ë³´ì¥
            return [n.strip() for n in numbers]
        
        # ìˆ«ìë„ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
        return []
        
    except (json.JSONDecodeError, ValueError):
        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ìˆ«ì ì¶”ì¶œ
        import re
        numbers = re.findall(r'\d+', result)
        return numbers if numbers else []

def parse_generator_input(user_question: str) -> dict:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ê³¼ëª©/ë¬¸í•­ìˆ˜/ë‚œì´ë„ íŒŒì‹±
    """
    system_prompt = f"""ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ê³¼ëª©/ë¬¸í•­ìˆ˜/ë‚œì´ë„ë¥¼ íŒŒì‹±í•˜ì„¸ìš”:
    ì§€ì •ëœ í˜•ì‹ì˜ ì‘ë‹µ ì™¸ì— ë¬¸ì¥ì´ë‚˜ ë‹¨ì–´, íŠ¹ìˆ˜ë¬¸ìëŠ” ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”.
    ì‚¬ìš©ì ì§ˆë¬¸ : {user_question}
    
    ì§€ì›í•˜ëŠ” ëª¨ë“œ:
    1. subject_quiz: ë‹¨ì¼ ê³¼ëª© ë¬¸ì œ ìƒì„±
    2. partial_exam: ì„ íƒëœ ê³¼ëª©ë“¤ì— ëŒ€í•´ ì§€ì •ëœ ë¬¸ì œ ìˆ˜ë§Œí¼ ìƒì„±
    3. full_exam: 5ê³¼ëª© ì „ì²´ ë¬¸ì œ ìƒì„± (ê° 20ë¬¸ì œì”©)
    
    ê³¼ëª©ì€ 5ê°€ì§€ ì¤‘ ì„ íƒ: (ê³¼ëª©ì€ ë¬´ì¡°ê±´ ì•„ë˜ 5ê°€ì§€ ì¤‘ ì„ íƒì„ í•´ì•¼ í•©ë‹ˆë‹¤. ë˜í•œ, 'ê³¼ëª© ë‹¹', 'ì „ê³¼ëª©'ì„ ìš”ì²­í•  ê²½ìš° ëª¨ë“  ê³¼ëª©ì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.)
    - ì†Œí”„íŠ¸ì›¨ì–´ì„¤ê³„, ì†Œí”„íŠ¸ì›¨ì–´ê°œë°œ, ë°ì´í„°ë² ì´ìŠ¤êµ¬ì¶•, í”„ë¡œê·¸ë˜ë°ì–¸ì–´í™œìš©, ì •ë³´ì‹œìŠ¤í…œêµ¬ì¶•ê´€ë¦¬
    
    ë¬¸í•­ ìˆ˜ëŠ” ê³¼ëª©ë³„ ìµœëŒ€ 40ë¬¸ì œê¹Œì§€ ê°€ëŠ¥
    ë‚œì´ë„ëŠ” ì´ˆê¸‰, ì¤‘ê¸‰, ê³ ê¸‰ ì¤‘ í•˜ë‚˜, ì–¸ê¸‰ ì—†ìœ¼ë©´ ì¤‘ê¸‰ìœ¼ë¡œ ê°„ì£¼
    ê³¼ëª© ì„ ì • ì—†ì´ ë¬¸ì œ ìˆ˜ ë§Œìœ¼ë¡œ ë¬¸ì œ ìƒì„± ìš”ì²­ ì‹œ ì „ì²´ ê³¼ëª© ìƒì„±. ì´ ë•Œ, ê³¼ëª© ë‹¹ ë¬¸ì œ ìˆ˜ëŠ” ì „ì²´ ë¬¸ì œ ìˆ˜ì˜ 1/5ë¡œ ê°„ì£¼
    ë‹¤ë¥¸ ë³€ìˆ˜ ì—†ì´ ë‹¨ìˆœí•œ ë¬¸ì œ ìƒì„± ìš”ì²­ì€ ì „ì²´ ì‹œí—˜ ë¬¸ì œ ìƒì„±ìœ¼ë¡œ ê°„ì£¼
    
    íŒŒì‹± ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:
    
    ë‹¨ì¼ ê³¼ëª©ì˜ ê²½ìš°:
    {{
        "mode": "subject_quiz",
        "subject_area": "ê³¼ëª©ëª…",
        "target_count": "ë¬¸í•­ ìˆ˜",
        "difficulty": "ë‚œì´ë„"
    }}
    
    ì—¬ëŸ¬ ê³¼ëª© ì„ íƒì˜ ê²½ìš°:
    {{
        "mode": "partial_exam",
        "selected_subjects": ["ê³¼ëª©1", "ê³¼ëª©2", "ê³¼ëª©3"],
        "questions_per_subject": "ê³¼ëª©ë‹¹ ë¬¸í•­ ìˆ˜",
        "difficulty": "ë‚œì´ë„"
    }}
    
    ì „ì²´ ê³¼ëª©ì˜ ê²½ìš°:
    {{
        "mode": "full_exam",
        "difficulty": "ë‚œì´ë„"
    }}
    """

    try:
        response = client.chat.completions.create(
            model=OPENAI_LLM_MODEL,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_question}
            ],
            temperature=LLM_TEMPERATURE
        )
        
        result = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            import json
            parsed = json.loads(result)
            return parsed
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {result}")
            return {
                "mode": "full_exam",
                "difficulty": "ì¤‘ê¸‰"
            }
            
    except Exception as e:
        print(f"âš ï¸ parse_generator_input ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "mode": "full_exam",
            "difficulty": "ì¤‘ê¸‰"
        }

# teacher_nodes.py
# ë…¸ë“œ ë‚´ë¶€ì—ì„œ ì‚¬ìš©ë˜ëŠ” í—¬í¼ í•¨ìˆ˜ë“¤ê³¼ ë¼ìš°íŒ… ë¡œì§

# ========== ê¸°ì¡´ í•¨ìˆ˜ë“¤ ==========
def get_user_answer(user_query: str) -> List[str]:
    """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ë‹µì•ˆ ì¶”ì¶œ"""
    # ê¸°ì¡´ êµ¬í˜„ ìœ ì§€
    pass

def parse_generator_input(user_query: str) -> Dict[str, Any]:
    """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ìƒì„± íŒŒë¼ë¯¸í„° ì¶”ì¶œ"""
    # ê¸°ì¡´ êµ¬í˜„ ìœ ì§€
    pass

def user_intent(user_query: str) -> str:
    """ì‚¬ìš©ì ì˜ë„ ë¶„ë¥˜"""
    # ê¸°ì¡´ êµ¬í˜„ ìœ ì§€
    pass

# ========== ë¼ìš°íŒ… í•¨ìˆ˜ë“¤ ==========
def route_solution(state: Dict[str, Any]) -> Dict[str, Any]:
    """solution ë…¸ë“œ ë¼ìš°íŒ…"""
    # ìš°ì„ ìˆœìœ„: ì „ì²˜ë¦¬ í•„ìš” â†’ ì „ì²˜ë¦¬ í›„ solution â†’ ê¸°ì¡´ ë¬¸ì œë¡œ solution
    from teacher_util import has_files_to_preprocess, has_questions
    
    if has_files_to_preprocess(state):
        next_node = "preprocess"
        print("ğŸ“„ PDF íŒŒì¼ ì „ì²˜ë¦¬ í›„ solution ì‹¤í–‰")
    elif has_questions(state):
        next_node = "solution"
        print("ğŸ“„ ê¸°ì¡´ ë¬¸ì œë¡œ solution ì‹¤í–‰")
    else:
        next_node = "mark_after_generator_solution"
    
    new_state = {**state}
    new_state.setdefault("routing", {})
    new_state["routing"]["solution_next"] = next_node
    return new_state

def route_score(state: Dict[str, Any]) -> Dict[str, Any]:
    """score ë…¸ë“œ ë¼ìš°íŒ…"""
    from teacher_util import has_solution_answers
    
    next_node = "score" if has_solution_answers(state) else "mark_after_solution_score"
    new_state = {**state}
    new_state.setdefault("routing", {})
    new_state["routing"]["score_next"] = next_node
    return new_state

def route_analysis(state: Dict[str, Any]) -> Dict[str, Any]:
    """analysis ë…¸ë“œ ë¼ìš°íŒ…"""
    from teacher_util import has_score
    
    next_node = "analysis" if has_score(state) else "mark_after_score_analysis"
    new_state = {**state}
    new_state.setdefault("routing", {})
    new_state["routing"]["analysis_next"] = next_node
    return new_state

# ========== ë§ˆí‚¹ í•¨ìˆ˜ë“¤ ==========
def mark_after_generator_solution(state: Dict[str, Any]) -> Dict[str, Any]:
    """generator í›„ solution ì‹¤í–‰ì„ ìœ„í•œ ë§ˆí‚¹"""
    ns = {**state}
    ns.setdefault("routing", {})
    ns["routing"]["after_generator"] = "solution"
    return ns

def mark_after_solution_score(state: Dict[str, Any]) -> Dict[str, Any]:
    """solution í›„ score ì‹¤í–‰ì„ ìœ„í•œ ë§ˆí‚¹"""
    ns = {**state}
    ns.setdefault("routing", {})
    ns["routing"]["after_solution"] = "score"
    return ns

def mark_after_score_analysis(state: Dict[str, Any]) -> Dict[str, Any]:
    """score í›„ analysis ì‹¤í–‰ì„ ìœ„í•œ ë§ˆí‚¹"""
    ns = {**state}
    ns.setdefault("routing", {})
    ns["routing"]["after_score"] = "analysis"
    return ns

# ========== í¬ìŠ¤íŠ¸ ë¼ìš°íŒ… í•¨ìˆ˜ë“¤ ==========
def post_generator_route(state: Dict[str, Any]) -> str:
    """generator ì‹¤í–‰ í›„ ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
    nxt = ((state.get("routing") or {}).get("after_generator") or "").strip()
    return nxt if nxt else "generate_problem_pdf"  # ê¸°ë³¸ì ìœ¼ë¡œ ë¬¸ì œì§‘ PDF ìƒì„±

def post_solution_route(state: Dict[str, Any]) -> str:
    """solution ì‹¤í–‰ í›„ ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
    nxt = ((state.get("routing") or {}).get("after_solution") or "").strip()
    return nxt if nxt else "generate_answer_pdf"  # ê¸°ë³¸ì ìœ¼ë¡œ ë‹µì•ˆì§‘ PDF ìƒì„±

def post_score_route(state: Dict[str, Any]) -> str:
    """score ì‹¤í–‰ í›„ ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
    nxt = ((state.get("routing") or {}).get("after_score") or "").strip()
    return nxt if nxt else "analysis"  # ê¸°ë³¸ì ìœ¼ë¡œ ë¶„ì„ ì§„í–‰

def post_analysis_route(state: Dict[str, Any]) -> str:
    """analysis ì‹¤í–‰ í›„ ë‹¤ìŒ ë…¸ë“œ ê²°ì •"""
    nxt = ((state.get("routing") or {}).get("after_analysis") or "").strip()
    return nxt if nxt else "generate_analysis_pdf"  # ê¸°ë³¸ì ìœ¼ë¡œ ë¶„ì„ ë¦¬í¬íŠ¸ PDF ìƒì„±